\documentclass[10pt]{amsart}
\author{Aram L. Karakhanyan}
\address{
School of  Mathematics\\
The University of Edinburgh,\\
Mayfield Road, King's Buildings,  EH9 3JZ\\
Edinburgh, UK}
\email{aram.karakhanyan@ed.ac.uk}
\title[Homogenization]{On a conjecture of De Giorgi related to homogenization}

\author{Henrik Shahgholian}
\address{Department of Mathematics, KTH, Lindstedtsv\"agen 25, 100 44 Stockholm, Sweden}
\email{henriksh@kth.se}
\thanks{H. Shahgholian was supported by Swedish Research Council. A.Karakhanyan was partly supported by EPSRC grant. 
We thank Michael Benedicks for his insightful  comments on the dynamical system issues of the current note,
and Bj\"orn Engquist for bringing to our attention the paper \cite{Hou}.}
\thanks{2010 Mathematics Subject Classification: 34C29, 37A10, 65L70, 74Q10}
\keywords{dynamical system, ODE, transport, homogenization, convergence rate}

\usepackage{color}
\usepackage{graphics}
\usepackage[dvips]{graphicx}
\usepackage{amsmath}
\usepackage{amsfonts}
\usepackage{mathrsfs}
\usepackage{mathrsfs}
\usepackage{mathabx}                                                                                      \usepackage{upgreek}
\usepackage{esint} 
\usepackage{fancyhdr}
\usepackage{latexsym}
\usepackage{amssymb}
\usepackage[all]{xy}
\usepackage{float,graphicx}
\usepackage{fancybox}
\usepackage{rotating}
\usepackage{tikz}
\usepackage{pgfplots}

\newtheorem{theorem}{Theorem}                                                                                \newtheorem{lemma}{Lemma}                                                                                    \newtheorem{proposition}{Proposition}                                                                        \newtheorem{corollary}{Corollary}                                                                            \newtheorem{definition}{Definition}                                                                          \newtheorem{claim}{Claim}
\theoremstyle{definition}                                                                                  \newtheorem{remark}[theorem]{Remark}
\newtheorem*{comp}{Comparison Principle}
\theoremstyle{theorem}
\newtheorem*{AAA}{Theorem A}                                                                   \newtheorem*{BBB}{Theorem B}
\newtheorem*{CCC}{Theorem C}
                                  

 

 
 
 

\usepackage{amsmath}

\begin{document}

\begin{abstract} 
For a  periodic vector field ${\textbf{F}}$,  let
 ${\textbf{X}}^{\varepsilon}$ solve the dynamical  system 
\begin{equation*}
 \frac{d{\textbf{X}}^{\varepsilon}}{dt}  = {\textbf{F}}{\left(}\frac {{\textbf{X}}^{\varepsilon}}{\varepsilon}{\right)} .
\end{equation*}
In \cite{DeGiorgi}  Ennio De Giorgi enquiers  whether from the existence of the limit  
${\textbf{X}}^0(t):=\lim\limits_{{\varepsilon}\to 0}{\textbf{X}}^{\varepsilon}(t)$ one can conclude that  $ \frac{d{\textbf{X}}^0}{dt}= constant$. 
Our main result settles this conjecture under fairly general assumptions on ${\textbf{F}}$, which may also depend on $t$-variable. 

Once the above problem is solved, one can apply the result to the transport equation, in a standard way. This is also touched upon in the text to follow.
\end{abstract}	

\maketitle

\section{Introduction}

\subsection{Problem setting}
For each $i=1, \dots, d$ let  $F_i:{\mathbb R}^d\to {\mathbb R}$ be ${\mathbb Z}^d$ periodic smooth function and ${\varepsilon}>0$ being small parameter. 
In this paper we  consider 
the first order  system of differential equations with oscillating structure 
\begin{eqnarray}\label{eq-0eps}
  {\displaystyle\frac{d{{x_i}}}{dt} }=F_i{\left(}\frac{x_1}{\varepsilon}, \dots, \frac{x_d}{\varepsilon}{\right)}\quad i=1, \dots, d.
\end{eqnarray}
Our primary motivation for studying (\ref{eq-0eps}) comes from a conjecture 
posed by Ennio De Giorgi in
\cite{DeGiorgi} (Conjecture 1.1 page 175)
concerning the homogenization of the transport equation 
\begin{eqnarray}\label{eq-0trans}
 {\partial}_tu^{\varepsilon}(x, t)+ {\textbf{F}}{\left(} x/ {\varepsilon}, t/{\varepsilon}{\right)}  \cdot \nabla_x u^{\varepsilon}(x, t)=0, \quad u^{\varepsilon}(x, 0)=u_0(x) \ \forall x\in {\mathbb R}^d ,
\end{eqnarray}
with ${\textbf{F}}=(F_1, F_2, \dots, F_d)$ Lipschitz continuous and periodic in $(x, t)$. The Lipschitz continuous initial condition  $u_0(x)$ is  specified at the initial time $t=0$. 

\medskip 
He also conjectured that if (\ref{eq-0trans}) is homogenizable then the following property must be true, see 
\cite{DeGiorgi} page 177:
{\it Let ${\textbf{X}}^{\varepsilon}(t)$ be the solution of
\begin{equation}\label{ibvp}
 {\displaystyle\frac{d{{{\textbf{X}}^{\varepsilon}}}}{dt} }={\textbf{F}}{\left(}\frac{ {\textbf{X}}^{\varepsilon}}{\varepsilon}{\right)}, \quad {\textbf{X}}^{\varepsilon}(0)= p.
\end{equation}
Then there exists
\begin{equation}\label{eff-lim}
 \lim_{{\varepsilon}\to 0}{\textbf{X}}^{\varepsilon}(t)={\textbf{X}}^0(t)
\end{equation}
for any $t,  p$.
Moreover, there is a vector ${\textbf{B}}\in {\mathbb R}^d$ such that
\begin{equation}\label{eff-der}
 \frac{d {\textbf{X}} ^0}{d t}={\textbf{B}} .
\end{equation}
}
On the other hand Peirone \cite{Peirone}  showed that if ${\textbf{F}}$ does not depend on $t$ then the asymptotic linearity of 
${\textbf{X}}^{\varepsilon}(t)$ as $t\to \infty$ implies that \eqref{eq-0trans} is homogenizable, see Remark \ref{rem-4}.

\subsection{Background litteratures}
As mentioned above, the homogenisation of (\ref{ibvp})
is closely related to the homogenisation of the first order 
transport equations ${\partial}_t u+{\textbf{F}}\cdot \nabla u=0$ describing miscible flow in porous media \cite{Tassa}. 
One of the central questions  concerning  (\ref{eq-0trans}) is the strong convergence which is not true 
in general as the example of  equation (\ref{eq-0trans}) with ${\textbf{F}}(x_1, x_2, t)=(0, \sin x_1), d=2$ shows,  see \cite{DeGiorgi} page 176.
It is known, for instance,  that if
${\operatorname{div}} {\textbf{F}}=0$ (i.e. the case of unit integral density $\rho=1$) then the effective 
equation has arithmetic averages $(\int_{{\mathbb T}^2}F_1(x)dx, \int_{{\mathbb T}^2}F_2(x)dx)$ as the forcing velocity, 
whereas the shear field ${\textbf{F}}(x)={\textbf{a}} {\varphi}(x), {\textbf{a}}=(1,\gamma)\in {\mathbb R}^2$ yields harmonic averages, i.e.
in the homogenised equation the forcing velocity is ${\textbf{a}}\int_{{\mathbb T}^2}\frac{dx}{{\varphi}(x)}$.
The interested reader can find more on this problem in the works  \cite{Tassa}, \cite{Regis} and \cite{Dali} and the references therein.

\medskip

The homogenization of more general transport equations with divergence free vector fields \begin{equation}\label{gen-trnsp}
{\partial}_t u^{\varepsilon}+{\operatorname{div}}[{\textbf{a}}_{\varepsilon} f(u^{\varepsilon})]=0, \quad u^{\varepsilon}(x, 0)=U_0(x, x/{\varepsilon})
\end{equation}
under the assumption ${\textbf{a}} _{\varepsilon} ={\textbf{a}} (x, x/{\varepsilon})$ and ${\operatorname{div}}_x{\textbf{a}} (x, y)={\operatorname{div}}_y{\textbf{a}}(x, y)=0$, is studied in  \cite{Weinan}. 
The case when ${\textbf{a}}_{\varepsilon}={\textbf{a}}(x/{\varepsilon})$ is studied in \cite{Hou}. It is also shown that solutions of \eqref{gen-trnsp}
converge in $L^2$ and the limit equation is either a constant coefficient linear transport equation (ergodic case) 
or an infinite dimensional dynamical system, see  \cite{Weinan, Hou}.

In \cite{Tartar} Tartar studied some transport equations with memory effects. He addressed the question
of importance of considering the limit function rather than the equation it satisfies. The question he raised was
  whether the limit  retains, in some sense, the structure of linear transport equations (say, it is traveling wave solution).

Some of this questions were addressed by Tassa in \cite{Tassa}, in particular he showed that for shear flow 
$d=2$ the limit is 
a travelling wave (Theorems 4.2 and 4.5 in \cite{Tassa})as well as some convergence rates which depend on whether the 
rotation number is  
rational or irrational and the smoothness of the forcing vector field. In fact for rational rotation number (Theorem 4.5 in \cite{Tassa}) 
the limit is determined by some function $a_\eta$ see (3.13) in \cite{Tassa} and the limit function is a
traveling wave if $a_\eta=const$ for all $\eta\in [0,1]$.

It seems plausible that the techniques here can (partially)
 be applied to more general context involving random structure, i.e. stochastic differential equations.
  Similar type of problems, have been studied in recent works of Bardi-Cesaroni-Scotti  \cite{BCS}. 
  
 A further direction, that our approach might be possible to extend to, is that of multi-scale problems. More exactly,
 one may consider ${\bf F}$ that has both slow and fast variable ${\bf F} (x,x/{\varepsilon})$. A particular case of this was studied by 
 G. Menon \cite{Menon}, with ${\bf F} (x,x/{\varepsilon}) = \hbox{div} ({\bf K}(x) + {\varepsilon} {\bf A}(x/{\varepsilon}) ) $.
 

\subsection{A few standing assumptions}
The non-oscillating system (i.e. when ${\varepsilon}=1$)
\begin{eqnarray}\label{eq-00}
  {\displaystyle\frac{d{{x_i}}}{dt} }=F_i{\left(} x_1, \dots, x_d {\right)}
\end{eqnarray}
enjoys a number of remarkable properties.
Suppose that (\ref{eq-00}) has invariant measure $d\mu_x=\rho(x)dx$ with density  $\rho >0$; see Section \ref{inv} for details. 
For the two dimensional problem,  $d=2$,  Kolmogorov 
proved that if ${\textbf{F}}(x)=(F_1(x_1, x_2), F_2(x_1, x_2))\not =0$ is ${\mathbb Z}^2$ periodic and  analytic in $(x_1,x_2)$ 
variables, then there is an analytic transformation of coordinates 
$y={\textbf{f}}(x)$ such that (\ref{eq-00}) transforms into 
{\bf shear flow} system 
\begin{equation}\label{shear-eq-00}
{\displaystyle\frac{d{{y_i}}}{dt} }=\frac{a_i}{G(y_1, \dots, y_d)} 
\end{equation} 
with constants $a_1=1, a_2\in {\mathbb R}$ and $G$  being a  periodic scalar function.

In fact, 
$$\int_E G(y_1,y_2)dy_1y_2=\int_E \rho(x_1,x_2)dx_1dx_2,\quad  {\rm for\ measurable}\ E\subset {\mathbb R}^2$$ 
is now the 
integral invariant of the new system of differential equations \cite{Kolm53}. 
The constant  $\gamma=a_2$ is 
called the rotation number and the system (\ref{eq-00}) is ergodic if $\gamma$ is irrational \cite{Sinai}.

The main goal of this article is to analyse the behaviour of the solution 
${\textbf{X}}^{\varepsilon}(t)$ (to equation \eqref{ibvp})  as ${\varepsilon}\to 0$ under some conditions  imposed on the vector-field
${\textbf{F}}=(F_1, \dots, F_d )$.

We make the following standing assumptions about the vectorfield  ${\textbf{F}}:$
\begin{itemize}
\item[{\bf(F.1)}] ${\textbf{F}}:{\mathbb T}^d\to {\mathbb R}^d $ is continuous, $1$-periodic and there is a constant $L>0$ such that 
\begin{equation}
|{\textbf{F}}({\textbf{u}}_1)-  {\textbf{F}}({\textbf{u}}_2)|\leq L|{\textbf{u}}_1-{\textbf{u}}_2|, \quad \forall {\textbf{u}}_1, {\textbf{u}}_2 \in {\mathbb R}^d.
\end{equation}
\item[{\bf(F.2)}] For any compact $D\subset[0,\infty)\times{\mathbb R}^d$, there is a constant $\lambda=\lambda(D) >0$ such that 
 $\lambda\le F_i(t, {\textbf{u}})\leq \frac1\lambda, 1\le i\le d$ for all $(t, {\textbf{u}})\in D\subset  [0,\infty)\times{\mathbb R}^d $. 
\item[{\bf(F.3)}]  There is a  bounded function $\rho>0$ such that ${\operatorname{div}} (\rho {\textbf{F}})=0$. Here $\rho$ is called the density of invariant measure.

\end{itemize}

\subsection{The approach and methodology}

 De Giorgi's conjecture has (more or less)  been ignored completely. 
 Everyone, that has touched upon the homogenization of the transport problem, have ignored the fact that convergence of the underlying dynamical system would give the 
convergence of the transport problem.  Our result (read observation) should be seen in the light of  homogenization of the dynamical system,
 rather than the transport problem; even though this directly implies the convergence of the transport problem. 
The approach we have taken here is a combination of a few, already worked out, methods (originating in the work of Kolmogorov \cite{Kolm53}, and later Bogolyubov \cite{Bogolyubov} ). Indeed,  amalgamating   Kolmogorov's method (and its refinement due to Tassa \cite{Tassa}) and Bogolyubov's method
allows one to apply singular perturbation techniques to homogenisation problems for dynamical systems giving convergence rates. This has not been done to the best of our knowledge, and hence worth noticing.
Such a   composition of hybrid techniques-- of combining singular perturbations, dynamical systems and homogenisation--  
gives new insights and opens up for the study of convergence rates for similar problems. 

We also want to stress that although our result seems to be new,   it does not use any new technique, and most probably, if the problem were noticed by others, that have worked with the related transport problem, one should have done a similar observation.

\medskip

\subsection{Main results}
In order to specify  the rates of convergence it is convenient to introduce the nondecreasing function
\begin{equation}\label{delta}
\delta({\varepsilon})=\sup_{x\in D}\sup_{s\in[0,T]}
{\varepsilon}\left|\int_0^{s/{\varepsilon}}[G(\tau, x)-G^0(x)]d\tau\right|,
\end{equation}
where $G^0$ is the average defined by 

\begin{equation}\label{eq-def-G0}
G^0(y)=\lim_{\ell\to \infty}\frac1 \ell\int_0^\ell  G(s, y)ds
\end{equation}
if the limit above exists uniformly in $y$.
Note that if $G(t, x)$ is periodic in $t$ then the limit in \eqref{eq-def-G0} exists and, moreover,  
\begin{equation}\label{e-estimate}
\delta({\varepsilon})\sim {\varepsilon}.
\end{equation}
Indeed,  for periodic $G(s)$ we have that $G^0(s)=\int_0^1 G(s)ds=const$ and thus 
\begin{eqnarray*}
\int_0^\ell(G(s)-G^0)ds&=&\sum_{m=1}^{[\ell ]}\int_{m-1}^{m}(G(s)-G^0)ds+\int_{[\ell]}^\ell (G(s)-G^0)ds=\\\nonumber
&=&\int_{[\ell]}^\ell (G(s)-G^0)ds={\mathcal} O(1)
\end{eqnarray*}
where $[\ell]$ is the integer part of $\ell>0$. Substituting  $\ell=\frac s{\varepsilon}$ the result follows.

\medskip 

We formulate our main results below starting off the one dimensional problem.

\begin{theorem} ($d=1$)
 Let  $G:{\mathbb T}\times{\mathbb R}$ be positive Lipschitz continuous function in both variables $(t, x)\in {\mathbb T}\times{\mathbb R}$, $G(t, \cdot)$ is $1$-periodic in 
 $t$.
 Let $X^{\varepsilon}$ be the solution to
initial value problem
\begin{eqnarray}\label{eq-Th1}
 \left\{
\begin{array}{ccc}
{\displaystyle} {\displaystyle\frac{d{{X}}}{dt} }^{\varepsilon}=\frac1{ G{\left(} t, \frac{ X^{\varepsilon}}{\varepsilon} {\right)} }\\
X^{\varepsilon}(0)=p,
\end{array}
\right.
\end{eqnarray}
and  $\delta({\varepsilon})$ be as in \eqref{delta}.
Then there is a Lipschitz continuous  function $X^0(t)$ such that 
\begin{equation}\label{Th1-a}
| X^{\varepsilon}(t)-X^0(t)|\lesssim \delta({\varepsilon}), \quad t\in[0, T].
\end{equation}
Furthermore, if  $G(t, \eta)$ does not depend on $t$ and 
is almost periodic in $\eta$, then $X^0(t)=p_0+\beta t.$ 
\end{theorem}

In the proof of Theorem 1 we will use a simple version of Bogolyubov's method, 
tailored for the Cauchy problem ${\displaystyle\frac{d{{{\textbf{Y}}^{\varepsilon}}}}{dt} } ={\textbf{G}}{\left(}\frac t{\varepsilon} , {\textbf{Y}}^{\varepsilon}{\right)}$, ${\textbf{Y}}^{\varepsilon}(0)=p$, 
see   \cite{Bogolyubov} \S 26, \cite{Sanders} Lemma 4.3.1.

\medskip 

Now we dwell on the multidimensional problem
\begin{theorem}\label{thm-d-dim} ($d>1$)
\smallskip 
\begin{itemize}
\item[(a)] Let $d\ge 2$, ${\textbf{F}}=\frac {{\textbf{a}}}G$, with periodic scalar function $G$,  such that ${\textbf{F}}$ satisfies {\bf (F.1)-(F.3)}. 
Assume further  ${\textbf{a}}\in {\mathbb R}^n$ satisfyyies a Diophantine type condition
 \begin{eqnarray}\label{eq-dphnt}
|\langle {\textbf{a}}, {\textbf{m}}\rangle |\geq \frac {C}{|{\textbf{m}}|^{d+\kappa}},\quad \forall {\textbf{m}}\in {\mathbb Z}^d\setminus\{0\}
\end{eqnarray}
where $C$ and $\kappa$ are positive constants.
   If ${\textbf{X}}^{\varepsilon}$ is the solution to 
 Cauchy problem ${\displaystyle\frac{d{{{\textbf{X}}^{\varepsilon}}}}{dt} }=\frac{{\textbf{a}} }{G{\left(} \frac{{\textbf{X}}^{\varepsilon}}{\varepsilon}{\right)}}, {\textbf{X}}^{\varepsilon}(0)=p$  then 
$$\left|{{\textbf{X}}^{\varepsilon}(t)} -(p+{\textbf{a}} t)\right| \lesssim \delta({\varepsilon}) \leq C {\varepsilon},$$
where the last inequality follows from \eqref{e-estimate}.
 

\item[(b)] If $d=2$ and ${\textbf{F}}={\textbf{F}}({\textbf{X}})$ is independent of $t$ and ${\mathbb Z}^2$ periodic in ${\textbf{X}}$, {\bf (F1)-(F3)} hold and ${\textbf{X}}^{\varepsilon}$ solves the Cauchy problem 
\begin{eqnarray}\label{eq-Th2}
 \left\{
\begin{array}{ccc}
{\displaystyle} {\displaystyle\frac{d{{{\textbf{X}}}}}{dt} }^{\varepsilon}={\textbf{F}}{\left(} \frac{{\textbf{X}}^{\varepsilon}}{\varepsilon} {\right)} \\
{\textbf{X}}^{\varepsilon}(0)=p.
\end{array}
\right.
\end{eqnarray}
then  there is a linear function ${\textbf{X}}^0(t)=p+{\textbf{B}} t$ such that 
\begin{equation}\label{Th1-b}
|{\textbf{X}}^{\varepsilon}(t)-{\textbf{X}}^0(t)|\lesssim {\varepsilon}, \quad t\in[0, T].
\end{equation}

\end{itemize}
\end{theorem}

In the proof of Theorem 2 we shall employ Kolmogorov's theorem on coordinate transformation as in  \cite{Kolm53}, its 
refinement for $d=2$ as in \cite{Tassa} and generalisations for $d\ge 3$ as done \cite{Arn92}, \cite{Ko07}. 

\subsection{Invariant measure}\label{inv}
Suppose ${\textbf{F}}\in C^1$ is given and let $\rho$ be sought as the solution of Liouville's equation
${\operatorname{div}}(\rho{\textbf{F}})=0$. Let $\tau=x_d, x'=(x_1, x_2, \dots, x_{d-1}, 0)$ and assume that $F_d>0$ then Liouville's equation can be rewritten as follows
$$\partial_\tau\log \rho+\nabla_{x'}\log\rho\cdot \frac{{\textbf{F}}'}{F_d}=-\frac{{\operatorname{div}} {\textbf{F}}}{F_d}$$
where ${\textbf{F}}'=(F_1, \dots, F_{d-1}, 0)$.
We can specify initial condition at time $\tau=0$, i.e. $x_d=0$ and then by  \cite{Lions} (Proposition II.1 and Remark afterwards)  
there is $L^\infty$ solution 
of this Cauchy problem in ${\mathbb R}^d\times[0, \infty)$, provided that ${\textbf{F}}\in C^{0,1}$ and so is the initial data at $\tau=0$.

\medskip 
\section{Proof of Theorem 1}

Lemma to follow is the  scaled  version of  one dimensions Bogolyubov's estimate.
\begin{lemma}\label{lem-tech}
Let $X^{\varepsilon}(t)$ be the solution of the Cauchy problem 
${\displaystyle\frac{d{{\Theta}}}{dt} }^{\varepsilon}(t)=G{\left(} \frac t{\varepsilon}, \Theta^{\varepsilon}(t){\right)}$, $\Theta^{\varepsilon}(0)=X_0$. Suppose that the following limit 
$$G^0(y)=\lim_{\ell\to \infty}\frac1 \ell\int_0^\ell  G(s, y)ds$$
exists uniformly in $y\in D$ for some compact $D\subset {\mathbb R}$
and the Cauchy problem ${\displaystyle\frac{d{{\Theta_0}}}{dt} }= G^0(\Theta^0), \Theta^0(0)=X_0$
has a unique solution  on the finite interval $[0, T_1]$ then 
\begin{equation}\label{rate-1}
| \Theta^{\varepsilon}-\Theta^0 |\le \delta({\varepsilon}) ,
\end{equation}
 as ${\varepsilon}\to 0$ on $0\leq t \leq T$ and $\delta({\varepsilon})$ is given by (\ref{delta}).

\end{lemma}

\begin{proof}
We use  Bogolyubov's estimate for the slowly varying systems which is valid on the time 
intervals of length $\sim \frac1{\varepsilon}$.
Define $\xi^{\varepsilon}(t)={\Theta^{\varepsilon}({\varepsilon} t)}$ 
then we have 
\begin{eqnarray}
\left\{
\begin{array}{ccc}
{\displaystyle} {\displaystyle\frac{d{{\xi}}}{dt} }^{\varepsilon}= {\varepsilon} G{\left(} t, {\xi^{\varepsilon}} {\right)} \\
\xi^{\varepsilon}(0)=X_0.
\end{array}
\right.
\end{eqnarray}
Furthermore, let $\xi^0(t)$ solve 
\begin{eqnarray}
\left\{
\begin{array}{ccc}
{\displaystyle} {\displaystyle\frac{d{{\xi}}}{dt} }^0= {\varepsilon} G^0{\left(} {\xi^0} {\right)} \\
\xi^0(0)=X_0 .
\end{array}
\right.
\end{eqnarray} 
Applying Bogolyubov's estimate,  \cite{Bogolyubov} \S 26, \cite{Sanders} Lemma 4.3.1 to 
$\xi^{\varepsilon}, \xi^0$ we have that 
$|\xi^{\varepsilon}(t)-\xi^0(t)|\leq \triangle({\varepsilon}, T)$ where 

\begin{equation}\label{eq-Bog}
\triangle({\varepsilon}, T)=\sup_{x\in D}\sup_{0\le{\varepsilon} t\le T}
{\varepsilon}\left|\int_0^{t}[G(\tau, x)-G^0(x)]d\tau\right|.
\end{equation}
After setting $\Theta^0({\varepsilon} t)=\xi^0(t)$, substituting ${\varepsilon} t =s$ in \eqref{eq-Bog}  and recalling \eqref{delta} the result follows.
 \end{proof}

\medskip 

Let us  denote $F(t, u)=\frac1{G(u, t)}>0$ then $F$  satisfies {\bf (F.1)}-{\bf (F.3)}. Let $X^{\varepsilon}$ be the solution to the 
initial value problem ${\displaystyle\frac{d{{ X^{\varepsilon}}}}{dt} }=F(t, X^{\varepsilon}/{\varepsilon}), X^{\varepsilon}(0)=p$.  
Clearly $0< {\displaystyle\frac{d{{X^{\varepsilon}}}}{dt} }\le \sup\limits_{\mathbb R} F<\infty$ and therefore $\{X^{\varepsilon}\}$ is uniformly Lipschitz continuous on any 
finite interval $[0, T]$. Furthermore, $X^{\varepsilon}$ is strictly monotone because  $F>0$. 
Thus $X^{\varepsilon}$ has inverse which we denote by 
$h^{\varepsilon}$,
 \begin{equation}\label{X-inv}
\xi = X^\varepsilon (h(\xi)).
\end{equation}

Rewriting the system for $h^{\varepsilon}$ we have
$$
\frac1{\frac{d h^{\varepsilon}}{d\xi }}=F(h^{\varepsilon}(\xi), \xi/{\varepsilon})\qquad \Rightarrow \qquad {\frac{d h^{\varepsilon}}{d\xi }}=\frac1{F(h^{\varepsilon}(\xi),\xi/{\varepsilon})}.
$$
As for the initial condition, we have   $h^{\varepsilon}(p)=0$.

Recalling $G(\tau, y)=\frac1{F(y,\tau)}$ we infer from Lemma \ref{lem-tech} that $h^{\varepsilon}\to h^0$ locally uniformly on 
$[0, \infty)$ and the homogenised equation is $\frac{dh^0}{d\xi}=G^0(h^0)$
where $$G^0(y)=\lim_{T\to \infty}\frac1 T\int_0^T\frac{d\xi}{F(y, \xi)}.$$

Returning to $X^{\varepsilon}$ and using the refined convergence rate (\ref{rate-1}) for periodic $F$, we note that by \eqref{X-inv}
\begin{eqnarray}
\xi &=&X^{\varepsilon}(h^{\varepsilon}(\xi))=X^{\varepsilon}([h^{\varepsilon}-h^0]+h^0)\\\nonumber
&=&X^{\varepsilon}({\mathcal} O(\delta({\varepsilon}))+h^0(\xi))
\end{eqnarray}
implying that $X^{\varepsilon}$ converges uniformly to $X^0(t)$, determined by the implicit equation $\xi=X^0(h^0(\xi))$.
Indeed, from the identity
$\xi=X^{\varepsilon}({\mathcal} O(\delta({\varepsilon}))+h^0(\xi))=[X^{\varepsilon}({\mathcal} O(\delta({\varepsilon}))+h^0(\xi))-X^{\varepsilon}(h^0(\xi))]+X^{\varepsilon}(h^0(\xi))$ we get that 
$$|X^{\varepsilon}(h^0(\xi))-\xi|=|X^{\varepsilon}({\mathcal} O(\delta({\varepsilon}))+h^0(\xi))-X^{\varepsilon}(h^0(\xi))|={\mathcal} O(\delta({\varepsilon}))$$
in view of the uniform Lipschitz continuity of $X^{\varepsilon}$. Thus we get the pointwise convergence rate 
\begin{equation}\label{point-conv}
\left|X^{\varepsilon}(t)-X^0(t)
\right|\lesssim {\mathcal} O(\delta({\varepsilon})).
\end{equation}

\medskip 

\section{Multi-dimensional problem: Proof of Theorem 2 (a)}

\subsection{Change of variables for $d\ge 3$} Let $d\mu=\rho dx $ be the invariant measure of the system ${\displaystyle\frac{d{{{\textbf{Y}}}}}{dt} }={\textbf{F}}({\textbf{Y}})$ and introduce the following numbers
\begin{eqnarray}\label{char-nmbr}
a_i=\frac{\int\limits_{{\mathbb T}^d}\rho F_i} {\int\limits_{{\mathbb T}^d} \rho}, \qquad 1\le i\le d ,
\end{eqnarray}
where ${\textbf{F}}=(F_1, \dots, F_d)$ is the vectorfield on the right hand side of the  equation
(\ref{eq-00}).		

\smallskip 

For $d\ge 3$ Kolmogorov's theorem has been   generalized by Kozlov as follows, see \cite{Ko07}, Theorem $1^\prime$.

\begin{proposition}
There exists a change of variables transforming ${\displaystyle\frac{d{{\bf Y}}}{dt} }=\bf F(\bf Y)$ into 
\begin{eqnarray}\label{shear-00}
 {\displaystyle\frac{d{{w_j}}}{dt} }=C\frac{a_j}{G(w_1, \dots, w_d)}, \qquad j=1, \dots, N
\end{eqnarray}
with invariant measure $d\mu_w=\frac{dw}{G(w_1, \dots, w_d)}$ and some constant $C\not=0$.
Furthermore,  if ${\textbf{a}}=(a_1, \dots, a_d)$ is diophantine
then there exists a transformation into the constant coefficient system
${\displaystyle\frac{d{{w_j}}}{dt} }=a_j$.
\end{proposition}

\smallskip

Employing  Kozlov's theorem one can  reduce the system ${\displaystyle\frac{d{{\bf Y}}}{dt} }=\bf F(\bf Y)$  to (\ref{shear-00}).

\medskip 

\subsection{Proof of Theorem 1 }

We recapitulate Theorem 1  as follows.

\begin{lemma}[\bf Shear flow]\label{lem-shear}
Suppose ${\displaystyle\frac{d{{{\textbf{z}}^{\varepsilon}}}}{dt} }=\frac{{\textbf{a}}}{G{\left(}{{\textbf{z}}^{\varepsilon}}/{\varepsilon} {\right)}}$, ${\textbf{a}}=(a_1, \dots, a_d)\in {\mathbb R}^d$
and $\frac{{\textbf{a}}}{G}$ satisfies ({{\textbf{F}}.1})-({{\textbf{F}}.3}).
If ${\textbf{a}}$ is Diophantine then 
 $|{\textbf{z}}^{\varepsilon}(t)-{\textbf{z}}^0(t)|\lesssim {\varepsilon}$, for $t\in[0, T]$ where ${\textbf{z}}^0(t)={\textbf{a}} t+p$.
\end{lemma}

\begin{proof}
We shall use the coordinate transformation introduced in \cite{Ko07} Theorem 2: if  ${\textbf{u}}(t)$ solves the 
shear system ${\displaystyle\frac{d{{{\textbf{u}}}}}{dt} }=\frac{{\textbf{q}}}{G({\textbf{u}})}$ with diophantine ${\textbf{q}}$ then the mapping given by 
the equations
\begin{equation*}
w_j=u_j+\frac{q_j}{{\mathcal M(G)}}f(u_1, \dots, u_d), \qquad 1\le j\le d
\end{equation*}
transforms the equation into 
$${\displaystyle\frac{d{{w_j}}}{dt} }=q_j$$
see \cite{Ko07} page 197. Here $\mathcal M(G)=\fint\limits_{{\mathbb T}^d}G$ is the mean value of $G$ and $f$ is determined from the 
first order differential equation
$$\langle \nabla f, {\textbf{q}}\rangle=G-\mathcal M(G).$$ 
If fact, this mapping is non degenerate (i.e. has nontrivial Jacobian) 
and one-to-one. 

Taking ${\varepsilon} {\textbf{u}}= {\textbf{z}}$ we see that 
$${\displaystyle\frac{d{{{\textbf{u}}}}}{dt} }=\frac{{\textbf{q}}}{G({\textbf{u}})}$$ 
with ${\textbf{q}}=\frac{{\textbf{a}}}{\varepsilon}$. 
From Fourier's expansion we have
$$G(u)-\mathcal M(G)=\sum\limits_{m\in{\mathbb Z}^d\setminus\{0\}}G_me^{2\pi i\langle m, u\rangle}$$ 
which by integration gives 
$$f(u)={\varepsilon} \sum\limits_{m\in{\mathbb Z}^d\setminus\{0\}}\frac{G_m}{2\pi i\langle m, {\textbf{a}}\rangle }e^{2\pi i\langle m, u\rangle} ,$$
and  the series is convergent,  due  to the assumption that ${\textbf{a}} $ is Diophantine (see \eqref{eq-dphnt}). Notice that 
the sum is bounded because $\frac 1G$ satisfies the assumptions $\bf (F.1)-(F.3)$. 
Summarizing we have 
\begin{eqnarray*}
\frac{a_j}{\varepsilon} t+w^{\varepsilon}_j(0)=q_j t+w^{\varepsilon}_j(0) &=&\\
w^{\varepsilon}_j(t)
&=&
\frac{z_j^{\varepsilon}(t)}{\varepsilon}+ \left\{\frac{a_j}{\varepsilon} \frac1{\mathcal M(G)}\right\} {\varepsilon} \sum\limits_{m\in{\mathbb Z}^d\setminus\{0\}}\frac{G_m}{2\pi i\langle m, {\textbf{a}}\rangle }e^{2\pi i\langle m, u\rangle}\\
&=&\frac{z_j^{\varepsilon}(t)}{\varepsilon}+ \frac{a_j}{\mathcal M(G)}\sum\limits_{m\in{\mathbb Z}^d\setminus\{0\}}\frac{G_m}{2\pi i\langle m, {\textbf{a}}\rangle }e^{2\pi i\langle m, u\rangle} ,
\end{eqnarray*}
implying 
$a_jt+p_j-z_j^{\varepsilon}(t)={\mathcal} O({\varepsilon})$
and the proof follows.
\end{proof}

\medskip 

\begin{remark}\label{rem-4}
Peirone showed that if ${\textbf{F}}\in C^1({\mathbb T}^d)$ is ${\mathbb Z}^d$ periodic, $u_0\in C^1$  and the limit $\lim\limits_{t\to \infty} \frac{S^t_{{\textbf{F}}}(x)}{t}$ exists 
for a.e. $x\in{\mathbb T}^d$  then the problem 
(\ref{eq-0trans}), is homogenizable, \cite{Peirone} Lemma 2.2 (b).
Here $S_{{\textbf{F}}}^t$ is the semigroup generated by (\ref{eq-00}).
Our result establishes the converse of this statement for homogenizable (\ref{eq-0trans}).
\end{remark}

\section{Proof of Theorem 2(b)}

Our goal here is to apply Kolmogorov's coordinate transformation in order to reduce the general problem to shear flow.
Tassa \cite{Tassa} found an explicit formula for this that we will write below. 
We should point out that Kolmogorov's proof in \cite{Kolm53} is not constructive.   

It is convenient to introduce some basic facts about the equation ${\displaystyle\frac{d{{\bf X}}}{dt} }={\textbf{F}}({\textbf{X}})$ with ${\textbf{F}}$ satisfying the 
properties ({\bf F.1})-({\bf F3}). Let $d\mu=\rho dx$ be the invariant measure corresponding to this system, 
then by definition ${\operatorname{div}}(\rho {\textbf{F}})=0$. Thus the vectorfield ${\textbf{b}}=(b_1,b_2)=\rho{\textbf{F}}$
is divergence free. This yields that  the integral $\int_0^1 b_1(x_1,x_2)dx_2$ is constant since
\begin{eqnarray}
{\partial}_{x_1}\int_0^1 b_1(x_1,x_2)dx_2&=&\int_0^1{\partial}_{x_1} b_1(x_1,x_2)dx_2\\\nonumber
&=&
-\int_0^1 {\partial}_{x_2}b_2(x_1,x_2)dx_2\\\nonumber
&=&-[b_2(x_1,1)-b_2(x_1,0)]=0.
\end{eqnarray}
Similarly we have that $\int_0^1 b_2(x_1,x_2)dx_1$ is constant. Denote
${\overline}{b_1}=\int_0^1 b_1(x_1,x_2)dx_2, $ ${\overline}{b_2}=\int_0^1 b_2(x_1,x_2)dx_1$ (which are 
the mean integrals of $b_1, b_2$ over ${\mathbb T}^2$ scone they are constants) and set
\begin{eqnarray}\label{y-coord}
\begin{array}{lll}
\displaystyle y_1=f_1(x_1,x_2)=\frac1{{\overline}{b_2}}\int_0^{x_1}b_2(\xi,0)d\xi\\
\vspace{-0.3cm}\\
\displaystyle y_2=f_2(x_1,x_2)=\frac1{{\overline}{b_1}}\int_0^{x_2}b_1(x_1,\xi)d\xi.
\end{array}
\end{eqnarray}
It is shown in \cite{Tassa} that in the new coordinate system we get the 
shear flow
 ${\displaystyle\frac{d{{{\textbf{y}}}}}{dt} }=\frac{{\textbf{a}}}{G({\textbf{y}})}$ with ${\textbf{a}}=(1,\gamma)$,  where $\gamma$ is   the
rotation number, see  \cite{Sinai}. Furthermore, we have that 
$$\left|\frac{{\partial}( y_1, y_2)}{{\partial}( x_1, x_2)}\right|=\frac{b_1(x_1, x_2)}{{\overline}{b_1}} \frac{b_2(x_1,0)}{{\overline}{b_2}}\not=0, \quad \forall x\in {\mathbb T}^2$$
and the invariant measure density is 
\begin{equation}
\frac1{G(y)}=\frac{b_2(g_1(y),0)}{{\overline} {b_2}}F_1(g_1(y), g_2(y))
\end{equation}
with ${\textbf{g}}=(g_1, g_2)$ being the inverse of ${\textbf{f}}=(f_1, f_2)$, see \cite{Tassa}, page 1395.   

\medskip

In order to take advantage of (\ref{y-coord}) we introduce the function ${\textbf{z}}^{\varepsilon}(t)={\textbf{X}}^{\varepsilon}(t)/{\varepsilon}$. Then ${\textbf{z}}^{\varepsilon}(t)$ solves the Cauchy problem 
${\displaystyle\frac{d{{\bf z^{\varepsilon}}}}{dt} }=\frac{{\textbf{F}}({\textbf{z}}^{\varepsilon})}{\varepsilon}$,  ${\textbf{z}}^{\varepsilon}({0})=\frac p{\varepsilon}$. Clearly, the invariant measure now is  
$d\mu_z=\frac1{\varepsilon}\rho dz$ and ${\textbf{b}}^{\varepsilon}=(\frac{b_1}{\varepsilon},\frac{b_2}{\varepsilon})$ is divergence free. Note that 
$\frac{b_i}{{\overline}{b_i}}=\frac{b_i^{\varepsilon}}{{\overline}{b_i^{\varepsilon}}}$ and therefore applying the change of variables 
$y={\textbf{f}}(z)$, with mapping ${\textbf{f}}$ given by (\ref{y-coord}) we obtain the shear flow
\begin{equation}
{\displaystyle\frac{d{{{\textbf{y}}^{\varepsilon}}}}{dt} }={\textbf{a}} \frac{b_2(g_1({\textbf{y}}^{\varepsilon}), 0)}{{\overline}{b_2}}\frac{F_1({\textbf{g}}({\textbf{y}}^{\varepsilon}))}{\varepsilon}.
\end{equation}

In order to get rid of the ${\varepsilon}$ in the denominator  we set ${\textbf{w}}^{\varepsilon}(t)={\varepsilon} {\textbf{y}}^{\varepsilon}(t)$. Then ${\textbf{w}}^{\varepsilon}(t)$ solves the equation 
\begin{equation}
{\displaystyle\frac{d{{{\textbf{w}}^{\varepsilon}}}}{dt} }={\textbf{a}} \frac{b_2(g_1({\textbf{w}}^{\varepsilon}/{\varepsilon}), 0)}{{\overline}{b_2}} {F_1({\textbf{g}}({\textbf{w}}^{\varepsilon}/{\varepsilon}))}.
\end{equation} 

By \eqref{y-coord} we have that 
\begin{eqnarray*}
f_1(x_1+1, x_2)&=&f_1(x_1, x_2)+1,\\\nonumber
 f_1(x_1, x_2+1)&=&f_1(x_1, x_2)
\end{eqnarray*}
and similarly 
\begin{eqnarray*}
f_2(x_1+1, x_2)&=&f_2(x_1, x_2),\\\nonumber
 f_2(x_1, x_2+1)&=&f_2(x_1, x_2)
\end{eqnarray*}
in view of the periodicity of ${\textbf{b}}$.  
Consequently if ${\textbf{e}}_i, 1\le i\le 2$ is the unit vector in the canonical basis of ${\mathbb R}^2$ then this translates to the 
inverse of ${\textbf{f}}$, namely we have  $g_j(\eta+{\textbf{e}}_i)=g_j(\eta)+M_{ij}, 1\le i,j\le 2$
where $M_{ij}\in {\mathbb Z}$, see \cite{Tassa}  equation  (2.5). 
This yields that $\frac1{G(\eta)}=\frac{b_2(g_1(\eta), 0)}{{\overline}{b_2}}{F_1({\textbf{g}}(\eta))}$ is periodic 
function and ${\textbf{w}}^{\varepsilon}$ solves the Cauchy problem 
\begin{equation}
{\displaystyle\frac{d{{{\textbf{w}}^{\varepsilon}}}}{dt} }=\frac{{\textbf{a}}} {G{\left(}\frac{{\textbf{w}}^{\varepsilon}}{\varepsilon}{\right)}}, \quad  {\textbf{w}}^{\varepsilon}(0)={\varepsilon} {\textbf{f}}{\left(} \frac{{\textbf{x}}^{\varepsilon}(0)}{\varepsilon}{\right)}.
\end{equation}
From here, in light of  (\ref{y-coord}) we have 
\begin{eqnarray}
w_1^{\varepsilon}(t)&=&\frac{\varepsilon}{{\overline}{b_2}}\int_0^{z_1^{\varepsilon}(t)}b_2(\xi, 0)d\xi=\frac{\varepsilon}{{\overline}{b_2}}\int_0^{x_1^{\varepsilon}(t)/{\varepsilon}}b_2(\xi, 0)d\xi\\\nonumber
&=&\frac{x_1^{\varepsilon}(t)}{{\overline}{b_2}}\left\{\frac1{x_1^{\varepsilon}(t)/{\varepsilon}}\int_0^{x_1^{\varepsilon}(t)/{\varepsilon}}b_2(\xi, 0)d\xi\right\}.
\end{eqnarray}
Because $b_i$ are periodic it follows that  $\lim\limits_{\ell \to\infty}\frac1{\ell}\int_0^\ell b_2(\xi, 0)d\xi={\overline}{b_2}$.
Furthermore, it follows that 
$$\left| \frac1{\ell}\int_0^\ell b_2(\xi, 0)d\xi-{\overline}{b_2}\right|\leq \frac C\ell $$
for  ${\textbf{b}}$ is periodic, see  \eqref{e-estimate} and its proof.

 Hence we conclude that 
\begin{equation}\label{x1-asym}
w_1^{\varepsilon}(t)=x_1^{\varepsilon}(t)+{\mathcal} O{\left(} \frac{\varepsilon}{x_1^{\varepsilon}(t)}{\right)}, \quad t\in [0, T]
\end{equation}
for any finite $T>0$.
In particular for the initial condition we get 
that $w_1^{\varepsilon}(0)=p_1+{\mathcal} O({\varepsilon})$.
As for the asymptotic expansion of $w_2^{\varepsilon}$ then we need to use a well-known fact that 
there is a scalar function ${\varphi}$ such that ${\textbf{b}}=({\partial}_2{\varphi}, -{\partial}_1{\varphi})$ for any 
two dimensional divergence free vector field ${\textbf{b}}$. From this equation ${\varphi}$  
is determined as  periodic modulo a linear function, i.e. there is ${\textbf{q}}\in {\mathbb R}^2$ and a constant $q_0$ such that 
${\varphi}(x)=\psi(x)+{\textbf{q}}\cdot x+q_0$ where $\psi$ is periodic. Using this fact we compute
\begin{eqnarray*}
w_2^{\varepsilon}(t)&=&\frac{\varepsilon}{{\overline}{b_1}}\int_0^{z_2^{\varepsilon}(t)}b_1{\left(} \frac{x_1^{\varepsilon}}{\varepsilon}, \xi {\right)} d\xi =\frac{\varepsilon}{{\overline}{b_1}}\int_0^{x_2^{\varepsilon}(t)/{\varepsilon}}b_1{\left(} \frac{x_1^{\varepsilon}}{\varepsilon}, \xi{\right)} d\xi\\
&=& \frac{\varepsilon}{{\overline}{b_1}}\int_0^{x_2^{\varepsilon}(t)/{\varepsilon}}\left[b_1{\left(} \frac{x_1^{\varepsilon}}{\varepsilon}, \xi{\right)} -b_1(0, \xi)\right]d\xi+\frac{\varepsilon}{{\overline}{b_1}}\int_0^{x_2^{\varepsilon}(t)/{\varepsilon}}b_1{\left(} 0, \xi{\right)} d\xi\\
&=&  \frac{\varepsilon}{{\overline}{b_1}} \left[\psi {\left(} \frac{x_1^{\varepsilon}}{\varepsilon}, \frac{x_2^{\varepsilon}}{\varepsilon}{\right)} -\psi {\left(} 0, \frac{x_2^{\varepsilon}}{\varepsilon}{\right)} +q_1\frac{x_1^{\varepsilon}}{\varepsilon}\right]
+\frac{\varepsilon}{{\overline}{b_1}}\int_0^{x_2^{\varepsilon}(t)/{\varepsilon}}b_1{\left(} 0, \xi{\right)} d\xi\\
&=& {\mathcal} O({\varepsilon} )+x_1^{\varepsilon}(t)\frac{q_1}{{\overline}{b_1}}
+\frac{\varepsilon}{{\overline}{b_1}}\int_0^{x_2^{\varepsilon}(t)/{\varepsilon}}b_1{\left(} 0, \xi{\right)} d\xi\\
&=&{\mathcal} O({\varepsilon})+x_1^{\varepsilon}(t)\frac{q_1}{{\overline}{b_1}}+x_2^{\varepsilon}(t)+{\mathcal} O{\left(} \frac{\varepsilon}{x_2^{\varepsilon}(t)}{\right)} 
\end{eqnarray*}
where the last line follows as in (\ref{x1-asym}), or integrating by parts and using ${\textbf{b}}=({\partial}_2{\varphi}, -{\partial}_1{\varphi})$.
In particular, at $t=0$ we have that $w_2^{\varepsilon}(0)=\frac{q_1}{{\overline}{b_1}}p_1+p_2+{\mathcal} O({\varepsilon} )$.

Summarizing, we see that ${\textbf{w}}^{\varepsilon}$ solves the following Cauchy problem
\begin{equation*}
{\displaystyle\frac{d{{{\textbf{w}}^{\varepsilon}}}}{dt} }=\frac{{\textbf{a}}}{G{\left(}\frac{{\textbf{w}}^{\varepsilon}}{\varepsilon}{\right)}}, \qquad  {\textbf{w}}^{\varepsilon}(0)={\left(} p_1+{\mathcal} O({\varepsilon}), \frac{q_1}{{\overline}{b_1}}p_1+p_2+{\mathcal} O({\varepsilon}){\right)}.
\end{equation*}

By Lemma \ref{lem-shear}, there is a linear function ${\textbf{w}}^0$ such that 
$|{\textbf{w}}^{\varepsilon}(t)-{\textbf{w}}^0(t)|\lesssim\delta({\varepsilon}), t\in[0, T]$. 
Then $|x_1^{\varepsilon}(t)-w_1^0(t)|\leq {\mathcal} O(\delta({\varepsilon})) +{\mathcal} O{\left(} \frac{\varepsilon}{x_1^{\varepsilon}(t)}{\right)}.$ 
Finally for $x_2^{\varepsilon}$ we have
\begin{eqnarray*}
w_2^{\varepsilon} - w_2^0&=&x_2^{\varepsilon}+x_1^{\varepsilon}\frac{q_1}{{\overline}{b_1}}+{\mathcal} O({\varepsilon})+{\mathcal} O{\left(} \frac{\varepsilon}{x_2^{\varepsilon}(t)} {\right)}- w_2^0\\
  &=&\left[x_2^{\varepsilon}-w_2^0+w_1^0\frac{q_1}{{\overline}{b_1} }\right]+(x_1^{\varepsilon}-w_1^0)\frac{q_1}{{\overline}{b_1} }+{\mathcal} O({\varepsilon})+{\mathcal} O{\left(} \frac{\varepsilon}{x_2^{\varepsilon}(t)}{\right)}
 
 
\end{eqnarray*}
and consequently we infer the estimate 
\begin{equation*}
\left| x_2^{\varepsilon}-w_2^0+w_1^0\frac{q_1}{{\overline}{b_1}} \right|\leq \frac{q_1}{{\overline}{b_1}}  \left[{\mathcal} O({\varepsilon})
+{\mathcal} O{\left(} \frac{\varepsilon}{x_1^{\varepsilon}(t)}{\right)}\right]  +  {\mathcal} O({\varepsilon})+{\mathcal} O{\left(}   \frac{\varepsilon}{|x_1^{\varepsilon}(t)| } + \frac{\varepsilon}{|x_2^{\varepsilon}(t)|}  {\right)}.
\end{equation*}

\medskip

\section{Examples}
\noindent
{\bf Example 1:}
Let ${\textbf{F}}$ be 1-periodic vector filed such that $F_2=1$ and 
$$ F_1(x_1, x_2)=F_1(x_1)=\left\{ 
\begin{array}{ll}
1 &\qquad  0<x_1 \leq 1/2 ,\cr
0 &\qquad   1/2 < x_1 \leq 1.
\end{array}
\right.
$$ 
Let $y^{\varepsilon}(t)$ be the solution to the following initial value problem
$$
 \left\{ 
\begin{array}{ll}
{\displaystyle\frac{d{{y^{\varepsilon}}}}{dt} } ={\textbf{F}}{\left(} \frac{y^{\varepsilon}}{\varepsilon} {\right)},\cr
y^{\varepsilon}(0)=p. 
\end{array}
\right.
$$
Consider the $\frac{\varepsilon}{2\sqrt{2}}$-strip of the line $p+s(2,1)$, i.e. $S_{\varepsilon}=\{x\in {\mathbb R}^n: |x-[p+s(2,1)]|\le \frac{\varepsilon}{2\sqrt{2}}, s\ge 0\}$.
Thus as ${\varepsilon}\to 0$ the trajectory (i.e. the set of points) converges to the line $\ell(s)=p+s(2,1), s\ge 0$ in Hausdorff distance.
Hence the trajectory of the limit is the line $\ell(s)$.
As for the speed of the convergence, we note first that by definition $y^{\varepsilon}_2=1$ and it is enough to study the ode
${\displaystyle\frac{d{z}}{dt} }=F_1(z/{\varepsilon})$. Multiplying both sides of this equation by ${\displaystyle\frac{d{{z^{\varepsilon}}}}{dt} }$ and integrating 
we obtain that 
\begin{eqnarray*}
\int_{0}^s\left|{\displaystyle\frac{d{{z^{\varepsilon}(t)}}}{dt} }\right|^2dt=\int_0^s F_1 {\left(} \frac{z^{\varepsilon}(t)}{\varepsilon}  {\right)} {\displaystyle\frac{d{{z^{\varepsilon}(t)}}}{dt} }dt=qs+{\mathcal} O({\varepsilon})
\end{eqnarray*}
where $q=\fint_{[0, 1]}F_1=\frac12$. Since $\left|{\displaystyle\frac{d{{z^{\varepsilon}(t)}}}{dt} }\right|\leq \sup F_1$ we have from Lebesgue dominated 
 convergence theorem 
 \begin{eqnarray*}
\int_{0}^s \left|{\displaystyle\frac{d{{z^0(t)}}}{dt} }\right|^2dt=\frac s2,
\end{eqnarray*}
and after differentiation $\left|{\displaystyle\frac{d{{z^0(t)}}}{dt} }\right|=\sqrt{ \frac12}$. 

The astute reader has probably noticed that we did not use condition $\bf F.3$ here, but could still obtain a convergence rate. This is due to the one-dimensional character of the problem, since $F_2=1$ here.

 

\medskip

{\bf Example 2:}\ Another example is given by $F$ with  saw-like graph
\begin{eqnarray}
F(\tau)=\left\{
\begin{array}{ccc}
\frac{2h\tau}a +\sigma& {\rm if} \ \tau\in [0, \frac a2)\\
\frac{2h}a(a-\tau)  +\sigma& {\rm if}\ \tau\in[\frac a2, a)
\end{array}
\right.
\end{eqnarray}
periodically extended over ${\mathbb R}$, see Figure 1. Here $a>0$ is the periodicity of $F$
and $h=\max F$ is the pick of $F$. We can solve this equations explicitly: 
indeed we have that
\begin{eqnarray*}
{\displaystyle\frac{d{{y^{\varepsilon}}}}{dt} }=\left\{
\begin{array}{ccc}
\frac{2h}a(\frac{y^{\varepsilon}}{\varepsilon}-ka) +\sigma& {\rm if} \ \frac{y^{\varepsilon}}{\varepsilon} \in ak+[0, \frac a2)\\
\frac{2h}a(a(k+1)-\frac{y^{\varepsilon}}{\varepsilon})  +\sigma& {\rm if}\ \frac{y^{\varepsilon}}{\varepsilon} \in ak+[\frac a2, a)
\end{array}
\right.
\end{eqnarray*}
After integration one gets
\begin{eqnarray*}
{y^{\varepsilon}}=\left\{
\begin{array}{lll}
C_-(k)e^{\frac{2ht}{{\varepsilon} a}}+{\varepsilon} ka -\frac{a\sigma{\varepsilon}}{2h}& {\rm if} \ {y^{\varepsilon}} \in {\varepsilon} ak+[0, \frac{ a{\varepsilon}}2)\\
C_+(k)e^{-\frac{2ht}{{\varepsilon} a}}+{\varepsilon} (k+1)a -\frac{a\sigma{\varepsilon}}{2h}& {\rm if} \ {y^{\varepsilon}} \in {\varepsilon} ak+[\frac{ a{\varepsilon}}2, a{\varepsilon})
\end{array}
\right.
\end{eqnarray*}
with some constants $C_\pm(k)$ and $k\in {\mathbb Z}$. 
Clearly this solution $y^{\varepsilon}$ is monotone and hence the argument above works.
Obviously $\frac1a\int_0^a\frac{d\tau}{ F(\tau)}=\frac a h\log{\left(} \frac{ h+\sigma}{\sigma} {\right)}\equiv\beta$ and therefore we infer that 
$y^{\varepsilon}$ converges uniformly to $y^0(t)=p+\frac t{\beta}$ on any finite closed interval $[0, T]$.

 \begin{center}
 \begin{figure}
 \begin{tikzpicture}[scale=1.5]
  
      
  
    
\draw (-1,0.3) -- (-0.5,3) --(0,0.3) --(0.5,3) -- (1,0.3) -- (1.5,3) -- (2,0.3) -- (2.5,3) -- (3,0.3) --(3.5,3);

  \draw[style=help lines] (-1,0) grid (3.9,3.9)
       [step=0.25cm]      (1,2) 
       ;

  \draw[->] (-0.2,0) -- (4,0) node[right] {$\tau$};
  \draw[->] (0,-0.2) -- (0,4) node[above] {$F(\tau)$};

  \foreach \x/\xtext in {-1/-1,1/1, 
  2/2, 3/3}
    \draw[shift={(\x,0)}] (0pt,2pt) -- (0pt,-2pt) node[below] {$\xtext$};

  \foreach \y/\ytext in { 0/0, 1/1, 2/2, 
  3/3}    
    \draw[shift={(0,\y)}] (2pt,0pt) -- (-2pt,0pt) node[left] {$\ytext$};

 
 \end{tikzpicture}
 \caption{In this example $a=1, h=3$}
 \end{figure}
 \end{center}
\medskip 
 

 \noindent
 {\bf Example 3:} Theorem 1 is still valid if the periodicity of $G(t, \cdot)$  is 
 replaced with almost periodicity in $t$ because all we needed in the proof was the convergence 
 rate for $G^0$. In this case one may get weaker error estimates, see \cite{Vu} Example 11.13. Indeed, 
 the function  $F(x)=\sum_{k=0}^\infty\frac1{(2k+1)^2}\sin{\left(} \frac x{2k+1}{\right)}$ is almost periodic. 
 By direct computation 
 
 \begin{eqnarray*}
 \int_0^TF(x)dx&=&\sum_{k=0}^\infty\frac2{2k+1}\sin^2{\left(} \frac T{2(2k+1)}{\right)}\\
 &=&\sum_0^{N({\varepsilon})}\dots+\sum_{N({\varepsilon})}^\infty\dots
 \end{eqnarray*}
 $N({\varepsilon})\sim \frac1{\varepsilon}$ then in this case $\delta({\varepsilon})\lesssim {\mathcal} O({\varepsilon}|\log{\varepsilon}|)$.

\medskip 

\noindent
{\bf Example 4:}  (1-dimensional Transport Equation) One can apply  Theorem 1 to the homogenisation of  some model transport equations 
such as 
\begin{equation}\label{eq-trans1D}
{\partial}_t v^{\varepsilon}+H(x/{\varepsilon}){\partial}_x v^{\varepsilon}=0,\quad v^{\varepsilon}(x, t=0)=v_0(x).
\end{equation}
Here $H>0$ is $C^1$ smooth periodic function.  Let ${\textbf{F}}=(1, H)$ and $\rho$ the density of invariant measure, i.e.
${\operatorname{div}}(\rho {\textbf{F}})=0$. Therefore there is a function $M(x, t)$ solving the system 

\begin{eqnarray}
\left\{
\begin{array}{ccc}
{\partial}_t M= -\rho H(y/{\varepsilon})\\
{\partial}_x M=\rho.
\end{array}
\right.
\end{eqnarray}
The level sets $M=const$ are the characteristics of the equation \eqref{eq-trans1D}.
Noting that ${\partial}_t M=-\rho H\not =0$ and applying the inverse function theorem to $M(x, t)=const$
we infer that $x=h^{\varepsilon}(t)$ and therefore for the solution of the Cauchy problem we have the 
formula 
$$v^{\varepsilon}(x, t)=v_0(x-h^{\varepsilon}(t)),$$
where by construction ${\displaystyle\frac{d{{h^{\varepsilon}}}}{dt} }=H(h^{\varepsilon}/{\varepsilon}), h^{\varepsilon}(0)=x$. Denote $v^0(x, t)=v_0(x-h^0(t))$, where $h^0= \lim h^{\varepsilon}$.  Thus we have from Theorem 1
the estimate 
$$|v^{\varepsilon}(x, t)-v^0(x,t)|= |v_0(x-h^{\varepsilon}(t))-v_0(x-h^0(t))|\leq \|{\partial}_x v_0\|_\infty|h^{\varepsilon}(t)-h^0(t)|\lesssim {\varepsilon}.$$

\medskip 

\noindent
{\bf Example 5:}  (Wiggly vs Rectifiable trajectories)
Consider ${\displaystyle\frac{d{{X^{\varepsilon}}}}{dt} }=\nabla F(X^{\varepsilon}/{\varepsilon})$ with some  function $F$, which is sub-linear, e.g. we assume 
$|F(y)| \leq |y|^a $, $a<1$. 
Multiply this equation by ${\displaystyle\frac{d{X}}{dt} }^{\varepsilon}$ and integrate over the interval $[0, T], T>0$. Then we obtain 
$$\int_0^T\left|{\displaystyle\frac{d{X}}{dt} }^{\varepsilon}\right|^2dt={\varepsilon}\int_0^T\frac{d}{dt}{\left(} F{\left(}\frac {X^{\varepsilon}}{\varepsilon}{\right)} {\right)} dt=
{\varepsilon}\left[F{\left(}\frac{ X^{\varepsilon}(T)}{\varepsilon}{\right)}-F{\left(}\frac {X^{\varepsilon}(0)}{\varepsilon}{\right)}\right]$$
implying that 
$$\int_0^T\left|{\displaystyle\frac{d{X}}{dt} }^{\varepsilon}\right|^2dt\leq {\varepsilon} |X^{\varepsilon}(T)/{\varepsilon}|^{a} = {\mathcal} O({\varepsilon}^{1-a}).$$
Thus, this curves stays around the initial state (for finite time $T < \infty$), and the limit curve $\lim_{{\varepsilon}\to 0}X^{\varepsilon} = X^0$ does not move.

In contrast to our case, where the paths are rectifiable and the limit is a line, not a point.

\bibliographystyle{plain}

\begin{thebibliography}{1}

\bibitem{Arn92}
V.I. Arnold.
\newblock Polyintegrable flows.
\newblock {\em Algebra i Analiz}, 4(6):54--62, 1992.

\bibitem{BCS} M. Bardi, A. Cesaroni, A. Scotti,  Convergence in Multiscale Financial Models with Non-Gaussian Stochastic Volatility, preprint.

\bibitem{Bogolyubov} N. N. Bogolyubov, 
Y. A. Mitropolski, Asymptotic methods in the theory of non-linear oscillations, translated from Russian, New York: Gordon and Breach, 1961 

\bibitem{Dali}
A. L. Dalibard, Homogenization of linear transport equations in a stationary ergodic setting, Comm. Partial Differential Equations, 33 (2008), pp. 881--921.

\bibitem{CFS}
I. Cornfeld, S. Fomin, Ya. Sinai, Ergodic Theory. New York: Springer-Verlag, 1982.

\bibitem{DeGiorgi} E. De Giorgi, On the convergence of solutions of some evolution
differential equations,
Set-Valued Analysis
1994, Volume 2, Issue 1-2, pp 175-182.

\bibitem{Weinan} W. E, Homogenization of linear and nonlinear transport equations. 
Comm. Pure Appl. Math. 45 (1992), no. 3, 301--326

\bibitem{Hou} T. Hou, X. Xin, Homogenization of linear transport equations with oscillatory vector fields. 
SIAM J. Appl. Math. 52 (1992), no. 1, 34--45.

\bibitem{Regis} H. Ibrahim,  R. Monneau, 
On the Rate of Convergence in Periodic Homogenization of Scalar First-Order Ordinary Differential Equation, 
SIAM J. Math. Anal., 42(5), 2155--2176.

\bibitem{Kolm53}
A.N. Kolmogorov.
\newblock On dynamical systems with an integral invariant on the torus.
\newblock {\em Doklady}, 93(5):763--766, 1953.

\bibitem{Ko07}
V.V. Kozlov.
\newblock Dynamical systems with multivalued integrals on a torus.
\newblock {\em Proceedings of Steklov institute of Mathematics},
  256(1):188--205, 2007.

\bibitem{Lions} R.J. DiPerna, P.-L. Lions, 
Ordinary differential equations, transport theory and Sobolev spaces. 
Invent. Math. 98 (1989), no. 3, 511--547

\bibitem{Menon} G. Menon,  Gradient systems with wiggly energies and related averaging problems. 
Arch. Ration. Mech. Anal. 162 (2002), no. 3, 193Ð246. 

\bibitem{Peirone} R. Peirone, Convergence of solutions of linear transport equations, 
Ergod. Th. and Dynam. Sys. (2003), 23, 919--933.

\bibitem{Picci} L. Piccinini, Homogeneization problems for ordinary differential equations, Rend. Circ. Mat. Palermo (2), 27 (1978), pp. 95--112.

\bibitem{Sanders} J. Sanders, F. Verhulst, J. Murdock, 
Averaging Methods in Nonlinear Dynamical Systems,
 Springer 2007.

\bibitem{Sinai} Ya. Sinai,
Introduction to ergodic theory,  Princeton University Press, Princeton, N.J., 1976.

\bibitem{Tartar} L.Tartar, Nonlocal effects induced by homogenization, in PDE and 
Calculus of Variations, pp 925--938, F.Culumbini et al., eds., Birkh\"auser, Boston, 1989.

\bibitem{Tassa} T. Tassa, 
Homogenization of two-dimensional linear flows with integral invariance. 
SIAM J. Appl. Math. 57 (1997), no. 5, 1390--1405. 

\bibitem{Vu} F. Verhulst,
Methods and Applications of Singular Perturbations, Texts in Applied Mathematics 50, Springer, 2010.
\end{thebibliography}

\end{document}

