\documentclass[10pt]{amsart}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{amsfonts}
\usepackage{latexsym}
\usepackage{pstricks, pst-node, pst-text, pst-3d}
\usepackage{color}
\usepackage{bm}
\usepackage{hyperref}

\setcounter{MaxMatrixCols}{30}

\setlength{\textwidth}{5.5in}
\newtheorem{theorem}{Theorem}
\newtheorem{proposition}{Proposition}
\newtheorem{corollary}{Corollary}
\newtheorem{lemma}{Lemma}
\newtheorem{remark}{Remark}
\newtheorem{question}{Question}
\newtheorem{definition}{Definition}
\theoremstyle{remark}
\newtheorem{example}{Example}

\let\ov=\overline
\let\td=\tilde
\let\wtd=\widetilde
\let\dd=\partial

\begin{document}
\title{Decomposition of the Kostlan--Shub--Smale model for random polynomials}
\author[V.~Gichev]{Victor Gichev}

\thanks{The author was partially supported by
the grant of the Norwegian Research Council \#204726/V30}

\subjclass[2010]{Primary 60H25,  60G60; Secondary  43A85}
\keywords{Kostlan--Shub--Smale model, random polynomials, average
Hausdorff measure of zeroes, isotropy irreducible homogeneous
spaces}

\address{Sobolev Institute of Mathematics\\
Omsk Branch\\
ul. Pevtsova, 13, \\ 644099, Omsk, Russia}
\email{gichev@ofim.oscsbras.ru}

\begin{abstract}
Let ${\mathcal{P}}_n$ be the space of homogeneous polynomials of degree $n$
on ${\mathbb{R}}^{m+1}$. We consider the asymptotic behavior of the
coefficients relating to the decomposition of ${\mathcal{P}}_n$ into the sum
of ${\mathop{\mathrm{SO}}}(m+1)$-irreducible components. Using the results, we prove
that a random Kostlan--Shub--Smale polynomial in ${\mathcal{P}}_n$ can be
approximated by polynomials of lower degree (roughly, of magnitude
$C\sqrt{n\ln n}$) in the Sobolev spaces $H^k(S^m)$ on the unit
sphere $S^m$ with a high probability.
\end{abstract}
\maketitle

\section{Introduction}

Let $G$ be a compact Lie group acting on a Riemannian manifold $M$
by isometries, ${\mathcal{E}}$ be a finite dimensional $G$-invariant
subspace of $C^\infty(M)$, and $\sigma$ be a $G$-invariant
probability measure on ${\mathcal{E}}$. For $u\in{\mathcal{E}}$, set
$N_u=u^{-1}(0)$. The Hausdorff measure ${{\mathord{\mathfrak{h}}}}^{m-1}(N_u)$ of $N_u$,
where $m=\dim M$, is a random variable whose distribution depends
on $\sigma$. There are other metric quantities which can be
considered in this setting, for example, the Euler characteristic
of $N_u$ (see \cite{Po99}, \cite{Bu07}). Most of the known results
were proved for the Gaussian distributions in ${\mathcal{E}}$ and the
uniform distributions in the unit sphere in ${\mathcal{E}}$.

We consider the case $G={\mathop{\mathrm{SO}}}(m+1)$, $M=S^m={\mathop{\mathrm{SO}}}(m+1)/{\mathop{\mathrm{SO}}}(m)$, the
unit sphere in ${\mathbb{R}}^{m+1}$, and ${\mathcal{E}}={\mathcal{P}}_n$, the space of real
homogeneous of degree $n$ polynomials on ${\mathbb{R}}^{m+1}$. Let ${\mathcal{H}}_j$
be the subspace of all harmonic polynomials in ${\mathcal{P}}_j$. There is
the well known
 ${\mathop{\mathrm{SO}}}(m+1)$-invariant decomposition
\begin{eqnarray}\label{harmdec}
{\mathcal{P}}_n
=\sum_{j\in J_n}|x|^{n-j}{\mathcal{H}}_{j},
\end{eqnarray}
where we set
\begin{eqnarray}\label{defjnz}
J_n=\{j\in{\mathbb{Z}}:\,0\le j\leq n,~n-j~\,\text{even}\}
\end{eqnarray}
for short. Clearly,  the restriction onto $S^m$ is injective on
the space ${\mathcal{P}}_n$. The space $\sum_{j\in J_n}{\mathcal{H}}_j$ has the same
property since it consists of harmonic polynomials. Also, the
space of traces of all even (odd) polynomials of degree less or
equal to $n$ coincides with ${\mathcal{P}}_n\big|_{S^m}$ but the restriction
map is not injective. We shall denote by ${\mathcal{P}}_n$, ${\mathcal{H}}_j$ the
trace spaces on $S^m$ as well as the spaces of polynomials on
${\mathbb{R}}^{m+1}$ hoping that no confusion will occur. Due to this
convention,
\begin{eqnarray*}
{\mathcal{P}}_j\subseteq{\mathcal{P}}_n~~~~\hbox{\rm if}~~j\in J_n.
\end{eqnarray*}
The investigation of random polynomials was initiated by papers
\cite{BP} by Bloch and Polya, and \cite{LO38}, \cite{LO39} by
Littlewood and Offord. In \cite{Kac}, M.\,Kac proved an exact
integral formula for the expectation of the number of real zeroes
of random polynomials of one variable with standard Gaussian
coefficients (i.e., having expectation $0$ and variance $1$).
Kostlan (see \cite{Ko93}, \cite{EK95}) found a geometric proof of
this formula. For any $a\in{\mathbb{R}}^{n+1}$, common points of the
hyperplane $a^\bot$ and the moment curve ${{\mathord{\gamma}}}(x)=(1,x,\dots,x^n)$
are in one-to-one correspondence with zeroes of the polynomial
${\left<{a},{{{\mathord{\gamma}}}(x)}\right>}$. The same is true for the central projection
$\td{{\mathord{\gamma}}}(x)=\frac{{{\mathord{\gamma}}}(x)}{|{{\mathord{\gamma}}}(x)|}$ of ${{\mathord{\gamma}}}$ onto the unit sphere
$S^n$. Set  $f(a)={\mathop{\mathrm{card}}}(a^\bot\mathop\cap\td{{\mathord{\gamma}}})$. Since $f(a)$ is
homogeneous of degree $0$, we can compute the expectation of the
number of zeroes integrating $f$ over $S^n$; on the other hand,
the integral is proportional to the length of $\td{{\mathord{\gamma}}}$ due to a
Crofton type formula.

This method can be extended onto the other function spaces and
inner products. Kostlan noted that the distribution on the space
of polynomials whose coefficients are independent Gaussian with
the variance ${{n}\choose{j}}$ at $x^j$ has a hidden symmetry: it
can be lifted onto the space of homogeneous degree $n$ polynomials
of two variables as an ${\mathop{\mathrm{SO}}}(3)$-invariant distribution. In
\cite{Ko93}, Kostlan found the expectation of the number of
solutions to a random system of equations $u_j(x)=0$, where
$u_j\in{\mathcal{P}}_n$ are independent random polynomials, $j=1,\dots,k$,
where $k\leq m$. It is proportional to $n^{\frac{k}{2}}$ and
equals to $n^{\frac{m}{2}}$ if $k=m$. Shub and Smale in the paper
\cite{SS93} extended this result onto the case of different
powers: the expectation of the number of solutions to the system
$u_1(x)=\dots=u_m(x)=0$, $u_j\in{\mathcal{P}}_{n_j}$, is equal to
$\sqrt{n_1\dots n_m}$.

In the paper \cite{Po99}, Podkorytov introduced a parameter of a
Gaussian ${\mathop{\mathrm{SO}}}(m)$-invariant distribution in ${\mathcal{P}}_n$ and found an
explicit formula for the expectation of the Euler characteristic
of $N_u$ which is a function of the parameter. For higher
codimensions (i.e., the varieties
$N_{u_1}\mathop\cap\dots\mathop\cap N_{u_k}$, where $k\leq m$),
B\"urgisser computed the expectations of the Euler characteristic
in the paper \cite{Bu07}. His proof involves the Weyl's tube
formula and is new even for the codimension 1.

The results above can be formulated in terms of Podkorytov's
parameter. The coefficient of metric homothety introduced in
\cite{Gi08} is the square root of it. This coefficient, which we
denote by $s$, can be defined for all isotropy irreducible
homogeneous spaces. The space $M=G/H$ is isotropy irreducible if
$H$ is irreducible in $T_oM$, where $o$ is the base point of $M$
corresponding to $H$. Such a space admits the unique up to a
scaling factor invariant Riemannian metric. Thus any equivariant
nonconstant mapping of $M$ into a Riemannian $G$-manifold is a
finite covering and a local metric homothety onto its image. In
particular, this is true for the normalized evaluation mapping
$\iota:\,M\to{\mathcal{S}}$, where ${\mathcal{S}}$ is the unit sphere in ${\mathcal{E}}$. The
coefficient $s$ above corresponds to $\iota$:
\begin{eqnarray}\label{defss}
s=\frac{|d_p\iota(v)|_{\mathcal{E}}}{|v|_{T_pM}},
\end{eqnarray}
where the right-hand part is independent of the choice of $p\in M$
and $v\in T_pM\setminus\{0\}$. Federer's kinematic formula for
spheres (\cite[Theorem~3.2.48]{{Fe69}}) makes it possible to
compute the expectation of ${{\mathord{\mathfrak{h}}}}^{m-1}(N_u)$. It is equal to
$\frac{\varpi\varpi_{m-1}}{\varpi_{m}}s$, where $\varpi$ and
$\varpi_k$ are volumes of $M$ and the unit sphere $S^k$ in
${\mathbb{R}}^{k+1}$, respectively. For the expectation of measures of the
intersections of the sets $N_u$, there is a similar expression
with the product of the coefficients of metric homothety instead
of $s$.

Thus, $s$ is an essential ingredient in the formulas for the
averages.  Sometimes, it is possible to find it following the
definition (i.e., applying (\ref{defss})). This is the case in the
Kostlan--Shub--Smale model. If ${\mathcal{E}}$ is $G$-irreducible, then it
is an eigenspace of the Laplace--Beltrami operator\footnote{this
is true for isotropy irreducible homogeneous spaces and for the
spaces ${\mathcal{E}}$ whose decomposition into the irreducible components
is free of multiplicities but this is not true in general}
${{\mathord{\Delta}}}$ and $s=\sqrt{\frac{{\mathord{\lambda}}}{m}}$, where ${{\mathord{\lambda}}}$ is the
eigenvalue of $-{{\mathord{\Delta}}}$. In general, $s$ depends on the irreducible
components of ${\mathcal{E}}$ and the inner product in ${\mathcal{E}}$. For the norm
of $L^2(M)$ in ${\mathcal{E}}$  the answer is given in \cite[Lemma~1]{Gi13}:
if ${\mathcal{E}}={\mathcal{E}}_1\oplus\dots\oplus{\mathcal{E}}_k$, where ${\mathcal{E}}_j$ are
irreducible, then
\begin{eqnarray}\label{ssqunu}
s^2=\nu_1s_1^2+\dots+\nu_ks_k^2,
\end{eqnarray}
where $s_j$ is the coefficient of metric homothety for ${\mathcal{E}}_j$ and
$\nu_j=\frac{\dim{\mathcal{E}}_j}{\dim{\mathcal{E}}}$, $j=1,\dots,k$.
In Section~\ref{seccoef}, we show that $s$ is subject to
(\ref{ssqunu}) for any invariant inner product, where $\nu_j$
depend on the choice of the norm but $s_j$ are independent of it.

Due to the decomposition (\ref{harmdec}), in the case $M=S^m$ and
${\mathcal{E}}={\mathcal{P}}_n$  we have $s\sim\frac{n}{\sqrt{m+2}}$ as $n\to\infty$
for the $L^2(S^m)$-norm in ${\mathcal{E}}$. In the Kostlan--Shub--Smale
model (see Section~\ref{seccoepn} for the definition),
$s=\sqrt{n}$ independently of $m$.

In this paper, we find the coefficients for the
Kostlan--Shub--Smale model (Theorem~\ref{kss-l2}) and their
scaling limit as $n\to\infty$ (Theorem~\ref{limitnu}). The
coefficients $\nu_j$ have a sharp peak near $\sqrt{(m-1)n}$ and
decay very fast. The main result is Theorem~\ref{lower} which
states that
a random Kostlan--Shub--Smale polynomial of degree $n$ admits a
good approximation in the Sobolev spaces by polynomials of lower
degree (roughly, $C\sqrt{n\ln n}$ or greater) with a high
probability. For example, if $n$ is sufficiently large,
\begin{eqnarray*}
l_n>2\sqrt{mn\ln n},
\end{eqnarray*}
and $n-l_n$ is even, then the inequality
\begin{eqnarray*}
{\mathrm{dist}}\left(u,{\mathcal{P}}_{l_n}\right)<{{\mathord{\varepsilon}}}_n|u|
\end{eqnarray*}
holds with the probability greater that $1-\eta_n$, where ${\mathrm{dist}}$
stands for the distance in $L^2(S^m)$,
\begin{eqnarray*}
{{\mathord{\varepsilon}}}_n=a n^{-\frac{m}{2}},~~~\eta_n=bn^{-\frac{m}{2}},
\end{eqnarray*}
 and $a,b$ are
independent of $n$. If $l_n>{{\mathord{\alpha}}} n$, where ${{\mathord{\alpha}}}<1$, then ${{\mathord{\varepsilon}}}_n$
and $\eta_n$ may both decay exponentially when $n$ grows. We get
an estimate for the expectation of the ratio of the squared
distance from $u$ to ${\mathcal{P}}_{l_n}$ in the Kostaln--Shub--Smale model
which grows polynomially as $n\to\infty$. The inequality above
holds with a high probability due to the fast decay of the
coefficients of the decomposition.

Everywhere in the paper, we fix $m$ and drop it in the notation
assuming
\begin{eqnarray}\label{assmn}
1<m<n.
\end{eqnarray}
The notation $|\ |$ is used for the Euclidean norms and ${\left<{\
},{\ }\right>}$ for the relating inner product. The base point of $M=G/H$
corresponding to $H$ we denote by $o$. If $M$ is the unit sphere
$S^m$ in ${\mathbb{R}}^{m+1}$, then $o=(1,0,\dots,0)$. In the notation
$L^2(M)$ the invariant probability measure on $M$ is assumed.
Also, $du$, $dx$, etc. stands either for the Lebesgue measure in
an Euclidean space or for the invariant probability measure on a
compact homogeneous space (in particular, on $S^m$).

\medskip

{\bf Acknowledgements.} I cordially thank Irina Markina and
Aleksandr Vasil'ev for the kind hospitality and fruitful
discussions during my stay at the University of Bergen, where part
of this work was done.

\section{Coefficients corresponding to the
invariant Euclidean structures}\label{seccoef}

Since ${{\mathord{\Delta}}}$ is $G$-invariant, the space of all
${{\mathord{\lambda}}}$-eigenfunctions is also $G$-invariant for any ${{\mathord{\lambda}}}\in{\mathbb{C}}$.
Hence there is a $G$-invariant orthogonal decomposition
\begin{eqnarray}\label{decce}
{\mathcal{E}}={\mathcal{E}}_1\oplus\dots\oplus{\mathcal{E}}_l,
\end{eqnarray}
where the summands are $G$-irreducible eigenspaces of ${{\mathord{\Delta}}}$. Let
${{\mathord{\lambda}}}_j$ denote the eigenvalue of $-{{\mathord{\Delta}}}$ on ${\mathcal{E}}_j$. We assume
${\mathcal{E}}_j\neq0$ for all $j=1,\dots,l$.

The evaluation mapping ${\mathop{\mathrm{ev}}\nolimits}_{\mathcal{E}}:\,M\to{\mathcal{E}}$ is defined by the
identity
\begin{eqnarray}\label{defev}
{\left<{{\mathop{\mathrm{ev}}\nolimits}_{\mathcal{E}}(p)},{u}\right>}=u(p),
\end{eqnarray}
where $p\in M$, $u\in{\mathcal{E}}$. Then
$\iota(p)=\frac{{\mathop{\mathrm{ev}}\nolimits}_{\mathcal{E}}(p)}{|{\mathop{\mathrm{ev}}\nolimits}_{\mathcal{E}}(p)|}$.
Due to the homogeneity of $M$, $|{\mathop{\mathrm{ev}}\nolimits}_{\mathcal{E}}(p)|$ is independent of
$p$. Set
\begin{eqnarray}
\label{defcevp}c=|{\mathop{\mathrm{ev}}\nolimits}_{\mathcal{E}}(p)|,\\
\phi={\mathop{\mathrm{ev}}\nolimits}_{\mathcal{E}}(o),\nonumber
\end{eqnarray}
and $c_j=|{\mathop{\mathrm{ev}}\nolimits}_{{\mathcal{E}}_j}(p)|$, $\phi_j={\mathop{\mathrm{ev}}\nolimits}_{{\mathcal{E}}_j}(o)$, where
$j=1,\dots,l$. Clearly, $\phi=\phi_1+\dots+\phi_l$. Since $\phi_j$
are pairwise orthogonal, we get
\begin{eqnarray}\label{cjcjsq}
c^2=c_1^2+\dots+c_l^2.
\end{eqnarray}
Let ${\mathord{\mathfrak{g}}}$ be the Lie algebra of $G$.
\begin{lemma}\label{snusj}
Set $\nu_j=\frac{c_j^2}{c^2}$, and let $s_j$ be the coefficient of
the metric homothety for ${\mathcal{E}}_j$, $j=1,\dots,l$. Then
\begin{eqnarray}\label{csnucjsj}
s^2=\nu_1s_1^2+\dots+\nu_ls_l^2.
\end{eqnarray}
\end{lemma}
\begin{proof}
For any $\xi\in{\mathord{\mathfrak{g}}}$, we have
$d_p\iota(\xi(p))=\frac{1}{c}\xi{\mathop{\mathrm{ev}}\nolimits}_{\mathcal{E}}(p)$ and, according to
(\ref{defss}),
\begin{eqnarray}\label{xiphi}
cs|\xi(o)|_{T_oM}=|\xi\phi|_{\mathcal{E}}.
\end{eqnarray}
Similarly, $s_jc_j|\xi(o)|_{T_oM}=|\xi\phi_j|_{{\mathcal{E}}_j}$. Since
$\xi\phi_j\in{\mathcal{E}}_j$,
\begin{eqnarray*}
|\xi\phi|_{\mathcal{E}}^2=|\xi\phi_1+\dots+\xi\phi_l|^2_{\mathcal{E}}
=|\xi\phi_1|_{{\mathcal{E}}_1}^2+\dots+|\xi\phi_l|_{{\mathcal{E}}_l}^2
=(c_1^2s_1^2+\dots+c_l^2s_l^2)|\xi(o)|_{T_oM}.
\end{eqnarray*}
Together with (\ref{xiphi}), this implies (\ref{csnucjsj}).
\end{proof}

Let ${\left<{\ },{\ }\right>}$, $\wtd{{\left<{\ },{\ }\right>}}$ be two $G$-invariant
inner products in ${\mathcal{E}}$, ${\mathcal{S}}$ and $\wtd{\mathcal{S}}$ be the corresponding
unit spheres in ${\mathcal{E}}$, respectively. We shall endow with the tilde
the notation for relating objects. We assume additionally that
there are $\tau_j>0$, $j=1,\dots,l$, such that for all $u,v\in{\mathcal{E}}$
\begin{eqnarray}\label{nnorms}
\wtd{{\left<{u},{v}\right>}}=\tau_1^{-1}{\left<{u_1},{v_1}\right>}+
\dots+\tau_l^{-1}{\left<{u_l},{v_l}\right>},
\end{eqnarray}
where $u_j,v_j$ are components of $u,v$ in the decomposition
(\ref{decce}). The assumption holds if the summands in
(\ref{decce}) are pairwise non-equivalent as $G$-modules.

\begin{lemma}\label{eqisct}
For any $j=1,\dots,l$, the following equalities hold:
\begin{eqnarray*}
\begin{array}{r}
\td c_j^2=\tau_j c_j^2 ,\\
\td\phi_j=\tau_j\phi_j,\\
\td s_j=s_j=\sqrt{\frac{{{\mathord{\lambda}}}_j}{m}},
\end{array}
\end{eqnarray*}
and, moreover, $\td s^2=\frac{\tau_1 c_1^2}{\td c^2}s_1^2+
\dots+\frac{\tau_l c_l^2}{\td c^2}s_l^2$, where $\td c^2=\tau_1
c_1^2+\dots+\tau_l c_l^2$.
\end{lemma}
\begin{proof}
Suppose ${\left<{u},{v}\right>}=\tau\wtd{{\left<{u},{v}\right>}}$ for all $u,v\in{\mathcal{E}}$.
Due to the equalities
$u(o)=\wtd{{\left<{u},{\td\phi}\right>}}={\left<{u},{\frac1{\tau}\td\phi}\right>}
={\left<{u},{\phi}\right>}$, we have $\td\phi=\tau\phi$ and $\td
c^2=\wtd{|\td\phi|}^2=\tau|\phi|^2=\tau c^2$ in this case. By
(\ref{xiphi}),
\begin{eqnarray*}
cs|\xi(o)|_{T_oM}=|\xi\phi|,\\ 
c\td s|\xi(o)|_{T_oM}=\wtd{|\xi\td\phi|}\phantom{!}
\end{eqnarray*}
for all $\xi\in{\mathord{\mathfrak{g}}}$. The equality $\td\phi=\tau\phi$ implies
$\wtd{|\xi\td\phi|}^2=\tau|\xi\phi|^2$ and, together with $\td
c^2=\tau c^2$ and the equalities above,  $\td s=s$. According to
\cite[Lemma~1]{Gi13}, in the case of $L^2(M)$-norm and ${\mathcal{E}}$
irreducible we have $s=\sqrt{\frac{{\mathord{\lambda}}}{m}}$, where ${{\mathord{\lambda}}}$ is the
eigenvalue of $-{{\mathord{\Delta}}}$ on ${\mathcal{E}}$ (in \cite{Gi13}, it is assumed that
${\mathcal{E}}\perp{{\mathord{\mathbf1}}}$ but for the space of constant functions the
equality $s=\sqrt{\frac{{\mathord{\lambda}}}{m}}$ is evidently true since
${{\mathord{\lambda}}}=s=0$). Since the invariant inner products on irreducible
$G$-modules are pairwise proportional, the arguments above prove
the first three equalities. The remaining ones follow from
Lemma~\ref{snusj} and (\ref{cjcjsq}).
\end{proof}
\begin{corollary}
Let ${{\mathord{\lambda}}}_{\min}$ and ${{\mathord{\lambda}}}_{\max}$ be the least and largest
eigenvalues of $-{{\mathord{\Delta}}}$ in ${\mathcal{E}}$, respectively. Suppose ${{\mathord{\lambda}}}_{\min}<
{{\mathord{\lambda}}}_{\max}$.  Then
\begin{eqnarray*}
\sqrt{\frac{{{\mathord{\lambda}}}_{\min}}{m}}< s<\sqrt{\frac{{{\mathord{\lambda}}}_{\max}}{m}}.
\end{eqnarray*}
Moreover, for any $s$ satisfying this inequality there is an
invariant Euclidean norm on ${\mathcal{E}}$ whose coefficient of metric
homothety is equal to $s$.
\end{corollary}
\begin{proof}
The assumption ${\mathcal{E}}_j\neq0$ implies $\nu_j>0$. Thus the obvious
equality
\begin{eqnarray*}
\nu_1+\dots+\nu_l=1
\end{eqnarray*}
implies the inequalities above. Since $\tau_j$'s may be arbitrary
positive numbers, the second assertion of the corollary follows
from Lemma~\ref{eqisct}.
\end{proof}
In \cite{Po99}, Podkorytov stated without proof equivalent
inequalities for Gaussian ${\mathop{\mathrm{SO}}}(m+1)$-invariant distributions in
${\mathcal{P}}_n$.

\section{The coefficients for the space of homogeneous polynomials}
\label{seccoepn} We refer to \cite[Chapter~5]{Ax01} for known
facts on harmonic polynomials. In this section, we find the
coefficients introduced in the previous one for the decomposition
(\ref{harmdec}) and the following Euclidean norms: the first, $|\
|$, is the norm of $L^2(S^m)$ for the invariant probability
measure and the second, $\wtd{|\ |}$, is defined by
\begin{eqnarray}\label{decph}
\wtd{{\left<{x^{{\mathord{\alpha}}}},{x^{{\mathord{\beta}}}}\right>}}=\begin{cases}{{\mathord{\alpha}}}!,&{{\mathord{\alpha}}}={{\mathord{\beta}}}
\\0,&{{\mathord{\alpha}}}\neq{{\mathord{\beta}}},
\end{cases}
\end{eqnarray}
where ${{\mathord{\alpha}}}=({{\mathord{\alpha}}}_0,{{\mathord{\alpha}}}_1,\dots,{{\mathord{\alpha}}}_m)$,
${{\mathord{\beta}}}=({{\mathord{\beta}}}_0,{{\mathord{\beta}}}_1,\dots,{{\mathord{\beta}}}_m)$, ${{\mathord{\alpha}}}!={{\mathord{\alpha}}}_0!\dots{{\mathord{\alpha}}}_m!$, and
$x^{{\mathord{\alpha}}}=x_0^{{{\mathord{\alpha}}}_0}\dots x_m^{{{\mathord{\alpha}}}_m}$.
A simple straightforward computation shows that the formula
\begin{eqnarray}\label{sympro}
\wtd{{\left<{u},{v}\right>}}=u\left(\frac{\partial}{\partial x}\right)v
\end{eqnarray}
defines the same inner product in ${\mathcal{P}}_n$ (notice that the
right-hand part is constant). To the best of my knowledge, it was
introduced in the the book \cite{St70} by E.\,Stein. The products
are both ${\mathop{\mathrm{SO}}}(m+1)$-invariant. The Kostlan--Shub--Smale model
corresponds to the Gaussian distribution whose density is
proportional to $e^{-\wtd{|u|}^2}$ on ${\mathcal{P}}_n$.

We use the notation of (\ref{harmdec}). On $S^m$, ${\mathcal{H}}_j$ is the
eigenspace of the Laplace--Beltrami operator $-{{\mathord{\Delta}}}$ corresponding
to the eigenvalue ${{\mathord{\lambda}}}_j=j(j+m-1)$. Furthermore,
\begin{eqnarray}\label{dimcpn}
\dim{\mathcal{P}}_n={{n+m}\choose{m}}.
\end{eqnarray}
It follows from (\ref{harmdec}) that
\begin{eqnarray}\label{dimhn}
\dim{\mathcal{H}}_n={{n+m}\choose{m}}-{{n+m-2}\choose{m}}
=\frac{(m+n-2)!(m+2n-1)}{(m-1)!n!}
\end{eqnarray}
if $n\geq2$. Clearly, $\dim{\mathcal{H}}_0=1$, $\dim{\mathcal{H}}_1=m+1$ and,
moreover, the equalities remain true if we replace the factorials
with ${{\mathord{\Gamma}}}$ and extend the right-hand side of (\ref{dimhn})
analytically. For short, set
\begin{eqnarray*}
{{\mathord{\varkappa}}}(x)=|x|^2=x_0^2+x_1^2+\dots+x_m^2.
\end{eqnarray*}

\begin{lemma}\label{taukj}
Let $u\in{\mathcal{H}}_j\setminus\{0\}$ and $k\geq0$. Then
\begin{eqnarray*}
\frac{\wtd{|{{\mathord{\varkappa}}}^k u|}^2}{|u|^2}= 2^k
k!\prod_{i=1}^{j+k}(m+2i-1)
\end{eqnarray*}
\end{lemma}
\begin{proof}
For $u\in{\mathcal{P}}_j$, let $u(x)=\sum_{|{{\mathord{\alpha}}}|=j}u_{{\mathord{\alpha}}} x^{{\mathord{\alpha}}}$, where
$|{{\mathord{\alpha}}}|={{\mathord{\alpha}}}_0+\dots+{{\mathord{\alpha}}}_m$, be its decomposition into the sum of
monomials. By definition,
\begin{eqnarray}\label{kosnorm}
\wtd{|u|}^2=\sum_{|{{\mathord{\alpha}}}|=j}u_{{\mathord{\alpha}}}^2{{\mathord{\alpha}}}!,
\end{eqnarray}
If $u\in{\mathcal{H}}_j$, then its $L^2$-norm $|u|$ can be computed by a
similar formula (\cite[Theorem~5.14]{Ax01}):
\begin{eqnarray}\label{koltwo}
|u|^2=\frac1{(m+1)(m+3)\dots(m+2j-1)}\sum_{|{{\mathord{\alpha}}}|=j} u_{{\mathord{\alpha}}}^2{{\mathord{\alpha}}}!.
\end{eqnarray}
This proves the lemma in the case $k=0$. Thus we have a base for
the induction on $k$. Let ${{\mathord{\varphi}}}$ be a smooth function on ${\mathbb{R}}$ and
$v\in{\mathcal{P}}_j$. Using the equalities
\begin{eqnarray*}
{{\mathord{\Delta}}}{{\mathord{\varphi}}}({{\mathord{\varkappa}}})=4{{\mathord{\varphi}}}''({{\mathord{\varkappa}}}){{\mathord{\varkappa}}}+2(m+1){{\mathord{\varphi}}}'({{\mathord{\varkappa}}}),\\
{\left<{\nabla{{\mathord{\varphi}}}({{\mathord{\varkappa}}})},{\nabla v}\right>}=2j{{\mathord{\varphi}}}'({{\mathord{\varkappa}}})v,
\end{eqnarray*}
we get
\begin{eqnarray*}
{{\mathord{\Delta}}}({{\mathord{\varphi}}}({{\mathord{\varkappa}}})v)
=2(2{{\mathord{\varphi}}}''({{\mathord{\varkappa}}}){{\mathord{\varkappa}}}+(m+2j+1){{\mathord{\varphi}}}'({{\mathord{\varkappa}}}))v +{{\mathord{\varphi}}}({{\mathord{\varkappa}}}){{\mathord{\Delta}}} v.
\end{eqnarray*}
If $u\in{\mathcal{H}}_j$ and ${{\mathord{\varphi}}}({{\mathord{\varkappa}}})={{\mathord{\varkappa}}}^k$, then
\begin{eqnarray*}
{{\mathord{\Delta}}}({{\mathord{\varkappa}}}^k u)=2k\left(m+2j+2k-1\right){{\mathord{\varkappa}}}^{k-1}u.
\end{eqnarray*}
By (\ref{sympro}),
\begin{eqnarray*}
\wtd{|{{\mathord{\varkappa}}}^ku|}^2=\wtd{{\left<{{{\mathord{\varkappa}}}^k u},{{{\mathord{\varkappa}}}^k
u}\right>}}=\wtd{{\left<{{{\mathord{\varkappa}}}^{k-1}u},{{{\mathord{\Delta}}}({{\mathord{\varkappa}}}^k u)}\right>}}=
2k\left(m+2(j+k)-1\right)\wtd{|{{\mathord{\varkappa}}}^{k-1}u|}^2.
\end{eqnarray*}
This verifies the step of the induction and concludes the proof.
\end{proof}
For the convenience of the reader, we collect the formulas for
coefficients in the theorem below.
\begin{theorem}\label{kss-l2}
Let ${\mathcal{E}}_j$ be the summand $|x|^{n-j}{\mathcal{H}}_{j}$ in the decomposition
(\ref{harmdec}) of the space ${\mathcal{E}}={\mathcal{P}}_n$ and let $c_j,s_j$ and
$c,s$ be defined by formulas (\ref{defcevp}), (\ref{defss}) for
the spaces ${\mathcal{E}}_j,{\mathcal{E}}$, respectively. If ${\mathcal{E}}$ is equipped with
the norm $|\ |$ of $L^2(S^m)$, then
\begin{eqnarray}
c^2=\dim{\mathcal{P}}_n=\sum_{j\in J_n}c_j^2={{m+n}\choose{m}}
\label{csqua},\\
c_j^2=\dim{\mathcal{H}}_{j}=\frac{(m+j-2)!(m+2j-1)}{(m-1)!j!},
\label{cksqua}\\
s_j^2=\frac{j(m+j-1)}{m}\label{snmtk},\\
s^2=\frac{1}{c^2} \sum_{j\in J_n}c_j^2s_j^2
=\frac{n(m+n+1)}{m+2}\label{sjsqu},
\end{eqnarray}
and $\nu_j=\frac{c_j^2}{c^2}$.

Set $K_n=2^{-n}{{\mathord{\Gamma}}}\left(\frac{m+1}{2}\right)$. The coefficients
$\tau_j$ in (\ref{nnorms}) for $|\ |$ and $\wtd{|\ |}$, where
$\wtd{|\ |}$ is defined by (\ref{kosnorm}), are subject to the
formula
\begin{eqnarray}\label{ftauj}
\tau_j=\frac{K_n}{{{\mathord{\Gamma}}}\left(\frac{n-j+2}{2}\right)
{{\mathord{\Gamma}}}\left(\frac{m+n+j+1}{2}\right)}.
\end{eqnarray}
Furthermore, $\td s_j=s_j$,      $\td\nu_j=n!\,\td c_j^2$, where
\begin{eqnarray}
\td c_j^2=\tau_j c_j^2=
\frac{K_n}{(m-1)!}\,\frac{{{\mathord{\Gamma}}}(m+j-1)(m+2j-1)}
{{{\mathord{\Gamma}}}\left(j+1\right){{\mathord{\Gamma}}}\left(\frac{n-j+2}{2}\right)
{{\mathord{\Gamma}}}\left(\frac{m+n+j+1}{2}\right)},\nonumber\\
\td c^2=\frac{1}{n!},\label{tdc}\\
\td s^2=n\label{tds}.
\end{eqnarray}
\end{theorem}
\begin{proof}
For any invariant finite dimensional subspace of $L^2(M)$ the
squared norm of the evaluation functional at a point of $M$ is
equal to the dimension of the space (to prove this, note that the
integral operator with the kernel
$\phi(p,q)={\left<{{\mathop{\mathrm{ev}}\nolimits}_{\mathcal{E}}(p)},{{\mathop{\mathrm{ev}}\nolimits}_{\mathcal{E}}(q)}\right>}$ is the orthogonal
projection onto ${\mathcal{E}}$ and its trace is equal to
$\int_M\phi(p,p)\,dp$.) This proves the first equalities in
(\ref{csqua}) and (\ref{cksqua}) and, together with
(\ref{dimcpn}), (\ref{dimhn}), and (\ref{cjcjsq}) the remainder of
(\ref{csqua}) and (\ref{cksqua}).

Since ${\mathcal{H}}_j$ is the ${{\mathord{\lambda}}}_j$-eigenspace of $-{{\mathord{\Delta}}}$ with
${{\mathord{\lambda}}}_j=j(m+j-1)$, (\ref{snmtk}) is a consequence of
Lemma~\ref{eqisct}.

According to (\ref{cksqua}) and (\ref{snmtk}), (\ref{sjsqu}) is
equivalent to the equality
\begin{eqnarray*}
\sum_{j\in J_n}\frac{(m+j-2)!(m+2j-1)}{(m-1)!j!} \cdot
\frac{j(m+j-1)}{m}= {{m+n}\choose{m}}\cdot \frac{n(m+n+1)}{m+2},
\end{eqnarray*}
where $m\geq2$. Assuming ${n\choose k}=0$ for integer $k<0$ or
$k>n$ (this is true for the analytic extension of ${n\choose k}$
on $k$), we may rewrite this equality as
\begin{eqnarray*}
\sum_{j\in J_n}
\left\{{m+j\choose{m+1}}+{m+j-1\choose{m+1}}\right\}=
{m+n+1\choose{m+2}}.
\end{eqnarray*}
The formula above is equivalent to the following one, which is an
easy consequence of the Pascal Triangle equality:
\begin{eqnarray*}
\sum_{j=1}^n{{m+j}\choose{m+1}}={m+n+1\choose{m+2}}.
\end{eqnarray*}

By definition, $\nu_j=\frac{c_j^2}{c^2}$ (see Lemma~\ref{snusj}).

The equality (\ref{ftauj}) follows from  Lemma~\ref{taukj} with
$k=\frac{n-j}{2}$.  Since the group ${\mathop{\mathrm{SO}}}(m+1)$ is irreducible in
${\mathcal{H}}_j$, $\td c_j^2=\tau_j c_j^2$ and $\td s_j=s_j$ by
Lemma~\ref{eqisct}.

Set $o=(1,0,\dots,0)$. By (\ref{decph}),
$\wtd{{\left<{u},{x_0^n}\right>}}=n!u(o)$ for all monomials $u\in{\mathcal{P}}_n$.
Therefore, $\td\phi(x)=\frac1{n!}x_0^n$,
$\wtd{|\td\phi|}^2=\frac1{n!}$ and (\ref{tdc}) follows.

Due to (\ref{xiphi}), we may compute $s$ applying to $\td \phi_o$ any
vector field $\xi\in{\mathop{\mathrm{so}}}(m+1)$ such that $\xi(o)\neq 0$. Let
$\xi=x_1\frac{\partial}{\partial x_0}-x_0\frac{\partial}{\partial
x_1}$. Then $|\xi(o)|=1$ and we get
\begin{eqnarray}\label{prtds}
\td s^2=\frac{\wtd{|\xi\td\phi_o|}^2}{\td c^2}
=\frac1{n!}\wtd{\big|nx_0^{n-1}x_1\big|}^2 =n.
\end{eqnarray}
This concludes the proof of the theorem.
\end{proof}
An equivalent form of the equality (\ref{tds}) is known from the
paper \cite{Ko93} by Kostlan. In \cite{Po99}, Podkorytov stated
the equality $s^2=\frac{n(n+m+1)}{m+2}$ without proof.

\section{Asymptotic behavior of the coefficients as $n\to\infty$}
Now, our aim is to find the scaling limit of the coefficients
$\td\nu_j=\frac{\td c^2_j}{\td c^2}$. The coefficients  $c_j^2$
and $\tau_j$ (see (\ref{csqua}) and (\ref{ftauj}), respectively)
admit the evident extensions on $j$ onto ${\mathbb{C}}$, which are entire
functions which we shall denote as $c^2({{\mathord{\zeta}}})$ and $\tau({{\mathord{\zeta}}})$.
The function $c^2({{\mathord{\zeta}}})$ is a polynomial of degree $m-1$.
Thus
\begin{eqnarray*}
\td c^2({{\mathord{\zeta}}})=\tau({{\mathord{\zeta}}}) c^2({{\mathord{\zeta}}}),\\
\td\nu({{\mathord{\zeta}}})=n!\,\td c^2({{\mathord{\zeta}}})\phantom{,}
\end{eqnarray*}
are entire functions. In this section, $c^2,\td c^2$ denote the
extensions (thus they are not the sums of $c_j^2$ and $\td c_j^2$
as in the previous one). These functions depend on $m$ and $n$
which we omit in the notation.
Note that $\tau$, $c^2$, and $\td\nu$ are positive on the interval
$(0,n)$.
\begin{lemma}\label{tdcconc}
The function $\ln \td\nu$ is strictly concave on the interval
$(0,n)$ and has the unique maximum on it.
\end{lemma}
\begin{proof}
We have $\ln c^2(x)''<0$ because $c^2$ is a product of linear
functions, for $\ln\tau$ the same is true since $\ln{{\mathord{\Gamma}}}(x)''>0$.
Hence $\ln\td\nu$ is strictly concave.

Suppose that
\begin{eqnarray}\label{tdceq}
\td\nu(x+2)=\td\nu(x)~~\mbox{for some}~x\in(0,n-2).
\end{eqnarray}
Then $\td\nu$ has a critical point
\begin{eqnarray*}
x_c\in(x,x+2)
\end{eqnarray*}
which necessarily is unique and corresponds to the global maximum
on $(0,n)$ since $\ln\td\nu$ is strictly concave. Thus, it is
sufficient to prove (\ref{tdceq}). Set
\begin{eqnarray*}
\rho_n(x)=\frac{\td\nu(x+2)}{\td\nu(x)},
\end{eqnarray*}
where $x$ runs over $(0,n-2)$.  The condition (\ref{tdceq}) is
equivalent to
\begin{eqnarray}\label{rhoton}
\rho_n(x)=1~~\mbox{for some}~x\in(0,n-2).
\end{eqnarray}
According to (\ref{cksqua}) and (\ref{ftauj}),
\begin{eqnarray}
\frac{c(x+2)^2}{c(x)^2}=
\frac{(m+x-1)(m+x)}{(x+1)(x+2)}\cdot\frac{m+2x+3}{m+2x-1},\nonumber\\
\frac{\tau(x+2)}{\tau(x)}=
\frac{{{\mathord{\Gamma}}}\left(\frac{n-x+2}{2}\right){{\mathord{\Gamma}}}\left(\frac{m+n+x+1}{2}\right)}
{{{\mathord{\Gamma}}}\left(\frac{n-x}{2}\right){{\mathord{\Gamma}}}\left(\frac{m+n+x+3}{2}\right)}
=\frac{n-x}{n+x+m+1}.\label{tautau}
\end{eqnarray}
Hence
\begin{eqnarray}\label{rhofo}
\phantom{xxxx} \rho_n(x)=\left(1+\frac{m-2}{x+1}\right)
\left(1+\frac{m-2}{x+2}\right)
\left(1+\frac{2}{x+\frac{m-1}{2}}\right)\frac{n-x}{n+x+m+1}.
\end{eqnarray}
Due to (\ref{assmn}), $\rho_n(0)=\frac{2mn}{m+n+1}>1$. Assuming
$n>3$ and applying (\ref{assmn}) again, we get
\begin{eqnarray*}
\rho_n(n-2)=\frac{2(n+m-3)(n+m-2)}{n(n-1)(2n+m-5)}
<\frac{4(n+m-3)}{n(2n+m-5)}\leq \frac{n+m-3}{2n+m-5}<1.
\end{eqnarray*}
If $n=3$, then $m=2$ and $\rho_n(n-2)=\frac23$.
This proves (\ref{rhoton}) and consequently the lemma.
\end{proof}
Set
\begin{eqnarray}\label{mundew}
\mu_n=\sqrt{(m-1)n},\\
\label{defka} \bar\nu_n=\td\nu(x_c),
\end{eqnarray}
where $x_c$ is the critical point of $\td\nu$ (hence $\bar\nu_n$
is the maximum of $\td\nu(x)$ on $[0,n]$).

In the following theorem, we assume that $\td\nu$ is a function on
$(0,\infty)$ which vanishes outside $(0,n)$.
\begin{theorem}\label{limitnu}
If $n$ is sufficiently large, then
\begin{eqnarray}\label{betwe}
\mu_n-\frac{m+1}{2}<x_c<\mu_n+2.
\end{eqnarray}
For any $t>0$
\begin{eqnarray}\label{limnumu}
\lim_{n\to\infty}\frac{\td\nu(\mu_nt)}{\bar\nu_n} =
\left(t^2e^{1-t^2}\right)^{\frac{m-1}{2}},
\end{eqnarray}
where the sequence on the left converges uniformly on
$(0,\infty)$. Moreover,
\begin{eqnarray}\label{asynun}
\bar\nu_n=\frac{A_m}{\sqrt{n}}(1+o(1)),
\end{eqnarray}
as $n\to\infty$, where
$A_m=\frac{2\sqrt{2}}{{{\mathord{\Gamma}}}\left(\frac{{m}}{2}\right)}
\left(\frac{m-1}{2e}\right)^{\frac{m-1}{2}}$.
\end{theorem}
\begin{proof}
Setting $x=a\sqrt{n}$ in factors of $\rho_n$, we get
\begin{eqnarray*}
1+\frac{m-2}{a\sqrt{n}+1}=1+\frac{m-2}{a\sqrt{n}}
-\frac{m-2}{a^2n}+O\left(n^{-\frac32}\right),\\
1+\frac{m-2}{a\sqrt{n}+2}=1+\frac{m-2}{a\sqrt{n}}
-\frac{2(m-2)}{a^2n}+O\left(n^{-\frac32}\right),\\
1+\frac{4}{m+2a\sqrt{n}-1}=1+\frac{2}{a\sqrt{n}}
-\frac{m-1}{a^2n}+O\left(n^{-\frac32}\right),\\
\frac{n-a\sqrt{n}}{n+a\sqrt{n}+m+1}=\frac{1-\frac{a}{\sqrt{n}}}
{1+\frac{a}{\sqrt{n}}+\frac{m+1}{n}} =1-\frac{2a}{\sqrt{n}}
+\frac{2a^2-m-1}{n}\\
+O\left(n^{-\frac32}\right).
\end{eqnarray*}
Hence
\begin{eqnarray*}
\rho_n(a\sqrt{n})=1+\left(\frac{2(m-1)}{a}-2a\right)\frac1{\sqrt{n}}
+O\left(\frac1n\right).
\end{eqnarray*}
Therefore,
\begin{eqnarray*}
\rho_n(a\sqrt{n})=1+O\left(\frac1n\right)~~~\Longleftrightarrow~~~
a=\sqrt{m-1}.
\end{eqnarray*}
Thus $\mu_n$ can be considered as an approximation of $x_c$.
According to the calculation above,
\begin{eqnarray}\label{muas}
\rho_n(\mu_n)=1-\frac{2(m+1)}{n}+ O\left(n^{-\frac32}\right).
\end{eqnarray}
It follows that
\begin{eqnarray}\label{rhomuo}
\rho_n(\mu_n)<1
\end{eqnarray}
for sufficiently large $n$.
The function $\rho_n$ is positive, decreasing, and convex since
each factor in (\ref{rhofo}) possesses these properties (the
factors are convex because all of them may be written as
$\pm1+\frac{a}{x+b}$, where $a>0$).
Thus (\ref{rhomuo}) gives an upper bound for $x_c$:
\begin{eqnarray*}\label{xclemun}
x_c<\mu_n+2.
\end{eqnarray*}
To find a lower bound, we do one step of the Newton method:
\begin{eqnarray*}
\eta_n=\mu_n-\frac{\rho_n(\mu_n)-1}{\rho_n'(\mu_n)}<x_c.
\end{eqnarray*}
Since $\rho_n$ is convex and decreasing, $\rho_n(\eta_n)>1$. Hence
$x_c>\eta_n$. We shall replace $\eta_n$ with a simpler term which
is asymptotic to it as $n\to\infty$. Due to (\ref{muas}), it is
sufficient to do this for $\rho_n'(\mu_n)$. Let us  consider
$(\ln\rho_n)'$. For the first three factors in (\ref{rhofo}) we
may use the equality
$\ln\left(1+\frac{a}{x+b}\right)'=-\frac{a}{(x+a)(x+a+b)}
=-\frac{a}{x^2}+O\left(x^{-3}\right)$ as $x\to\infty$. The
logarithmic derivative of the forth one is equal to
$\frac{2n+m+1}{(n-x)(n+x+m+1)}$. Setting $x=\mu_n$, we get
\begin{eqnarray*}
\frac{\rho_n'(\mu_n)}{\rho_n(\mu_n)}=-\left(2\cdot\frac{m-2}{\mu_n^2}
+\frac{2}{\mu_n^2}+\frac{2}{n}\right)+O\left(n^{-\frac32}\right)
=-\frac{4}{n}+O\left(n^{-\frac32}\right).
\end{eqnarray*}
Together with (\ref{mundew}) and (\ref{muas}), this implies
\begin{eqnarray}\label{rhopmn}
\rho_n'(\mu_n)=-\frac4n+O\left(n^{-\frac32}\right).
\end{eqnarray}
Therefore,
\begin{eqnarray*}
\mu_n-\eta_n=\frac{\rho_n(\mu_n)-1}{\rho_n'(\mu_n)}=\frac{m+1}{2}
+O\left(n^{-\frac32}\right).
\end{eqnarray*}
A straightforward computation shows that
\begin{eqnarray*}
\lim_{n\to\infty}
n^{\frac32}\left(\rho_n\left(\mu_n-\frac{m+1}{2}\right)-1\right)
=\frac{m(m+1)}{\sqrt{m-1}}.
\end{eqnarray*}
Hence $\rho_n\left(\mu_n-\frac{m+1}{2}\right)>1$ for sufficiently
large $n$. This proves (\ref{betwe}).\footnote{actually,
$\mu_n-\frac{m-1}{2}$ is a good approximation of $x_c$ for large
$n$ since it is the center of the interval $(\eta_n,\eta_n+2)$ and
$\eta_n$ is close to the solution of the equation $\rho_n(x)=1$}

\smallskip

The following equalities can be proved by a straightforward
computation:
\begin{eqnarray}
\lim_{n\to\infty}\rho_n(\mu_nx)=1,\label{limrmux}\\
\lim_{n\to\infty} \mu_n\ln\rho_n(\mu_n
x)=2(m-1)\left(\frac1x-x\right),\nonumber
\end{eqnarray}
and the convergence is locally uniform on $(0,\infty)$. The
sequence of piecewise constant functions defined by the equality
\begin{eqnarray}\label{deffn}
f_n(\xi)=\mu_n\ln\rho_n(i)
\end{eqnarray}
for $\xi\in\left(\frac{i-2}{\mu_n},\frac{i}{\mu_n}\right]$, where
$i\in J_n$, converges to $2(m-1)\left(\frac1\xi-\xi\right)$
locally uniformly on $(1,t)$.  Thus,
\begin{eqnarray*}
\int_1^tf_n(\xi)\,d\xi=\frac2{\mu_n}\sum_{i\in J_n,\atop i<\mu_n
t}
\mu_n\ln\rho_n(i)+O\left(n^{-\frac12}\right)= 2\ln \prod_{i\in
J_n,\atop i<\mu_n t}\rho_n(i)+O\left(n^{-\frac12}\right),\\
\lim_{n\to\infty}\ln\frac{\td\nu(\mu_nt)}{\td\nu(\mu_n)}
=\lim_{n\to\infty}\ln \prod_{\mu_n<i<\mu_nt,\atop
n-i~\mbox{\rm\tiny even}}\rho_n(i)
=\frac12\lim_{n\to\infty}\int_1^tf_n(\xi)\,d\xi
\\
=(m-1)\int_1^t\left(\frac1\xi-\xi\right)\,d\xi=\frac{m-1}2(1+2\ln
t-t^2).
\end{eqnarray*}
Here and in what follows, we use Lebesgue's Dominated Convergence
Theorem with the majorant of the type $Ke^{-\eta t}$. The
convergence is locally uniform. Due to (\ref{betwe}),
\begin{eqnarray}\label{barmunu}
\lim_{n\to\infty}\frac{\td\nu(\mu_n)}{\bar\nu_n}
=\lim_{n\to\infty}\frac{\td\nu(\mu_n)}{\td\nu(x_c)}=1.
\end{eqnarray}
Therefore, $\lim_{n\to\infty}\frac{\td\nu(\mu_nt)}{\bar\nu_n}
=\left(t^2e^{1-t^2}\right)^{\frac{m-1}{2}}$ for any $t>1$. The
arguments above with minor changes can be extended onto the case
$0<t\leq1$. Thus (\ref{limnumu}) holds for all $t>0$.  The
sequence $\frac{\td\nu(\mu_nt)}{\bar\nu_n}$ converges uniformly on
any compact interval in $(0,\infty)$. Since $\ln\td\nu(\mu_nt)$ is
concave and $\td\nu(\mu_nt)$ is positive and has maximum near $1$,
this implies the uniform convergence on $(0,\infty)$.

Further,
\begin{eqnarray*}
\lim_{n\to\infty}\frac{2}{\mu_n}\sum_{i\in J_n}
\left(\frac{j^2}{\mu_n^2}
e^{1-\frac{j^2}{\mu_n^2}}\right)^{\frac{m-1}{2}} =\int_0^\infty
\left(t^2e^{1-t^2}\right)^{\frac{m-1}{2}}\,dt
=\frac{{{\mathord{\Gamma}}}\left(\frac{m}{2}\right)}{2\sqrt{e}}
\left(\frac{2e}{m-1}\right)^{\frac{m}{2}}.
\end{eqnarray*}
On the other hand, the equality $\sum_{0\leq j\leq n,\atop
n-i~\mbox{\rm\tiny even}}\td\nu_j=1$, (\ref{limnumu}), and
Lebesgue's Dominated Convergence Theorem imply
\begin{eqnarray*}
\lim_{n\to\infty}\bar\nu_n\sum_{i\in J_n}\left(\frac{j^2}{\mu_n^2}
e^{1-\frac{j^2}{\mu_n^2}}\right)^{\frac{m-1}{2}}=1.
\end{eqnarray*}
Computing the ratio of the left-hand parts of the equalities
above, we get
\begin{eqnarray} \label{limnumun}
\lim_{n\to\infty}\bar\nu_n\mu_n=
\frac{4\sqrt{e}}{{{\mathord{\Gamma}}}\left(\frac{m}{2}\right)}
\left(\frac{m-1}{2e}\right)^{\frac{m}{2}}=A_m\sqrt{m-1}.
\end{eqnarray}
This proves (\ref{asynun}) and the theorem.
\end{proof}
The constant $A_m$ in (\ref{asynun}) decreases when $m$ grows and
\begin{eqnarray*}
\lim_{m\to\infty}A_m=\frac{2}{\sqrt{\pi}}.
\end{eqnarray*}
Since $m\geq2$, this implies the inequalities
\begin{eqnarray}\label{ineqam}
\frac{2}{\sqrt{\pi}}<A_m\leq\frac{2}{\sqrt{e}}
\end{eqnarray}
We omit the proof which is standard.

Modifying the arguments above slightly, it is possible to find an
upper bound for the ratio $\frac{\td\nu(j)}{\td\nu(\mu_n)}$.
\begin{proposition}\label{nuabove}
Set $j_n=\min\{j\in J_n:\,j>\mu_n\}$ and let $j\in J_n$, $j>j_n$.
Then
\begin{eqnarray}\label{estnuab}
\frac{\td\nu(j+2)}{\td\nu(j_n+2)}
<\frac{j^{m-1}}{j_n^{m-1}}e^{\frac{j_n^2-j^2}{2n}}.
\end{eqnarray}
\end{proposition}
\begin{proof}
Since $\rho_n(x)$ decreases on $(0,n)$,
\begin{eqnarray}\label{lnrhole}
\int_{j_n}^{j}\ln\rho_n(x)\,dx>2\sum_{i\in J_n,\atop i<
j}\ln\rho_n(i+2)= 2\ln\frac{\td\nu(j+2)}{\td\nu(j_n+2)}.
\end{eqnarray}
The inequality $\ln(1+x)<x$ and (\ref{rhofo}) imply
\begin{eqnarray*}
\ln\rho_n(x)<\frac{m-2}{x+1}+\frac{m-2}{x+2}+\frac{4}{2x+m-1}
-\ln\frac{n+x+m+1}{n-x}.
\end{eqnarray*}
Due to the evident inequality
$\frac{m-2}{x+1}+\frac{m-2}{x+2}+\frac{2}{x+\frac{m-1}{2}}
<\frac{2(m-1)}{x}$, for the integral of the sum of the first three
terms we have the upper bound
\begin{eqnarray*}
2(m-1)\int_{j_n}^{j}\frac{dx}{x} =2(m-1)\ln\frac{j}{j_n}.
\end{eqnarray*}
If $0<t<1$, then $\ln\frac{1+t}{1-t}>2t$. Setting $t=\frac{x}{n}$,
we get the inequality $\ln\frac{n+x+m+1}{n-x}>\frac{2x}{n}$.
Therefore,
\begin{eqnarray}\label{estrtau}
\int_{j_n}^j\ln\frac{n+x+m+1}{n-x}\,dx>\frac{j^2-j_n^2}{n}.
\end{eqnarray}
Thus,
\begin{eqnarray*}
\int_{j_n}^j\ln\rho_n(x)\,dx<2(m-1)\ln\frac{j}{j_n}+\frac{j_n^2-j^2}{n}.
\end{eqnarray*}
Together with (\ref{lnrhole}), this implies (\ref{estnuab}).
\end{proof}

\section{Approximation by polynomials of lower degree}
Let $x$ be the Kostlan--Shub--Smale random polynomial in ${\mathcal{P}}_n$.
In this section, we show that $x$ admits a good approximation on
$S^m$ by polynomials of degree less than $n$ (for example, near
$\sqrt{(m+1)n\ln n}$ in the norm of $L^2(S^m)$). This is a kind of
the compromise between the concentration measure phenomenon in the
spheres $\td{\mathcal{S}}$ and the fast decay of the coefficients $\nu_j$.
We estimate the expectation of
$\frac{{\mathrm{dist}}_X(x,{\mathcal{P}}_{l_n})}{\|x\|_X}$ and the probability of the
inequality ${\mathrm{dist}}_X(x,{\mathcal{P}}_{l_n})<{{\mathord{\varepsilon}}}\|x\|_X$, where $X$ is the
Sobolev space $H^q=H^q(S^m)$,  $q\geq0$,
with the norm
\begin{eqnarray*}
|u|_q=\Big(|u_0|^2+\sum_{j=1}^\infty j^{2q}|u_j|^2\Big)^{\frac12}.
\end{eqnarray*}
If $j>m-1$, then $j^2<{{\mathord{\lambda}}}_j<2j^2$, where ${{\mathord{\lambda}}}_j=j(j+m-1)$ is the
$j$th eigenvalue of the Laplace--Beltrami operator ${{\mathord{\Delta}}}$ on $S^m$.
Hence $|u|_q$ is equivalent to the norm
\begin{eqnarray*}
\Big(|u_0|^2+|(-{{\mathord{\Delta}}})^{\frac{q}{2}}u|^2\Big)^{\frac12}
=\Big(|u_0|^2+\sum_{j=0}^\infty{{\mathord{\lambda}}}_j^q|u_j|^2\Big)^{\frac12}
\end{eqnarray*}
Clearly, $H^0=L^2(S^m)$.

\begin{lemma}\label{jqtau}
For all sufficiently large $n$ the function ${{\mathord{\alpha}}}(x)=x^{2q}\tau(x)$
strictly decreases on the interval $(\sqrt{2qn}+2,n)$.
\end{lemma}
\begin{proof}
Since $\ln{{\mathord{\Gamma}}}$ is strictly convex, the function $\ln\tau(x)$  is
strictly concave on $(0,n)$. Hence the same is true for
$\ln{{\mathord{\alpha}}}(x)$.  Set
\begin{eqnarray*}
{{\mathord{\varphi}}}(x)=\frac{{{\mathord{\alpha}}}(x+2)}{{{\mathord{\alpha}}}(x)}
=\left(1+\frac{2}{x}\right)^{2q}\frac{n-x}{n+x+m+1}.
\end{eqnarray*}

Let $q>0$. Then ${{\mathord{\varphi}}}(x)\to\infty$ as $x\to0$. Hence the inequality
${{\mathord{\varphi}}}(a)<1$ for $a\in(0,n)$ implies ${{\mathord{\varphi}}}(b)=1$ for some
$b\in(0,a)$. Hence ${{\mathord{\alpha}}}$ has a critical point in $(b,b+2)$.
Therefore, ${{\mathord{\alpha}}}$ decreases on $(a+2,n)$ if ${{\mathord{\varphi}}}(a)<1$. A
calculation shows that
\begin{eqnarray*}
{{\mathord{\varphi}}}(\sqrt{2qn})=1-\left(m+1+\frac{1}{q}\right)\frac{1}{n}
+O\left(n^{-\frac32}\right).
\end{eqnarray*}
Hence ${{\mathord{\varphi}}}(\sqrt{2qn})<1$ for large $n$.

If $q=0$, then ${{\mathord{\alpha}}}(x)=\tau(x)$. Since
$(\ln\tau)'(x)=\frac12\Psi\left(\frac{n-x+2}{2}\right)
-\frac12\Psi\left(\frac{n+x+m+1}{2}\right)$, where
$\Psi=(\ln{{\mathord{\Gamma}}})'$, and $(\ln{{\mathord{\Gamma}}})''(x)>0$, we get $\tau'(x)<0$ for
all $x>0$. This concludes the proof of the lemma.
\end{proof}

\begin{lemma}
Let $x=x_1\oplus x_2\oplus x_3$ correspond to the decomposition
${\mathbb{R}}^d={\mathbb{R}}^{d_1}\oplus{\mathbb{R}}^{d_2}\oplus{\mathbb{R}}^{d_3}$, $a>-d_1$, and
$d_2>2$. Then
\begin{eqnarray}\label{doned}
\int_{S^{d-1}}|x_1|^a\,dx=
\frac{{{\mathord{\Gamma}}}\left(\frac{d_1+a}{2}\right){{\mathord{\Gamma}}}\left(\frac{d}{2}\right)}
{{{\mathord{\Gamma}}}\left(\frac{d+a}{2}\right){{\mathord{\Gamma}}}\left(\frac{d_1}{2}\right)},\\
\label{frain}\int_{S^{d-1}}\frac{|x_1|^2}{|x_2|^2}\,dx=
\frac{d_1}{d_2-2}.
\end{eqnarray}
\end{lemma}
\begin{proof}
Clearly, for any homogeneous of degree ${{\mathord{\alpha}}}$ continuous function
$f$ on ${\mathbb{R}}^d$
\begin{eqnarray}\label{ihoma}
\int_{{\mathbb{R}}^d} f(x)e^{-|x|^2}\,dx
=\frac{\varpi_{d-1}}{2}{{\mathord{\Gamma}}}\left(\frac{d+{{\mathord{\alpha}}}}{2}\right)
\int_{S^{d-1}}f(\xi)\,d\xi,
\end{eqnarray}
where
$\varpi_k=\frac{2\pi^{\frac{k+1}{2}}}{{{\mathord{\Gamma}}}\left(\frac{k+1}{2}\right)}$
is the volume of the sphere $S^k$ and $dx$, $d\xi$ stand for the
Lebesgue measure on ${\mathbb{R}}^d$ and the invariant probability measure
on $S^{d-1}$, respectively. Hence
\begin{eqnarray*}
\int_{{\mathbb{R}}^d}|x_1|^ae^{-|x|^2}\,dx=\frac{\varpi_{d-1}}{2}
{{\mathord{\Gamma}}}\left(\frac{d+a}{2}\right)\int_{S^{d-1}}|\xi_1|^a\,d\xi
=\pi^{\frac{d}{2}}\frac{{{\mathord{\Gamma}}}\left(\frac{d+a}{2}\right)}
{{{\mathord{\Gamma}}}\left(\frac{d}{2}\right)} \int_{S^{d-1}}|\xi_1|^a\,d\xi.
\end{eqnarray*}
In particular, for $a=0$ we get $\pi^{\frac{d}{2}}$. On the other
hand,
\begin{eqnarray*}
\int_{{\mathbb{R}}^d}|x_1|^ae^{-|x|^2}\,dx
=\int_{{\mathbb{R}}^{d_2+d_3}}e^{-|x_2|^2-|x_3|^2}\,dx_2
\int_{{\mathbb{R}}^{d_1}}|x_1|^ae^{-|x_1|^2}\,dx_1 =\pi^{\frac{d}{2}}
\frac{{{\mathord{\Gamma}}}\left(\frac{d_1+a}{2}\right)}{{{\mathord{\Gamma}}}\left(\frac{d_1}{2}\right)}
\end{eqnarray*}
and (\ref{doned}) follows. Similarly,
$\int_{{\mathbb{R}}^d}\frac{|x_1|^2}{|x_2|^2}e^{-|x|^2}\,dx
=\pi^{\frac{d}{2}}\int_{S^{d-1}}\frac{|x_1|^2}{|x_2|^2}\,dx$ by
(\ref{ihoma}) and
\begin{eqnarray*}
\int_{{\mathbb{R}}^d}\frac{|x_1|^2}{|x_2|^2}e^{-|x|^2}\,dx=
\int_{{\mathbb{R}}^{d_1}}|x_1|^2e^{-|x_1|^2}\,dx_1
\int_{{\mathbb{R}}^{d_2}}|x_2|^{-2}e^{-|x_2|^2}\,dx_2
\int_{{\mathbb{R}}^{d_3}}e^{-|x_3|^2}\,dx_3\\
=\pi^{\frac{d_1}{2}}\frac{{{\mathord{\Gamma}}}\left(\frac{d_1+2}{2}\right)}
{{{\mathord{\Gamma}}}\left(\frac{d_1}{2}\right)}\cdot
\pi^{\frac{d_2}{2}}\frac{{{\mathord{\Gamma}}}\left(\frac{d_2-2}{2}\right)}
{{{\mathord{\Gamma}}}\left(\frac{d_2}{2}\right)}\cdot \pi^{\frac{d_3}{2}}=
\pi^{\frac{d}{2}}\frac{d_1}{d_2-2}.
\end{eqnarray*}
This proves (\ref{frain}).
\end{proof}

\begin{theorem}\label{lower}
Let $l_n$ be a sequence of positive integers such that $l_n<n$,
\begin{eqnarray}
\limsup_{n\to\infty}\frac{l_n}{n}<1,\label{boulnn}\\
\lim_{n\to\infty}n^{m+2q}e^{-\frac{l_n^2}{n}}=0.\label{lngrow}
\end{eqnarray}
Suppose that $t_n>0$ satisfy the conditions
\begin{eqnarray}\label{condt}
\lim_{n\to\infty}n^mt_n^{-4}
=\lim_{n\to\infty}t_n^4n^{2q}e^{-\frac{l_n^2}{n}}=0.
\end{eqnarray}
Then there exist $A,B>0$, where $A$ depends only on $q$ and $B$
only on the sequence $l_n$, such that for
\begin{eqnarray*}
\eta_n=An^{\frac{m}{2}}t_n^{-2},\\
{{\mathord{\varepsilon}}}_n=Bt_nn^{\frac{q}{2}}e^{-\frac{l_n^2}{4n}}
\end{eqnarray*}
we have $\lim_{n\to\infty}{{\mathord{\varepsilon}}}_n=\lim_{n\to\infty}\eta_n=0$ and for
all sufficiently large $n$ the inequality
\begin{eqnarray}\label{distvx}
{\mathrm{dist}}_{H^q}(x,{\mathcal{P}}_{l_n})<{{\mathord{\varepsilon}}}_n|x|,
\end{eqnarray}
holds for the random Kostlan--Shub--Smale polynomial $x\in{\mathcal{P}}_n$
with the probability greater than $1-\eta_n$.
\end{theorem}
\begin{proof}
First of all, we note that (\ref{condt}) implies
${{\mathord{\varepsilon}}}_n,\eta_n\to0$ as $n\to\infty$.

Let $J_n$ be defined by (\ref{defjnz}). We consider the partition
of $J_n$ by the following subsets of $[0,n]$:
$I_1=[\sqrt{2qn},a\sqrt{n}]$, where $a>\sqrt{2q}$, $I_3=[l_n,n]$,
where $l_n>a\sqrt{n}$, and $I_2=[0,n]\setminus(I_1\mathop\cup
I_3)$.
Set
\begin{eqnarray}\label{decuzv}
{\mathcal{P}}_n={\mathcal{U}}_n\oplus{\mathcal{Z}}_n\oplus{\mathcal{V}}_n,
\end{eqnarray}
where each summand is the sum of the spaces ${\mathcal{H}}_j$ with $j$
running over the intersection of $J_n$ with one the sets
$I_1,I_2,I_3$, respectively. For $x\in{\mathcal{P}}_n$, let $x=u+z+v$ be the
corresponding decomposition. Then
\begin{eqnarray*}
|v|_q={\mathrm{dist}}_{H^q}(x,{\mathcal{P}}_{l_n})
\end{eqnarray*}
since the decomposition (\ref{harmdec}) is orthogonal in the
involved inner products. We shall estimate the probability of the
inequality $|v|<{{\mathord{\varepsilon}}}_n|x|$ reducing it to the inequality
$\wtd{|v|}< t_n\wtd{|u|}$ and estimating the expectation of the
ratio $\wtd{|v|}^2/\wtd{|u|}^2$. Since it is homogeneous of degree
$0$, its distribution for the Kostlan--Shub--Smale model and for
the uniform distribution in the unit sphere $\td{\mathcal{S}}$ coincide. We
denote by $\td{{\mathord{\sigma}}}$ the invariant probability measure on $\td{\mathcal{S}}$.
By (\ref{frain}),
\begin{eqnarray}\label{expecvu}
{{\mathsf{M}}}\left(\wtd{|v|}^2/{\wtd{|u|}^{2}}\right)
=\frac{\dim{\mathcal{V}}_n}{\dim\,{\mathcal{U}}_n-2}.
\end{eqnarray}
According to the decomposition (\ref{harmdec}),
\begin{eqnarray*}
\dim\,{\mathcal{U}}_n\geq\dim{\mathcal{P}}_{[a\sqrt{n}]-1}-\dim{\mathcal{P}}_{[\sqrt{2qn}]}.
\end{eqnarray*}
If $q=0$, then $\dim\,{\mathcal{U}}_n\geq\dim{\mathcal{P}}_{[a\sqrt{n}]-1}$ since
$\tau(x)$ decreases on $(0,\infty)$ (see proof of
Lemma~\ref{jqtau}). Replacing ${\mathcal{V}}_n$ with ${\mathcal{P}}_n$ in
(\ref{expecvu}), we get
\begin{eqnarray*}
\limsup_{n\to\infty}n^{-\frac{m}{2}}
{{\mathsf{M}}}\left({\wtd{|v|}^2}/{\wtd{|u|}^{2}}\right)\leq
\lim_{n\to\infty}\frac{\dim{\mathcal{P}}_n}{n^{\frac{m}{2}}\dim\,{\mathcal{U}}_n}
=\frac{1}{a^m-(2q)^{\frac{m}{2}}}.
\end{eqnarray*}
In particular, for $q=0$ we get the lower bound $a^{-m}$. Set
\begin{eqnarray*}
\td V_{t,l}=\{x\in\td{\mathcal{S}}:\,\wtd{|v|}>t\wtd{|u|}\}.
\end{eqnarray*}
Due to the Chebyshev inequality,
\begin{eqnarray}\label{bgramq}
A>\frac{1}{a^m-(2q)^{\frac{m}{2}}}\kern12pt\Longrightarrow\kern12pt
\td{{\mathord{\sigma}}}\left(\td
V_{t_n,l_n}\right)<An^{\frac{m}{2}}t_n^{-2}\label{tnnmin}
\end{eqnarray}
for all sufficiently large $n$. By (\ref{condt}), $\td{{\mathord{\sigma}}}\left(\td
V_{t_n,l_n}\right)\to0$ as $n\to\infty$. Let
$a>2^{\frac1{m}}\sqrt{2q}$. Then
$a^m-(2q)^{\frac{m}{2}}>(2q)^{\frac{m}{2}}$. Thus for
$A=(2q)^{-\frac{m}{2}}$ the inequality on the right of
(\ref{bgramq}) holds for all sufficiently large $n$.

By Lemma~\ref{jqtau}, ${{\mathord{\alpha}}}$ decreases on $(\sqrt{2qn}+2,n)$. Since
\begin{eqnarray*}\label{tdtolt}
\begin{array}{r}
|v|_q^2=\sum\limits_{j\in J_n\cap I_3}{{\mathord{\alpha}}}(j)\wtd{|v_j|}^2,\\
|u|_q^2=\sum\limits_{j\in J_n\cap I_1}{{\mathord{\alpha}}}(j)\wtd{|u_j|}^2,
\end{array}
\end{eqnarray*}
where the indices correspond to the decomposition (\ref{harmdec}),
we get
\begin{eqnarray*}\label{vkineq}
\begin{array}{r}
|v|_q^2<{{\mathord{\alpha}}}(l_n)\wtd{|v|}^2,\\%=l_n^q\tau(l_n)\wtd{|v|}^2,\\
|u|_q^2>{{\mathord{\alpha}}}(a\sqrt{n})\wtd{|u|}^2.
\end{array}
\end{eqnarray*}
if $v\neq$ and $u\neq0$ (we shall assume this in the sequel;
clearly, this does not affect the result). Therefore, $x\notin\td
V_{t_n,l_n}$ implies
\begin{eqnarray}\label{vquqtn}
|v|_q^2
<t_n^2\frac{{{\mathord{\alpha}}}(l_n)}{{{\mathord{\alpha}}}(a\sqrt{n})}|u|_q^2
=t_n^2\left(\frac{l_n^2}{a^2n}\right)^q
\frac{\tau(l_n)}{\tau(a\sqrt{n})}|u|_q^2.
\end{eqnarray}
The ratio $\frac{\tau(l_n)}{\tau(a\sqrt{n})}$ can be estimated as
in Proposition~\ref{nuabove}. The arguments which prove the
inequality (\ref{estrtau}) show that
\begin{eqnarray}\label{lntauaa}
\ln\frac{\tau(l_n+2)}{\tau(a\sqrt{n}+2)}<
{-\int_{a\sqrt{n}}^{l_n}\ln\frac{n+x+m+1}{n-x}\,dx}
<{\frac{a^2}{2}-\frac{l_n^2}{2n}}.
\end{eqnarray}
According to (\ref{tautau}),
$\lim_{n\to\infty}\frac{\tau(a\sqrt{n}+2)}{\tau(a\sqrt{n})}=1$.
Due to (\ref{tautau}) and  and (\ref{boulnn}), for some $b>1$
\begin{eqnarray*}
\limsup_{n\to\infty}\frac{\tau(l_n+2)}{\tau(l_n)}>\frac1b.
\end{eqnarray*}
Hence
\begin{eqnarray}\label{easqtau}
\limsup_{n\to\infty}\frac{\tau(l_n)e^{\frac{l_n^2}{2n}}}{\tau(a\sqrt{n})}
=\limsup_{n\to\infty}\frac{\tau(l_n+2)e^{\frac{l_n^2}{2n}}}{\tau(a\sqrt{n}+2)}
\cdot\frac{\tau(l_n)}{\tau(l_n+2)}\cdot\frac{\tau(a\sqrt{n}+2)}{\tau(a\sqrt{n})}
<be^{\frac{a^2}{2}}.
\end{eqnarray}
If $q=0$, then $\left(\frac{l_n^2}{a^2n}\right)^q=1$ and we may
choose arbitrary $a>0$. Thus, the inequality
\begin{eqnarray}\label{vqaquq}
|v|_q^2<Bt_n^2n^qe^{-\frac{l_n^2}{2n}}|u|_q^2
\end{eqnarray}
holds for all sufficiently large $n$ if $B=2b$ and $x\notin\td
V_{t_n,l_n}$ by (\ref{vquqtn}) and (\ref{easqtau}) (we put
$a=\sqrt{2\ln2}$). Let $q>0$. The evident inequality
$\frac{l^2_n}{n}<n$ implies
$\left(\frac{l_n^2}{a^2n}\right)^q<a^{-2q}n^q$. By (\ref{vquqtn})
and the inequalities above, (\ref{vqaquq}) is true provided that
\begin{eqnarray*}
B>a^{-2q}be^{\frac{a^2}{2}}.
\end{eqnarray*}
Set $a=2\sqrt{q}$. Then $a^{-2q}e^{\frac{a^2}{2}}=e^{2q(1-\ln
2-\frac12\ln q)}$. The function on the right attains its maximal
value at $q=\frac{e}{4}$. It is approximately equal to $1.97<2$.
Thus the setting $B=2b$ satisfies (\ref{vqaquq}) for $x\notin\td
V_{t_n,l_n}$ and all $q\geq0$ if $n$ is sufficiently large. This
concludes the proof of the theorem.
\end{proof}

 Note that ${{\mathord{\varepsilon}}}_n^4\eta^2$ is equal to the expression under the
limit in (\ref{lngrow}) up to a multiplicative constant depending
only on $m$ and $q$. Hence neither ${{\mathord{\varepsilon}}}_n^4$ nor $\eta_n^2$ cannot
decay faster than $n^{m+2q}e^{-\frac{l_n^2}{n}}$. For example, if
$l_n=\sqrt{(m+2q+1)n\ln n}$, then
$n^{m+2q}e^{-\frac{l_n^2}{n}}=\frac1{n}$. For  $t_n=n^a$ we get
$\eta_n=An^{\frac{m}{2}-2a}$, ${{\mathord{\varepsilon}}}_n=Bn^{a-\frac{m+1}{4}}$, and
(\ref{condt}) is true if $m<4a<m+1$.

For the ratio of the expectations the estimate is better a bit.

\begin{proposition}\label{approx}
Let $u$ be a random polynomial uniformly distributed in the unit
sphere $\wtd{\mathcal{S}}\subseteq{\mathcal{P}}_n$  for the norm $\wtd{|\ |}$ and
$X=L^2(S^m)$. Let $t>1$, $l_n\in J_n$, and $l_n>t\mu_n$. Then
\begin{eqnarray*}
{{\mathsf{M}}}(|u|^2)=\frac{m!}{(n+m)!}
\end{eqnarray*}
and, for all sufficiently large $n$,
\begin{eqnarray*}
{{\mathsf{M}}}({\mathrm{dist}}_X(u,{\mathcal{P}}_l)^2)<
\frac{e^{-\frac{m-1}{2}(t-1)^2}}{\sqrt{2e(m-1)}\,(t-1)}
{{\mathsf{M}}}(|u|^2).
\end{eqnarray*}
\end{proposition}
\begin{proof}
Clearly, ${\mathrm{dist}}_X(u,{\mathcal{P}}_{l_n})^2=\sum\limits_{j\in
J_n,~~j>l_n}|u_j|^2$. Thus
\begin{eqnarray*}
{{\mathsf{M}}}\left({\mathrm{dist}}_X(u,{\mathcal{P}}_{l_n})^2\right)=\sum\limits_{j\in
J_n,~~j>l_n}\int_{\wtd S}|u_j|^2\,du=\sum\limits_{j\in
J_n,~~j>l_n}\tau_j\int_{\wtd S}\wtd{|u_j|}^2\,du
=\sum\limits_{j\in
J_n,~~j>l_n}\frac{\tau_jc_j^2}{c^2}\\
=\frac{\td c^2}{c^2}\sum\limits_{j\in J_n,~~j>l_n}\td\nu_j,
\end{eqnarray*}
where we use (\ref{doned}), (\ref{csqua}), and (\ref{cksqua}).
The calculation above can be performed for the set $J_n$ as well. Hence
\begin{eqnarray*}
{{\mathsf{M}}}\left(|u|^2\right)=\frac{\td c^2}{c^2}=\frac{m!}{(n+m)!}.
\end{eqnarray*}
We use  (\ref{tdc}), (\ref{csqua}), and the equality  $\sum_{j\in
J_n}\td\nu_j=1$. Since $t>1$ and $l_n>t\mu_n$, we may apply
Proposition~\ref{nuabove} for large $n$. Hence, for all $j>l_n$
\begin{eqnarray*}
\td\nu_{j+2}<\bar\nu_n
\left(\frac{j}{\mu_n}\right)^{m-1}e^{-\frac{j^2-\mu_n^2}{2n}}
=\bar\nu_n\left(x^2e^{1-x^2}\right)^{\frac{m-1}{2}},
\end{eqnarray*}
where we denote $x=\frac{j}{\mu_n}$. Using the elementary
inequality
$t^2e^{1-t^2}<e^{-(t-1)^2}$,
which holds for all $t>0$, $t\neq1$, we get
\begin{eqnarray*}
\sum\limits_{j\in J_n,~~j>l_n}\td\nu_j <{}\bar\nu_n
\sum\limits_{j\in J_n,~~j>l_n}
\left(\frac{j^2}{\mu_n^2}e^{1-\frac{j^2}{\mu_n^2}}\right)^{\frac{m-1}{2}}
<\frac{\bar\nu_n\mu_n}{2}\int_{l_n}
\left(x^2e^{1-x^2}\right)^{\frac{m-1}{2}}\,dx
\\
<\frac{\bar\nu_n\mu_n}{2}\int_t^\infty
e^{-\frac{m-1}{2}(x-1)^2}\,dt
=\frac{\bar\nu_n\mu_n}{\sqrt{2(m-1)}}
\int_{\sqrt{\frac{m-1}{2}}(t-1)}^\infty e^{-\xi^2}\,d\xi
\end{eqnarray*}
where we substitute $\xi=\sqrt{\frac{m-1}{2}}(t-1)$. Since
$\int_a^\infty e^{-\xi^2}\,d\xi=\frac{1}{2a}e^{-a^2}(1+o(1))$ as
$a\to\infty$ and
$\frac{\bar\nu_n\mu_n}{\sqrt{2(m-1)}}\leq\sqrt{\frac{2}{e}}(1+o(1))$
by (\ref{asynun}) and (\ref{ineqam}), we get for any ${{\mathord{\varepsilon}}}>0$ and
all sufficiently large $n$
\begin{eqnarray*}
\sum\limits_{j\in J_n,~~j>l_n}\td\nu_j
<\left(\sqrt{\frac{2}{e}}+{{\mathord{\varepsilon}}}\right)\frac{e^{-a^2}}{2a},
\end{eqnarray*}
where $a=\sqrt{\frac{m-1}{2}}(t-1)$. Moreover, ${{\mathord{\varepsilon}}}$ may be
dropped because we may replace $t$ with $t'\in(1,t)$ in the proof.
Thus,
\begin{eqnarray*}
\sum\limits_{j\in J_n,~~j>l_n}\td\nu_j <
\frac{e^{-\frac{m-1}{2}(t-1)^2}}{\sqrt{2e(m-1)}\,(t-1)}
\end{eqnarray*}
if $n$ is sufficiently large. This proves the proposition.
\end{proof}

\begin{thebibliography}{9999}
\bibitem{Ax01} Axler, S., Bourdon, P., Ramey, W.,
{\it Harmonic function theory}, 2nd ed.,
Graduate Texts in Mathematics. 137.
New York, Springer, xi, 259 p

\bibitem{BE53} Bateman H., Erdelyi A.,
{\it Higher transcendental functions}, V.1,
McGraw-Hill, New York (1953).

\bibitem{BP}
Bloch A., Polya G., {\it On the Zeros of Certain Algebraic
Equations}. Proc. London Math. Soc. 33, 102--114, 1932.

\bibitem{BBL}
Bogomolny E., Bohigas O., Leboeuf P., {\it  Quantum chaotic
dynamics and random polynomials}, J. Statist. Phys. 85 (1996), no.
5--6, 639--679.

\bibitem{Bu07}
B\"urgisser P., {\it Average Euler characteristic of random real
algebraic varieties}, C. R. Acad. Sci. Paris, Ser. I 345 (2007),
507--512.

\bibitem{EK95} Edelman A. and Kostlan E.,
{\it  How many zeros of a random polynomial are real?}
Bull. Amer. Math. Soc. (N.S.), 32(1):1--37, 1995.

\bibitem{EK95}
Edelman A., Kostlan E., {\it How many zeros of a random polynomial
are real?}  Bull. Amer. Math. Soc. 32 (1995), 1--37.

\bibitem{Fe69}
Federer H., {\it Geometric Measure Theory}, Springer, 1969.

\bibitem{Gi08}
Gichev V.M., {\it Some remarks on spherical harmonics}, St.
Petersburg Math. J. 20 (2009), 553--567. (Original publication:
Algebra i Analiz, tom 20 (2008), nomer 4 (Russian).)

\bibitem{Gi13}
Gichev V.M., {\it Metric properties in the mean of polynomials on
compact isotropy irreducible homogeneous spaces}, Analysis and
Math. Physics,  {\bf 3} (2013), No. 2, 119--144.

\bibitem{Kac}
Kac M., {\it  On the average number of real roots of a random
algebraic equation}, Bull. Amer. Math. Soc. 49, (1943). 314--320.

\bibitem{Ko93}
Kostlan E., {\it  On the distribution of roots of random
polynomials}. In The work of Smale in differential topology, From
Topology to Computation: Proceedings of the Smalefest, pages
419--431. Springer, 1993.

\bibitem{LO38}
Littlewood J.E.,  Offord A.C., {\it On the number of real roots of
a random algebraic equation}, J. London Math. Soc. vol. 13 (1938)
pp. 288--295.

\bibitem{LO39}
Littlewood J.E.,  Offord A.C., {\it On the number of real roots of
a random algebraic equation II}, Proc. Cambridge Philos. Soc. 35
(1939), 133--148.

\bibitem{Po99}
Podkorytov S. S., {\it The mean value of the Euler characteristic
of an algebraic hypersurface}, Algebra i Analiz, 11(5):185--193,
1999. English translation: St. Petersburg Math. J. 11(5) (2000),
pp. 853--860.

\bibitem{SS93}
Shub M. and Smale S., {\it  Complexity of B´ezouts theorem II:
volumes and probabilities.} In F. Eyssette and A. Galligo,
editors, Computational Algebraic Geometry, volume 109 of Progress
in Mathematics, pages 267--285. Birkh¨auser, 1993.

\bibitem{St70}
Stein E.M., {\it  Singular integrals and differentiability
properties of functions}, Prinston, 1970.

\end{thebibliography}

\end{document}

\begin{abstract}
Let $M=G/H$ be  an isotropy irreducible  homogeneous space of a
compact Lie group $G$, ${\mathcal{E}}$ be a finite dimensional $G$-invariant
linear space of smooth real valued functions on $M$ equipped with
an invariant inner product, and ${\mathcal{S}}$ be the unit sphere in ${\mathcal{E}}$.
The normalized evaluation mapping  $M\to{\mathcal{S}}$ is a local metric
homothety. Its coefficient $s$ is an essential ingredient in
formulas for the average of some metric quantities related to the
polynomials. If ${\mathcal{E}}$ is irreducible, then $s$ is independent of
the invariant inner product. In general, $s^2=\sum_j\nu_js_j^2$,
where $s_j$ corresponds to an irreducible component.  The
coefficients $\nu_j$ depend on the inner product and the
dimensions, $\nu_j>0$, and $\sum_j\nu_j=1$.

Let ${\mathcal{P}}_n$ be the space of homogeneous polynomials of degree $n$
on ${\mathbb{R}}^{m+1}$. The Kostlan--Shub--Smale random polynomial on
${\mathbb{R}}^{m+1}$ corresponds to the Gaussian distribution on ${\mathcal{P}}_n$
with the density $\pi^{-\frac{d}{2}}e^{-|u|^2}$, where
$d=\dim{\mathcal{P}}_n$ and the inner product is defined by the equality
$|x^{{\mathord{\alpha}}}|^2={{\mathord{\alpha}}}!$ for the monomials $x^{{\mathord{\alpha}}}$ and the condition of
orthogonality of distinct monomials. As a function space on the
unit sphere $S^m={\mathop{\mathrm{SO}}}(m+1)/{\mathop{\mathrm{SO}}}(m)$  in ${\mathbb{R}}^{m+1}$, ${\mathcal{P}}_n$ is a
sum of the spaces ${\mathcal{H}}_j$ of spherical harmonics of degree $j$. We
find the coefficients $\nu_j$ and their scaling limit as
$n\to\infty$.
Also, we show that a Kostlan--Shub--Smale random polynomial of
degree $n$ admits a good approximation by a polynomial of lower
degree (roughly, of magnitude $C\sqrt{n\ln n}$) in the Sobolev
spaces $H^k(S^m)$ with a high probability.
\end{abstract}

