\documentclass[11pt]{amsart}
\usepackage{amsmath,,amsthm, amssymb, amscd,amsxtra, esint}

\usepackage[dvips]{graphics,epsfig} 

\headheight=8pt 
\topmargin=0pt 
\textheight=624pt 
\textwidth=432pt 
\oddsidemargin=18pt 
\evensidemargin=18pt

\allowdisplaybreaks[2]

\sloppy

\hfuzz = 0.5cm 

\newtheorem{theorem}{Theorem} [section] 
\newtheorem{maintheorem}{Theorem} 
\newtheorem{lemma}[theorem]{Lemma} 
\newtheorem{proposition}[theorem]{Proposition} 
\newtheorem{remark}[theorem]{Remark} 
\newtheorem{example}{Example} 
\newtheorem{exercise}{Exercise} 
\newtheorem{definition}{Definition} 
\newtheorem{corollary}[theorem]{Corollary} 
\newtheorem{notation}{Notation}[section] 
\newtheorem{claim}[theorem]{Claim}

\newtheorem{conjecture}{Conjecture}[section] 
\newtheorem{scheme}{Scheme}[section]

\numberwithin{equation}{section} \numberwithin{theorem}{section}

      

 
 
 
 
 
 

 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 

\begin{document}

\title [Almost Sure Well-Posedness of NLS below $L^2$] {\bf Almost sure well-posedness of the cubic nonlinear Schr\"odinger equation below $L^2 (\mathbb{T})$}

\author{James Colliander, Tadahiro Oh}

\address{James Colliander\\
Department of Mathematics\\
University of Toronto\\
40 St. George St, Toronto, ON M5S 2E4, Canada}
\thanks{J.C. was supported in part by NSERC grant RGP250233-07.}
\email{colliand@math.toronto.edu}

\address{Tadahiro Oh\\
Department of Mathematics\\
University of Toronto\\
40 St. George St, Toronto, ON M5S 2E4, Canada}

\curraddr{Department of Mathematics\\
Princeton University\\
Fine Hall, Washington Rd\\
Princeton, NJ 08544-1000, USA}

\email{hirooh@math.princeton.edu}

\subjclass[2010]{35Q55, 37K05, 37L50, 37L40}

\keywords{Schr\"odinger equation; NLS, well-posedness; invariant measures; ill-posedness}
\begin{abstract}
We consider the Cauchy problem for the one-dimensional periodic cubic nonlinear Schr\"odinger 
equation (NLS) with initial data below $L^2$. 
In particular, we exhibit nonlinear smoothing when the initial data are randomized. 
Then, we prove local well-posedness of NLS almost surely for the initial data 
in the support of the canonical Gaussian measures on $H^s(\mathbb{T})$ for each $s > -\frac{1}{3}$,
and global well-posedness for each $s > -\frac{1}{12}$.

\end{abstract}

\maketitle

\tableofcontents

\newpage

\section{Introduction}

We consider the Cauchy problem for the one-dimensional periodic cubic nonlinear Schr\"odinger equation (NLS): 
\begin{equation}
	\label{NLS1} 
	\begin{cases}
		i u_t - u_{xx} \pm u |u|^2 =0 \\
		u|_{t= 0} = u_0, ~x \in {\mathbb{T}} = {\mathbb{R}} / 2 \pi {\mathbb{Z}}.
	\end{cases}
\end{equation}

{
\noindent}
We first establish almost sure local well-posedness 
for{\footnote{We actually consider the Wick ordered version \eqref{NLS2} instead of \eqref{NLS1} below.}} \eqref{NLS1} 
with respect to the canonical Gaussian measure supported on $H^s ({\mathbb{T}})$ in the range $-\frac{1}{3} < s < 0$. 
Then, we establish almost sure global well-posedness 
in $H^s({\mathbb{T}})$ for $-\frac{1}{12} < s < 0$. 
These results are motivated by (a) the well-posedness theory of nonlinear dispersive equations with low regularity initial conditions and (b) construction of measures on phase spaces which are invariant under the \eqref{NLS1} evolution.

\subsection{Low Regularity Well-Posedness Theory}

The well-posedness theory for the Cauchy problem \eqref{NLS1} for rough data has been the subject of recent studies. In particular, detailed studies of \eqref{NLS1} have revealed diverse phenomena of the associated data-to-solution map leading to ramified notions of ill-posedness and well-posedness. It is known that: 
\begin{itemize}
	\item The data-to-solution map $H^s\ni u_0 \longmapsto u(t) \in H^s$ (for some $t \neq 0$) is well-defined and analytic provided $s \geq 0$ \cite{Tsutsumi:1987p799} \cite{Bourgain:1993p453}. 

	\item Uniform continuity of the data-to-solution map from $H^s$ to $H^s$ fails for $s<0$ \cite{Kenig:2001p1478, Burq:2002p911, Christ:2003p838}. Moreover, when $s<0$, the data-to-solution map is discontinuous from $H^s ({\mathbb{T}})$ even to the space of distributions $(C^\infty ({\mathbb{T}}))^*$ \cite{Christ:2003p1180, Molinet:2009p365}. 
	\item The data-to-solution map is unbounded from $H^s ( {\mathbb{R}} )$ to $H^s ( {\mathbb{R}} )$ provided $s < -\frac{1}{2}$. For example, the norm inflation phenomena identified in \cite{Christ:2003p838} shows there exist initial data arbitrarily small in $H^s({\mathbb{R}})$ which evolve into solutions which are arbitrarily large in $H^s({\mathbb{R}})$ in an arbitrarily short time. 
	\item The data-to-solution map is bounded{\footnote{M. Christ (with J. Holmer and D. Tataru) announced similar results on ${\mathbb{T}}$ in April 2009 at IHP in Paris.}} from $H^s ({\mathbb{R}})$ to $H^s({\mathbb{R}})$ provided $-\frac{1}{6} \leq s <0$ \cite{Koch:2007p782}. Moreover, there exist weak solutions associated to every $u_0 \in H^s ({\mathbb{R}})$ in this range. These weak solutions are not known to be unique. 
\end{itemize}
It is unknown whether well-posedness with merely continuous dependence upon the initial data for \eqref{NLS1} holds true in $H^s$ for $s \geq -\frac{1}{2}$. In contrast to these negative results, this paper establishes positive results on subsets of $H^s ({\mathbb{T}})$ for certain $s<0$ which are full with respect to natural Gaussian measures.

\subsection{Invariant Gibbs Measures}

Inspired by \cite{Lebowitz:1988p737} and following an approach from \cite{Zhidkov:1994p834}, Bourgain \cite{Bourgain:1994p435}
constructed  the Gibbs measure for{\footnote{In fact, the construction and invariance of the Gibbs measure is proved for a family of (sub-)quintic NLS equations containing \eqref{NLS1} in \cite{Bourgain:1994p435}.}} \eqref{NLS1} and established its invariance under the \eqref{NLS1} flow. Sufficiently regular solutions of \eqref{NLS1} satisfy mass conservation 
\begin{equation}
	\label{mass} \| u(t ) \|_{L^2({\mathbb{T}})} = \| u_0 \|_{L^2 ({\mathbb{T}})}, 
\end{equation}

{
\noindent} and Hamiltonian conservation 
\begin{equation}
	\label{Hamiltonian} H[u(t) ] = \int_{\mathbb{T}} \frac{1}{2} |u_x (t) |^2 \pm \frac{1}{4} |u(t)|^4 dx = H[u_0]. 
\end{equation}

{
\noindent} By the Hamiltonian structure of the equation, the Gibbs measure 
\begin{equation}
	\label{GibbsMeasure} \text{``}d \mu = e^{-H[u]} \prod_{x \in {\mathbb{T}}} du(x)\text{''} 
\end{equation}
is formally invariant. The Gibbs measure is rewritten as a weighted Wiener measure 
\begin{equation}
	\label{WeightedWiener} d \mu = Z^{-1} e^{\mp \frac{1}{4} \int|u|^4 dx} d\rho 
\end{equation}
where 
\begin{equation}
	\label{Wiener} d \rho = Z_0^{-1} e^{-\frac{1}{2} \int |u_x|^2 dx} \prod_{x \in {\mathbb{T}}} du(x) 
\end{equation}
is the Wiener measure on ${\mathbb{T}}$.

The construction of the Gibbs measure proceeds by showing that the density $ e^{\mp \frac{1}{4} \int|u|^4 dx}$ is in $ L^1 (d \rho)$. Expressed in terms of Fourier coefficients, the Wiener measure describes a Gaussian distribution for each $|n| \widehat{u} (n)$. Thus, a typical element in the support of the Wiener measure may be represented{\footnote{There is an issue regarding the zero Fourier mode which the reader is invited to ignore. The Wiener measure will soon be adjusted using the conserved $L^2$ norm into another formally invariant Gaussian measure which avoids the $n=0$ issue.}} 
\begin{equation}
	\label{representation} u = u^\omega = \sum_{n \in {\mathbb{Z}}} \frac{g_n (\omega)}{|n|} e^{i n x} 
\end{equation}
where the $\{ g_n \}_{n \in \mathbb{Z}}$ are independent standard complex valued Gaussian random variables
on some probability space $(\Omega, \mathcal{F}, \mathbb{P})$.
Almost surely in $\omega$, the series \eqref{representation} defines a function $u^\omega \in H^{\frac{1}{2}-} ({\mathbb{T}})$. Thus, $\int |u|^4 dx $ is well-defined and the density $e^{\mp \frac{1}{4} \int|u|^4 dx} $ may be shown{\footnote{In the defocusing case, this step is clear. The focusing case requires a more delicate analysis exploiting an (invariant) $L^2({\mathbb{T}})$ size cutoff (See \cite{Lebowitz:1988p737} and \cite{Bourgain:1994p435}).}} to be in $L^1 ( \omega).$

The invariance of the Gibbs measure is established by studying a sequence of finite dimensional approximations obtained by Dirichlet-projecting the dynamics of \eqref{NLS1} onto finitely many modes using the fact that the \eqref{NLS1} evolution is well-defined on the support of the Wiener measure. Recall that the evolution for \eqref{NLS1} is well-defined for all $u_0 \in L^2 ({\mathbb{T}})$ so it is certainly well-defined on the support of the Gibbs measure living in $H^{\frac{1}{2}-} ({\mathbb{T}})$.

The questions of existence and invariance of the Gibbs measure associated to \eqref{NLS1} (in fact, associated to the Wick ordered version \eqref{NLS2}) posed on the two-dimensional torus ${\mathbb{T}}^2$ were investigated in \cite{Bourgain:1996p446}. In the 
two-dimensional case, the representation \eqref{representation} almost surely in $\omega$ defines a distribution in $H^{0-} ({\mathbb{T}}^2)$ but not in $L^2 ({\mathbb{T}}^2)$. More precisely, $u$ defined in \eqref{representation} is almost surely in $B^0_{2, \infty}({\mathbb{T}}^2) \setminus L^2({\mathbb{T}}^2)$. Since the data-to-solution map is not well-defined on even $L^2 ({\mathbb{T}}^2)$, 
the issue of well-defined dynamics on the support of the Gibbs measure is not at all obvious. 
Nonetheless, Bourgain \cite{Bourgain:1996p446} established  a well-defined local-in-time dynamics on the support of the Wiener measure. In the defocusing case, he proved global well-posedness almost surely on the support, exploiting the invariance of the (finite dimensional) Gibbs measure. 

\subsection{Almost Sure Local Well-Posedness} Consider the canonical Gaussian measure on $H^\alpha ({\mathbb{T}})$: 
\begin{equation} \label{Gaussian0}
d{{\widetilde}{\rho}}_\alpha = {{\widetilde}{Z}}_\alpha^{-1} e^{-\frac{1}{2} \int |D^\alpha u |^2 dx } \prod_{x \in {\mathbb{T}}} du(x), 
\end{equation}

{
\noindent}
where $D = \sqrt{- \partial_x^2}$. The Gaussian measure $d \rho_\alpha$ corresponds to a collection of Gaussian distributions of $\{ |n|^\alpha \widehat{u} (n)\}_{n \in {\mathbb{Z}}}$, so a typical element in the support may be represented{\footnote{The issue with the zero mode should be ignored; see \eqref{Gaussian1} below.}} as a random Fourier series 
\begin{equation}
	\label{representationalpha} u = u^\omega = \sum_{n \in {\mathbb{Z}}} \frac{g_n (\omega)}{|n|^\alpha} e^{inx}. 
\end{equation}
This series almost surely in $\omega$ defines a function in $H^{\alpha - \frac{1}{2} -} ({\mathbb{T}})$ but not in $H^{\alpha - \frac{1}{2} } ({\mathbb{T}})$. Note that $u_0^\omega$ in \eqref{representationalpha} can also be expressed as $u_0^\omega = \sum {\widetilde}{g}_n e_n$ where $e_n$ is another orthonormal basis in $H^{\alpha}(\mathbb{T})$ and $\{{\widetilde}{g}_n\}$ is another family of independent standard complex-valued Gaussian random variables. In this respect, the Gaussian measure ${\widetilde}{\rho}_\alpha$ is canonical. See \cite{Kuo:1975p724} for discussions on the Gaussian measures on Banach spaces. Also, see \cite{Zhidkov:2001p831}.

Since $\| u(t) \|_{L^2} = \|u_0 \|_{L^2}$ under the flow of \eqref{NLS1}, we formally expect the Gaussian measure on $L^2({\mathbb{T}})$ 
\begin{equation}
	\label{eq:white} d\rho_0 = Z_0^{-1} e^{-\frac{1}{2} \int | u |^2 dx } \prod_{x \in {\mathbb{T}}} du(x) 
\end{equation}

{
\noindent} to be invariant in view of the Hamiltonian structure of \eqref{NLS1}. This measure $\rho_0$ is the white noise on the distributions on ${\mathbb{T}}$ and is supported on $H^{-\frac{1}{2}-} ({\mathbb{T}}) \setminus H^{-\frac{1}{2}} ({\mathbb{T}})$, i.e. in the scaling critical/supercritical regime for \eqref{NLS1}. It was shown in \cite{Oh:2010p1338} that the white noise $\rho_0$ is a weak limit of the invariant measures under the flow of \eqref{NLS1}. However, this result does not establish the invariance of the white noise $\rho_0$ since the flow is not well-defined on its support. (See Remark \ref{REM:white}.) Invariance of white noise has recently been established for the KdV equation on ${\mathbb{T}}$ \cite{Quastel:2008p796, Oh:2009p792, Oh:2010p1338}. See \cite{Oh:2009p1296} for a summary of these results.

If we define $v(t) = e^{i \gamma t} u(t)$, with $\gamma \in {\mathbb{R}}$, where $u$ solves \eqref{NLS1}, then $v$ satisfies $i 
\partial_t v - v_{xx} \pm |v|^2v + \gamma v = 0$. Recall that ${\fint} |u|^2 dx := \frac{1}{2\pi} \int |u|^2 dx$ is conserved under the flow of \eqref{NLS1} for $u_0 \in L^2 ({\mathbb{T}})$. Hence, by letting $\gamma = \mp 2 \fint |u|^2 dx$, \eqref{NLS1} is equivalent to 
\begin{equation}
	\label{NLS2} 
	\begin{cases}
		i u_t - u_{xx} \pm (u |u|^2 -2 u \fint |u|^2 dx) = 0 \\
		u|_{t= 0} = u_0, 
	\end{cases}
\end{equation}

{
\noindent} at least for $u_0 \in L^2({\mathbb{T}})$. However, for $u_0 \notin L^2({\mathbb{T}})$, we can't freely convert solutions of \eqref{NLS2} into solutions of \eqref{NLS1}. Bourgain \cite{Bourgain:1996p446} refers to \eqref{NLS2} as 
the {\it Wick ordered cubic NLS} since it may also be obtained from the Wick ordered Hamiltonian. 

In the following, we choose to study \eqref{NLS2} instead of \eqref{NLS1} for $u_0 \notin L^2 ({\mathbb{T}})$. (See Remark \ref{REM:renorm}.) In particular, we consider $u_0 $ of the form (slightly adjusted compared with \eqref{representationalpha}) 
\begin{equation}
	\label{IV} u_0 = u_0^\omega = \sum_{n \in {\mathbb{Z}}} \frac{g_n (\omega)}{\sqrt{1+ |n|^{2\alpha}}} e^{inx} 
\end{equation}

{
\noindent} which can be regarded as a  typical element in the support of the Gaussian measure 
\begin{equation}
	\label{Gaussian1} d \rho_{\alpha} = Z_\alpha^{-1} \exp \Big(-\frac{1}{2}\int |u|^2 dx -\frac{1}{2} \int |D^{\alpha} u|^2 dx\Big) \prod_{x \in \mathbb{T}} d u(x). 
\end{equation}

{
\noindent} By shifting the Laplacian as in \cite{Bourgain:1994p435, Bourgain:1996p446}, i.e. replacing $-u_{xx}$ by $-u_{xx} +u$ in \eqref{NLS1} or \eqref{NLS2}, we can also regard $u_0$ of the form \eqref{IV} as the functions in the support of the Gaussian measure $ {\widetilde}{\rho}_\alpha$ defined in \eqref{Gaussian0}. 
(Strictly speaking, one needs to replace the denominator in \eqref{IV} by $(1+|n|^2)^\frac{\alpha}{2}$
in this case.)
Note that $u_0^\omega$ in \eqref{IV} is in $\bigcap_{s < {\alpha} - \frac{1}{2}} H^s \setminus H^{ {\alpha} - \frac{1}{2}}$.
In view of Bourgain's global well-posedness (GWP) result in $L^2(\mathbb{T})$ in \cite{Bourgain:1993p453}, 
we assume that ${\alpha} \leq \frac{1}{2}$ in the following 
so that $u_0^\omega$ lies strictly in the negative Sobolev spaces, almost surely in  $\omega$. 

In establishing local well-posedness, we follow the argument by Bourgain \cite{Bourgain:1996p446}. 
First, write \eqref{NLS2} as an integral equation as in \eqref{NLS3}.
\begin{equation} 
	\label{NLS3} u(t) = {\Gamma} u(t) := S(t) u_0 \pm i \int_0^t S(t - t') \mathcal{N}(u) (t') d t' 
\end{equation}

{
\noindent} where $S(t) = e^{-i {
\partial_x}^2 t}$, $u_0$ is as in \eqref{IV}, and \[\mathcal{N}(u) := u |u|^2 - 2u \fint |u|^2.\] 

{
\noindent}
Note that $S(t) u_0$ has the same regularity as $u_0$ for each fixed $t \in \mathbb{R}$. i.e. $S(t) u^\omega_0 \in H^{{\alpha}-\frac{1}{2}-} (\mathbb{T})\setminus H^{{\alpha}-\frac{1}{2}}(\mathbb{T})$ a.s. Hence, $S(t)u_0$ is strictly in the negative Sobolev space for ${\alpha} \leq \frac{1}{2}$ a.s.

However, it turns out that 
the nonlinear part $\int_0^t S(t - t') \mathcal{N}(u) (t') d t'$ lies 
almost surely in a smoother space $L^2 (\mathbb{T})$ even for ${\alpha} \leq \frac{1}{2}$. 
(Also, see \cite{Bourgain:1996p446}, \cite{Burq:2008p624}.) 
We indeed show that for each small ${\delta}> 0$ there exists $\Omega_{\delta}$ 
with complemental measure $< e^{-\frac{1}{{\delta}^c}}$ such that ${\Gamma}$ defined in \eqref{NLS3} 
is a contraction on $S(t) u_0^\omega + B$ for $\omega \in \Omega_{\delta}$ on the time interval $[0, {\delta}]$, 
where $B$ denotes the ball of radius 1 in the Bourgain space $X^{s, \frac{1}{2}+, {\delta}}$ for some $s \geq 0$.
(See \eqref{Xsb} and \eqref{Xsb2} for the definition of $X^{s, \frac{1}{2}+, {\delta}}$.) 

 The following theorem states almost sure local well-posedness for each ${\alpha} \in (\frac{1}{6}, \frac{1}{2}].$
\begin{maintheorem}
	\label{THM:LWP} Let ${\alpha} \in ( \max( \frac{s}{3} + \frac{1}{6}, s), \frac{1}{2}]$ with $ s \in [0, \frac{1}{2}]$. Then, the periodic (Wick ordered) cubic NLS \eqref{NLS2} is locally well-posed almost surely in $H^{{\alpha} - \frac{1}{2}-}(\mathbb{T})$. More precisely, there exist $c > 0$ such that for each ${\delta} \ll 1$, there exists a set $\Omega_{\delta} \in \mathcal{F}$ with the following properties:
	\begin{enumerate}
		\item[(i)] 
		The complemental measure of $\Omega_{\delta}$ is small. More precisely, we have
		\[\mathbb{P}(\Omega_{\delta}^c) = \rho_{\alpha} \circ u_0(\Omega_{\delta}^c) < e^{-\frac{1}{{\delta}^c}},\]
		
		
		{
\noindent} 
		where $\rho_{\alpha}$ is the Gaussian probability measure on $H^{{\alpha}-\frac{1}{2}-}({\mathbb{T}})$ defined in \eqref{Gaussian1}
		and $u_0$ is viewed as a map $u_0:\Omega \to H^{{\alpha}-\frac{1}{2}-}(\mathbb{T})$.
		
		\item[(ii)] For each $\omega \in \Omega_{\delta}$, there exists a (unique) solution $u$ of \eqref{NLS2} in
		\[e^{-i {
\partial_x}^2 t}u_0 + C([-{\delta}, {\delta}];H^{s}(\mathbb{T})) \subset C([-{\delta}, {\delta}];H^{{\alpha} - \frac{1}{2}-}(\mathbb{T}))\]
		with the initial condition $u_0^\omega$ given by \eqref{IV}. 
		Here, the uniqueness holds only in the ball centered at $e^{-i {
\partial_x}^2 t}u_0$ of radius 1 in $X^{s, \frac{1}{2}+,{\delta}}$.
	\end{enumerate}
	
	{
\noindent} In particular, we have almost sure local well-posedness with respect to the Gaussian measure \eqref{Gaussian1} supported in $H^{\sigma}(\mathbb{T})$ for each ${\sigma} > -\frac{1}{3}$. 
\end{maintheorem}

{
\noindent}
We prove Theorem \ref{THM:LWP} in Section \ref{SEC:LWP}
by a combination of deterministic multilinear estimates (e.g. Lemma \ref{LEM:deterministic})
and probabilistic estimates on the linear solution with random initial data (Lemmata \ref{LEM:prob1}, \ref{LEM:prob2}, and \ref{LEM:hyper}.) 

\subsection{Almost Sure Global Well-Posedness} \label{SUBSEC:1GWP}
We continue our study  on the periodic cubic NLS \eqref{NLS1} with random initial data in the negative Sobolev spaces. 
In the second part of this paper, we study global well-posedness of  \eqref{NLS1} 
with initial data of the form \eqref{IV}.
In particular, we establish almost sure global well-posedness of  \eqref{NLS1} 
with respect to the Gaussian measure $\rho_{\alpha}$ in \eqref{Gaussian1}
for certain values of ${\alpha} \leq \frac{1}{2}$.

So far, there is basically only one method known for proving  almost sure global well-posedness of PDEs 
with random initial data of type \eqref{IV}. 
In \cite{Bourgain:1994p435}, Bourgain proved the invariance of the Gibbs measures for NLS. In dealing with the super-cubic nonlinearity, (where only the local well-posedness result was available), he used a probabilistic argument and the approximating finite dimensional ODEs (with the invariant finite dimensional Gibbs measures) to extend the local solutions to global ones almost surely on the statistical ensemble and showed the invariance of the Gibbs measures. We point out that this method can be applied in a general setting, provided that  local well-posedness is obtained with a ``good" estimate on the solutions (e.g. via the fixed point argument) and that we have a formally invariant measure such as the Gibbs measure or the white noise (where the leading term corresponds to \eqref{Gaussian1} for ${\alpha} = 1$ and ${\alpha} = 0$.) See Bourgain \cite{Bourgain:1994p540, Bourgain:1996p446}, Burq-Tzvetkov \cite{Burq:2007p1542,Burq:2008p623}, Oh \cite{Oh:2009p791, OhSBO, Oh:2009p1296}, and Tzvetkov \cite{Tzvetkov:2006p801,Tzvetkov:2008p736}.

From Theorem \ref{THM:LWP}, we have local solutions in the support of the Gaussian measure $\rho_{\alpha}$ in \eqref{Gaussian1} for ${\alpha} \in (\frac{1}{6}, \frac{1}{2}]$, which we would like to extend globally in time. 
Since the values of ${\alpha}$ is strictly between 0 and 1, the initial condition $u_0$ in \eqref{IV} is not in the support of an invariant measure for \eqref{NLS2} i.e. 
$\rho_{\alpha}$ in \eqref{Gaussian1} does not correspond to (the quadratic part of) the Gibbs measure or the white noise.
 Therefore, Bourgain's probabilistic argument \cite{Bourgain:1994p435} is {\it not} applicable here.

The crucial point in the local theory is the fact 
that the nonlinear part is almost surely smoother than the initial data.
This observation led us to consider Bourgain's high-low method \cite{Bourgain:1998p434}
for establishing global well-posedness, 
 since this kind of {\it nonlinear smoothing} is the crucial ingredient for the method. Moreover, as you see below, the implementation of the high-low method naturally lets us apply our probabilistic local theory iteratively since the data for the difference equations with high frequency initial data 
 have random Fourier coefficients (with the same distribution) at each step.

\medskip
In the following, we briefly sketch the iteration scheme for global well-posedness.
Let $s = {\alpha} - \frac{1}{2}-$ with ${\alpha} \leq \frac{1}{2}$. i.e. $s<0$.\footnote{In the global theory, 
we use $s = {\alpha} - \frac{1}{2}- < 0$ to denote
the regularity of the initial data below $L^2$.}

 By the large deviation estimate, we have 
\begin{equation}
	\label{largedevi} \mathbb{P} ( \| u_0(\omega)\|_{H^s} \geq K ) \leq e^{-c K^2}. 
\end{equation}

{
\noindent} In the following, we restrict ourselves on $\Omega_K = \{ \omega \in \Omega: \| u_0(\omega)\|_{H^s} \leq K \}.$ By writing $u_0 = \phi_0 + \psi_0$, where $\phi_0 := \mathbb{P}_{\leq N} u_0 =\sum_{|n|\leq N} {\widehat}{u}_0(n) e^{inx}$,
the low-frequency part $\phi_0$ is in $L^2(\mathbb{T})$, and it satisfies 
\[\| \phi_0\|_{L^2} \leq N^{-s} \|\phi_0\|_{H^s} \leq N^{-s} K.\] 

Let $u^{1}$ denote the solution of \eqref{NLS2} with the initial data $\phi_0$ on some time interval $[0, {\delta}]$, where ${\delta}$ is the time of local existence, i.e. ${\delta} = {\delta}(N^{-s}K) \lesssim {\delta} (\|\phi_0\|_{L^2})$. Then, we have 
\begin{equation}
	\label{LNLS1} 
	\begin{cases}
		i {
\partial_t} u^{1} - {
\partial_x}^2 u^{1} \pm \mathcal{N}(u^{1}) = 0 \\
		u^{1}|_{t= 0} = \phi_0. 
	\end{cases}
\end{equation}

{
\noindent} From the $L^2$ well-posedness theory of Bourgain \cite{ Bourgain:1993p453}, \eqref{LNLS1} is globally well-posed with the $L^2$-conservation: $\|u^{1}(t)\|_{L^2} = \|\phi_0\|_{L^2} \lesssim N^{-s}K $ for any $t \in {\mathbb{R}}$. Moreover, from the local theory, we have 
\begin{equation}
	\label{u1bound} \|u^1\|_{X^{0, \frac{1}{2}+}[0, {\delta}]} \lesssim \|\phi_0\|_{L^2} \leq N^{-s}K. 
\end{equation}

Now, let $v^{1}$ be a solution of the following difference equation on $[0, {\delta}]$: 
\begin{equation}
	\label{HNLS1} 
	\begin{cases}
		i {
\partial_t} v^{1} - {
\partial_x}^2 v^{1} \pm (\mathcal{N} (u^{1} + v^{1}) - \mathcal{N}(u^{1})) = 0 \\
		v^{1}|_{t= 0} = \psi_0 = \sum_{|n|> N} \frac{g_n(\omega)}{\sqrt{1+|n|^{2{\alpha}}}} e^{inx}. 
	\end{cases}
\end{equation}

{
\noindent} i.e. we have $u(t) = u^{1}(t) + v^{1}(t)$ as long as the solution $v^{1}$ of \eqref{HNLS1} exists.
Note that $\psi_0$ has Gaussian-randomized Fourier coefficients. Hence, we can use our probabilistic local theory 
(as in Theorem \ref{THM:LWP})
to study \eqref{HNLS1}.

Suppose that, by our probabilistic local theory, we can show that \eqref{HNLS1} is locally well-posed on the time interval $[0, \delta]$ except on a set of measure $e^{-\frac{1}{{\delta}^c}}$. We have $v^1(t) = S(t) \psi_0 + w^1(t)$, where the nonlinear part $w^1(t)$ is smoother and is in $L^2({\mathbb{T}})$ for all $t \in [0, {\delta}]$. The appearance of the external function $u^1$ in \eqref{HNLS1} with large $X^{0, \frac{1}{2}+}_{[0,  {\delta}]}$-norm, forces us to refine our argument used to prove Theorem \ref{THM:LWP} to obtain a good estimate on $\|w^1(t)\|_{L^2}$.

At time $t = {\delta}$, we redistribute the data. i.e. write $u ({\delta}) = \phi_1 + \psi_1$, where $\phi_1 := u^1({\delta}) + w^1({\delta})$ and $\psi_1 := S({\delta}) \psi_0$. Let $u^2$ denote the solution of \eqref{NLS2} with the initial data $\phi_1$ starting at time $t = {\delta}$. i.e. 
\begin{equation}
	\label{LNLS2} 
	\begin{cases}
		i {
\partial_t} u^2 - {
\partial_x}^2 u^2 \pm \mathcal{N}(u^2) = 0 \\
		u^2|_{t= {\delta}} = \phi_1 = u^1({\delta}) + w^1({\delta}) \in L^2({\mathbb{T}}). 
	\end{cases}
\end{equation}

{
\noindent} Then, \eqref{LNLS2} is globally well-posed. Also, from the local theory, we have 
\begin{equation}
	\label{u2bound} \| u^2 \|_{X^{0, \frac{1}{2}+}[{\delta}, 2{\delta}]} \lesssim \|\phi_1\|_{L^2} \leq \| u^1({\delta})\|_{L^2} + \|w^1({\delta})\|_{L^2} \lesssim N^{-s}K + \|w^1({\delta})\|_{L^2} \lesssim N^{-s} K 
\end{equation}

{
\noindent} {\it as long as} 
\begin{equation}
	\label{w1bound} \|w^1({\delta})\|_{L^2} \lesssim N^{-s}K. 
\end{equation}

Now, let $v^2$ be the solution of the difference equation on $[{\delta}, 2{\delta}]$: 
\begin{equation}
	\label{HNLS2} 
	\begin{cases}
		i {
\partial_t} v^2 - {
\partial_x}^2 v^2 \pm (\mathcal{N} (u^2 + v^2) - \mathcal{N}(u^2)) = 0 \\
		v^2|_{t= {\delta}} = \psi_1 = \sum_{|n|> N} \frac{g_n(\omega)e^{i {\delta} n^2}}{\sqrt{1+|n|^{2{\alpha}}}} e^{inx}. 
	\end{cases}
\end{equation}

{
\noindent} Once again, $\psi_1$ has Gaussian-randomized Fourier coefficients.
Since the complex Gaussian is invariant under rotation, 
we see that $\psi_1$ has the same distribution as $\psi_0$.\footnote{This can be viewed as invariance
of the Gaussian measure $\rho_{\alpha}$ (restricted to the high frequencies) under the linear flow.
This is the key ingredient for the global-in-time argument (in the absence of (formally) invariant measures under the nonlinear PDE flow.)} 
Hence, we can use our probabilistic local theory to study \eqref{HNLS2}.

In this way, we iterate the deterministic local theory to the ``low-frequency'' part $u^j$ and the probabilistic local theory to the ``high-frequency'' part $v^j$ to prove that \eqref{NLS2} is well-posed on $[0, T]$ for arbitrary $T>0$. 
For details, see Section \ref{SEC:GWP}.
\begin{maintheorem}
	\label{THM:GWP1} Let ${\alpha} \in ( \frac{5}{12}, \frac{1}{2}]$. Then, the periodic (Wick ordered) cubic NLS \eqref{NLS2} is globally well-posed almost surely in $H^{{\alpha} - \frac{1}{2}-}(\mathbb{T})$. More precisely, for almost every $\omega \in \Omega$ there exists a (unique) solution $u$ of \eqref{NLS2} in
	\[e^{-i {
\partial_x}^2 t}u_0 + C({\mathbb{R}};L^2(\mathbb{T})) \subset C({\mathbb{R}};H^{{\alpha} - \frac{1}{2}-}(\mathbb{T}))\]
	with the initial condition $u_0^\omega$ given by \eqref{IV}.
	Here, the uniqueness holds in a very mild sense. See Remark \ref{REM:unique}.
	
	
	In particular, we have almost sure global well-posedness with respect to the Gaussian measure \eqref{Gaussian1} supported in $H^{s}(\mathbb{T})$ for each $s > -\frac{1}{12}$. 
\end{maintheorem}

\subsection{Remarks}

We conclude this introduction by stating several important remarks.
\begin{remark} \label{REM:ABS}
	\rm A linear part of a local-in-time solution constructed in Theorem \ref{THM:LWP} indeed lies in $C([-{\delta}, {\delta}];B(\mathbb{T}))$ for any Banach space $B ({\mathbb{T}}) \supset H^{\alpha}({\mathbb{T}})$ such that $(H^{\alpha}, B, \rho_{\alpha})$ is an abstract Wiener space. (Roughly speaking, 
	an abstract Wiener space is a Banach space extension $B({\mathbb{T}})$ of  $H^{\alpha}({\mathbb{T}})$, where the Gaussian measure $\rho_{\alpha}$ makes sense as a countable additive probability measure.) In this case, a solution $u$ to \eqref{NLS2} lies in
	\[ u = e^{-i {
\partial_x}^2 t}u_0 + (-i{
\partial_t} + {
\partial_x}^2)^{-1} u \in C([-{\delta}, {\delta}];B(\mathbb{T})) + C([-{\delta}, {\delta}];H^{s}(\mathbb{T}))\]
	
{
\noindent}	
for some $s\geq 0$ as in Theorem \ref{THM:LWP}. 	As examples of $B$, we can take the Sobolev spaces $W^{{\sigma}, p}$ with $ {\sigma} < {\alpha} - \frac{1}{2}$, the Fourier-Lebesgue spaces $\mathcal{F}L^{{\sigma}, p}$ with ${\sigma} < {\alpha} - \frac{1}{p}$, where $\mathcal{F}L^{{\sigma}, p}$ is defined via the norm $\|f\|_{\mathcal{F}L^{{\sigma}, p}} = \|{\langle {n} \rangle}^{\sigma} {\widehat}{f}(n)\|_{L^p_n}$,
	and  the Besov spaces $B^{{\alpha} - \frac{1}{2}}_{p, \infty}$ with $p < \infty$. 
	See B\'enyi-Oh \cite{Benyi:2010p842} for 	regularity of $\rho_{\alpha}$ (and $u_0$ in \eqref{IV}) in different function spaces. 
	In \cite{Benyi:2010p842}, we study the regularity of $\rho_{\alpha}$ for ${\alpha} = 1$ but it can be easily adjusted for any ${\alpha}$.
A similar comment applies to global-in-time solutions constructed in Theorem \ref{THM:GWP1}.
For global-in-time argument, however, it is important that the large deviation estimate \eqref{largedevi} still holds for these spaces.
\end{remark}

\begin{remark} \label{REM:unique}
	\rm In the local theory of Theorem \ref{THM:LWP}, 
	uniqueness holds only in the ball centered at $S(t) u_0^\omega$ of radius 1 in $X^{s, \frac{1}{2}+,{\delta}}$
	for some $s\geq 0$. Continuous dependence on the initial data holds, in some weak sense,  in $H^s({\mathbb{T}})$ for some $s \geq 0.$  
	(See Subsection \ref{SUBSEC:LWP1}.)
	Also, note that Theorem \ref{THM:LWP} can not be applied to \eqref{NLS1}, since $u_0^\omega$ is almost surely not in $L^2(\mathbb{T})$.

In the global theory of Theorem \ref{THM:GWP1}, 
the situation is a little more complicated.
 On the one hand, uniqueness and continuous dependence 
 for ``low-frequency'' part $u^j$ in the $j$th step hold in $C([(j-1) {\delta}, j{\delta}], L^2({\mathbb{T}})) \cap X^{0, \frac{1}{2}+} [(j-1) {\delta}, j{\delta}]$ as usual. On the other hand, uniqueness for the high-frequency part $v^j$ in the $j$th step holds only in the ball centered at $S(t) \psi_{j-1}$ of small radius in $X^{0, \frac{1}{2}+} [(j-1) {\delta}, j{\delta}]$. 
 Also, weak continuous dependence for $v^j$ holds in $L^2({\mathbb{T}})$ in the sense
 analogous to the local theory in Theorem \ref{THM:LWP}. 
  \end{remark}

\begin{remark} \label{REM:white}
\rm

Recall that the white noise corresponds to ${\alpha} = 0$ in \eqref{Gaussian1} (up to constants).
Hence,  Theorems \ref{THM:LWP} and \ref{THM:GWP1} may also be viewed as partial results towards showing 
well-posedness of \eqref{NLS2} on the support of the white noise $ \rho_0$. 
\end{remark}

\begin{remark}
	\rm The periodic cubic NLS \eqref{NLS1} is known to be ill-posed in $H^s(\mathbb{T})$ for $s < 0$. See Molinet \cite{Molinet:2009p365} for the most recent work and the references therein. 
	As for the Wick ordered cubic NLS \eqref{NLS2}, note that $ u_{N, a}(x, t) = a e^{i(Nx + N^2 t \mp |a|^2t)}$ solves the Wick ordered cubic NLS \eqref{NLS2} for $a \in \mathbb{C}$ and $N \in \mathbb{N}$. Hence, by following the argument of Burq-G\'erard-Tzvetkov \cite{Burq:2002p911}, we can show failure of uniform continuity of the solution map of \eqref{NLS2} below $L^2(\mathbb{T})$. Thus, it is nontrivial to construct solutions of \eqref{NLS2} in the negative Sobolev spaces.
Also, see Christ-Colliander-Tao \cite{Christ:2003p838}. 	
	
As mentioned earlier, Molinet \cite{Molinet:2009p365} showed that \eqref{NLS1} is not well-posedness below $L^2(\mathbb{T})$ by proving the weak discontinuity of the flow map in $L^2({\mathbb{T}})$. We point out that his argument does not apply to \eqref{NLS2}. 
Indeed, it is shown in \cite{SULEM} that the solution map to the Wick ordered cubic NLS \eqref{NLS2} is
weakly continuous in $L^2({\mathbb{T}})$.
\end{remark}

\begin{remark}
	\label{REM:FLP} \rm
	On the one hand, it is known that $u_0^\omega$ of the form \eqref{IV} is in $\mathcal{F}L^{s, p}$ almost surely for $ s < {\alpha} - \frac{1}{p}$ and not in the smoother spaces. See \cite{Oh:2009p792, Benyi:2010p842}. On the other hand, Christ \cite{Christ:2007p1011} constructed local-in-time solutions in $\mathcal{F} L^{0,p}$ for $2< p < \infty$ by the power series method. Also see Gr\"unrock-Herr \cite{Grunrock:2008p659} for the same result via the fixed point argument. Hence, it follows from their result that \eqref{NLS2} with $u_0^\omega$ in \eqref{IV} is almost surely locally well-posed for ${\alpha} > 0$, but the solution $u$ lies in $C([-{\delta}, {\delta}]; \mathcal{F} L^{0,\frac{1}{\alpha}+}({\mathbb{T}}))$. 
	
	In the following, 
	we first construct local-in-time solutions in $C([-{\delta}, {\delta}];H^{{\alpha} - \frac{1}{2}-}(\mathbb{T}))$ by exhibiting nonlinear smoothing under randomization. Also, see Remark \ref{REM:ABS}.
	In Theorem \ref{THM:GWP1},  we extend the local solutions to global ones (in the absence of invariant measures) by exploiting such nonlinear smoothing. 
\end{remark}

\begin{remark}
	\label{REM:renorm}\rm In \cite{Bourgain:1996p446}, the two dimensional Wick ordered (defocusing) cubic NLS appeared as an equivalent formulation of (the limit of the finite dimensional) Hamiltonian equation, arising from the Wick ordered Hamiltonian. Such renormalization on the nonlinearity was a natural consequence of the Euclidean $\varphi_2^4$ quantum field theory. In our case, by taking the initial data $u_0^\omega$ to be of the form \eqref{IV} with ${\alpha} \leq \frac{1}{2}$, \eqref{NLS2} also arises as an equivalent formulation of (the limit of the finite dimensional) Hamiltonian equation from the Wick ordered Hamiltonian, (at least for ${\alpha} > \frac{1}{4}$) under Gaussian assumption on solutions. Moreover, such renormalization is needed to obtain the continuous dependence on the initial data \cite{Christ:2007p1011, Grunrock:2008p659}.
See \cite{SULEM} for more discussion on this issue.
\end{remark}

\begin{remark}
	\rm In \cite{Bourgain:1996p446}, local solutions were constructed via the fixed point argument around the linear solution $z_1(t) := S(t)u_0$ with probabilistic arguments. Also see Burq-Tzvetkov \cite{Burq:2008p624, Burq:2008p623} and Thomann \cite{Thomann:2009p1427} for related arguments. While the basic probabilistic argument (e.g. Lemma \ref{LEM:prob2}) is similar, the argument in \cite{Burq:2008p624, Thomann:2009p1427} further exploits the properties of the eigenfunctions, and the argument in \cite{Bourgain:1996p446} and this paper exploits more properties of the product of Gaussian random variables via the hypercontractivity of the Ornstein-Uhlenbeck semigroup. 
(See Lemma \ref{LEM:hyper}.)

In \cite{OhFE}, the second author considered KdV and dispersionless Szeg\"o equation
with random initial data.
Even with random initial data, 
an attempt to construct local-in-time solutions by the fixed point argument
around the linear solution (below the deterministic threshold) failed for both of these equations. 
Nonetheless, local-in-time solutions for KdV 
(below the deterministic threshold) were constructed
via the second iteration argument, exploiting randomization of initial data.
\end{remark}

\medskip

This paper is organized as follows. 
In Section 2, we introduce the basic function spaces and notations. 
In Section 3, we list some deterministic and probabilistic lemmata. 
Then, we prove Theorem \ref{THM:LWP} in Section 4
and Theorem \ref{THM:GWP1} in Section 5.

\section{Notation} First, recall the Bourgain space $X^{s, b}(\mathbb{T} \times \mathbb{R})$, c.f. \cite{Bourgain:1993p453}, whose norm is given by
\begin{equation} \label{Xsb}
\| u\|_{X^{s, b}(\mathbb{T} \times \mathbb{R})} = \|{\langle {n} \rangle}^s {\langle {\tau - n^2} \rangle}^b {\widehat}{u}(n, \tau)\|_{l^2_n L^2_\tau } 
\end{equation}

{
\noindent} where ${\langle {\, \cdot\, } \rangle} = 1 + |\cdot|$.
Recall that $X^{s, b}$ embeds into $C_t H^s_x$ for $b  >\frac{1}{2}$.
 We also define the local-in-time version $X^{s, b, {\delta} }$ on ${\mathbb{T}} \times [-{\delta}, {\delta}]$, by
\begin{equation} \label{Xsb2}
 \|u\|_{X^{s, b, {\delta} }} = \inf \big\{ \|{\widetilde}{u} \|_{X^{s, b}({\mathbb{T}} \times \mathbb{R})}: {{\widetilde}{u}|_{[-{\delta}, {\delta}]} = u}\big\}.
\end{equation}

{
\noindent} 
We also define the local-in-time version $X^{s, b}_I = X^{s, b}[a, b]$
on an interval $I = [a, b]$.
The local-in-time versions of other function spaces are defined analogously.

For simplicity, we often drop $2\pi$ in dealing with the Fourier transforms. 
If a function $f$ is random, we may use the superscript $f^\omega$ to show the dependence on $\omega$.

We use $\eta \in C^\infty_c(\mathbb{R})$ to denote a smooth cutoff function supported on $[-2, 2]$ with $\eta \equiv 1$ on $[-1, 1]$ and let $\eta_{_{\delta}}(t) =\eta({\delta}^{-1}t)$,
and $\chi = \chi_{[-1, 1]}$ to denote the characteristic function of the interval $[-1, 1]$
 and let $\chi_{_{\delta}}(t) =\chi({\delta}^{-1}t) = \chi_{[-{\delta}, {\delta}]}(t)$.

The decreasing rearrangement of dyadic numbers $N_1, N_2, N_3$ will be denoted $N^1, N^2, N^3$, following \cite{Bourgain:1996p446}.

We use $c,$ $ C$ to denote various constants, usually depending only on ${\alpha}$ and $s$. If a constant depends on other quantities, we will make it explicit. We use $A\lesssim B$ to denote an estimate of the form $A\leq CB$. Similarly, we use $A\sim B$ to denote $A\lesssim B$ and $B\lesssim A$ and use $A\ll B$ when there is no general constant $C$ such that $B \leq CA$. We also use $a+$ (and $a-$) to denote $a + {\varepsilon}$ (and $a - {\varepsilon}$), respectively, for arbitrarily small ${\varepsilon} \ll 1$.

\section{Deterministic and Probabilistic Lemmata} 

\subsection{Deterministic Lemmata}
First, recall the following algebraic identity related to the cubic NLS: 
\begin{equation}
	\label{ALGEBRA} n^2 - (n_1^2 - n_2^2 + n_3^2) = 2(n_2 - n_1) (n_2 - n_3) 
\end{equation}

{
\noindent} for $n = n_1 - n_2 + n_3$. Let $N^1, N^2, N^3$ be the decreasing ordering of $N_1, N_2, N_3$, where $|n_j| \sim N_j$, and let $n^j$ denote the corresponding frequency.

Next, recall the following number theoretic fact \cite{HW}.
Given an integer $m$, let $d(m)$ denote the number of divisors of $m$.
Then, we have
\begin{equation} \label{DIVISOR}
d(m) \lesssim e^{c \frac{\log m}{\log \log m}} \ ( = o(m^{\varepsilon}) \text{ for any }{\varepsilon}>0.)
\end{equation}

{
\noindent}
From this fact, we obtain the following lemma.

\begin{lemma}
	\label{LEM:count1} 
	Fix $\mu \in \mathbb{Z}.$ Let 
	\begin{align}
		\label{Smu} S_\mu = \{ (n_1, n_2, n_3) \in \mathbb{Z}^3: |n_j|\sim N_j, n_2 \ne n_1, n_3, \textup{ and } 2(n_2 - n_1) (n_2 - n_3) = \mu\}. \notag 
	\end{align}
	
	{
\noindent} Then, we have 
	\begin{equation}
		\label{counting} \# S_\mu \lesssim (N^1)^{0+}N^3. 
	\end{equation}
\end{lemma}
\begin{proof}
	By assumption, we have $|\mu| \lesssim (N^1)^2$. Hence, the number of the divisors of $\mu$ is $o((N^1)^{\varepsilon})$ for any ${\varepsilon} > 0$. Without loss of generality, assume $N^3 \sim \min(|n_2|, |n_3|)$.
	
	First, suppose $|n_2|\sim N^3$.  Fix $n_2$. Then, from \eqref{DIVISOR}, there are at most $o((N^1)^{0+})$ many choices for $d := n_2 - n_1$. Then, there are at most $o((N^1)^{0+})$ many choices for $n_1$ and $n_3$ since $n_1 = n_2 - d$ and $n_3 = n_2 - \frac{\mu}{2d}$.
	
	Next, suppose $|n_3|\sim N^3$. Fix $n_3$. Then, from \eqref{DIVISOR}, there are at most $o((N^1)^{0+})$ many choices for $d := n_2 - n_3$. Then, there are at most $o((N^1)^{0+})$ many choices for $n_1$ and $n_2$ since $n_2 = d + n_3$ and $n_1 = d + n_3 - \frac{\mu}{2d}$. Hence, \eqref{counting} holds in both cases. 
\end{proof}

Recall that by restricting the Bourgain spaces onto a small time interval $[-{\delta}, {\delta}]$, we can gain a small power of ${\delta}$ (at a slight loss of regularity on ${\langle {\tau - n^2} \rangle} $.) See \cite{Bourgain:1993p453}.
\begin{lemma}
	\label{LEM:timedecay} Let $s \in{\mathbb{R}}$ and $b < \frac{1}{2}$. Then, there exists $C = C(b) > 0$ such that  we have 
	\begin{equation}
		\label{CCtime0}
		 \|u\|_{X^{s, b, {\delta}}}  \leq C {\delta}^{\frac{1}{2}-b-} \|u\|_{X^{s, \frac{1}{2}, {\delta}}}. 
	\end{equation}
\end{lemma}

{
\noindent}
Before presenting the proof, first recall the following fact from \cite{BOPCMI}.
Let $\chi_{_{\delta}} (t):= \chi_{[-{\delta}, {\delta}]}(t)$ be the characteristic function of the interval $[-{\delta}, {\delta}]$.
Then, for $b< \frac{1}{2}$, we have
\begin{equation} \label{CC00}
\|\chi_{_{\delta}}(t) u \|_{X^{s, b}} \sim \|u\|_{X^{s, b, {\delta}}}.
\end{equation}

{
\noindent}
Indeed, by definition \eqref{Xsb2} of local-in-time $X^{s, b}$, 
we have $ \|u\|_{X^{s, b, {\delta}}} \leq \|\chi_{_{\delta}}(t) u \|_{X^{s, b}}$.
The inequality in the other direction:
$ \|\chi_{_{\delta}}(t) u \|_{X^{s, b}} \leq C(b) \|u\|_{X^{s, b, {\delta}}} $
follows from the boundedness of multiplication by 
a sharp cutoff function
in $H^b_t$ for $b < \frac{1}{2}$.
Note that the constant $C(b)$ depends only on $b$,
in particular independent of ${\delta}$.

\begin{proof}
Let ${\widetilde}{u}$ be any extension of $u$ onto ${\mathbb{R}}$,
i.e. ${\widetilde}{u}$ is a function on ${\mathbb{R}}$ such that ${\widetilde}{u} = u$ on $[-{\delta}, {\delta}]$.
Also, let $v = \chi_{_{\delta}}(t) {\widetilde}{u}$.
Then, we have $v = {\widetilde}{u} = u$ on $[-{\delta}, {\delta}]$.
Moreover, from \eqref{CC00}, we have
\begin{equation} \label{CC0}
\|v\|_{X^{s, b}} \sim \|{\widetilde}{u}\|_{X^{s, b, {\delta}}} = \|u\|_{X^{s, b, {\delta}}}
\end{equation}

{
\noindent}
for $b < \frac{1}{2}$.

By interpolation, we have 
	\begin{equation}
		\label{CCtime1} 
		\| v\|_{X^{s, b}} \lesssim \| v\|^\alpha_{X^{s, 0 }}
		\| v\|^{1-\alpha}_{X^{s, \frac{1}{2}- }}, 
	\end{equation}
	
{
\noindent} 
where $\alpha = 1-(2+)b \in(0, 1)$. Recall 
${\widehat}{\chi_{_{\delta}}}(\tau) = {\delta} {\widehat}{\chi}({\delta}\tau)$,
where $\chi = \chi_{[-1, 1]}$. 
Hence, we have 
\begin{equation}
 \|{\widehat}{\chi_{_{\delta}}}\|_{L^q_\tau} \sim {\delta}^\frac{q-1}{q} \|{\widehat}{\chi}\|_{L^q_\tau} 
\lesssim {\delta}^\frac{q-1}{q},
\label{decay}
\end{equation} 

{
\noindent}
where the last inequality holds for $q > 1$.
Thus, we can gain a positive power of ${\delta}$ as long as $q>1$. 
For fixed $n$, by Young and H\"older inequalities, we have 
\begin{align*}
    \| {\widehat}{v}(n, \cdot) \|_{L^2_\tau} 
    & = 
    \| {\widehat}{\chi_{_{\delta}}} * {\widehat}{{\widetilde}{u}}(n, \cdot) \|_{L^2_\tau} 
		\leq \| {\widehat}{\chi_{_{\delta}}} \|_{L^{2-}_\tau} \|{\widehat}{{\widetilde}{u}}(n, \cdot) \|_{L^{1+}_\tau} \\
		& \lesssim {\delta}^{\frac{1}{2}-} \|{\langle {\tau-n^2} \rangle}^{-\frac{1}{2}} \|_{L^{2+}_\tau} 
		\|{\langle {\tau-n^2} \rangle}^{\frac{1}{2}}{\widehat}{{\widetilde}{u}}(n, \cdot) \|_{L^2_\tau}\\
		& \lesssim {\delta}^{\frac{1}{2}-} 
		\|{\langle {\tau-n^2} \rangle}^{\frac{1}{2}}{\widehat}{{\widetilde}{u}}(n, \cdot) \|_{L^2_\tau}.
\end{align*}
	
{
\noindent}	
 Hence, for $p > 2$, we have 
\begin{equation}
\label{CCtime2} \| v\|_{X^{s, 0 }} \lesssim {\delta}^{\frac{1}{2}-} \| {\widetilde}{u}\|_{X^{s, \frac{1}{2} }}. 
\end{equation}
	
{
\noindent} 
Then, from \eqref{CC0}, \eqref{CCtime1}, and \eqref{CCtime2}, 
we have
\begin{align*}
\|u\|_{X^{s, b, {\delta}}} \sim \|v \|_{X^{s, b}}
\lesssim {\delta}^{\frac{1}{2}-b-} \|{\widetilde}{u} \|_{X^{s, \frac{1}{2}}}
\end{align*}

{
\noindent}
for any extension ${\widetilde}{u}$  such that ${\widetilde}{u} = u$ on $[-{\delta}, {\delta}]$.	
Therefore, \eqref{CCtime0} follows from the definition
\eqref{Xsb2}. 
\end{proof}

Lastly, we present the deterministic multilinear estimates.
We use them in High Modulation Case (Subsections \ref{SUBSEC:LWP3} 
and \ref{SUBSEC:GWP4}.)
Recall the periodic $L^4$-Strichartz estimate from \cite{Bourgain:1993p453}: 
\begin{equation}
	\label{L4} \|u\|_{L^4_{x, t}} \lesssim \|u\|_{X^{0, \frac{3}{8}}}. 
\end{equation}

{
\noindent} Interpolating \eqref{L4} with $\|u\|_{L^2_{x, t}} = \|u\|_{X^{0, 0}}$, we have 
\begin{equation}
	\label{L3} \|u\|_{L^{3+}_{x, t}} \lesssim \|u\|_{X^{0, \frac{1}{4}+}}, \text{ and } \, \|u\|_{L^{2+}_{x, t}} \lesssim \|u\|_{X^{0, 0+}}. 
\end{equation}

\begin{lemma} \label{LEM:deterministic}
Let $u_j$, $j = 1, 2, 3, 4$, be functions on ${\mathbb{T}}\times [-{\delta}, {\delta}]$.
Then, we have

{
\noindent}
\textup{(a)}
\begin{equation} \label{det1}
\int_{-{\delta}}^{\delta} \int_{\mathbb{T}} u_1 u_2 u_3 u_4 dx dt \lesssim \prod_{j = 1}^4 \| u_j\|_{X^{0, \frac{3}{8}, {\delta}}}.
\end{equation}

{
\noindent}
\textup{(b)} With large $p$, we have
\begin{equation} \label{det2}
\int_{-{\delta}}^{\delta} \int_{\mathbb{T}} u_1 u_2 u_3 u_4 dx dt \lesssim 
\prod_{j = 1}^3 \| u_j\|_{X^{0, \frac{1}{4}+, {\delta}}} \|u_4\|_{L^p({\mathbb{T}}\times [-{\delta}, {\delta}])}.
\end{equation}

{
\noindent}
\textup{(c)} With large $p$, we have
\begin{equation} \label{det3}
\int_{-{\delta}}^{\delta} \int_{\mathbb{T}} u_1 u_2 u_3 u_4 dx dt \lesssim 
\prod_{j = 1}^2 \| u_j\|_{X^{0, 0+, {\delta}}}  \prod_{j = 3}^4 \|u_j\|_{L^p({\mathbb{T}}\times [-{\delta}, {\delta}])}.
\end{equation}

{
\noindent}
\textup{(d)} With large $p$, we have
\begin{equation} \label{det4}
\int_{-{\delta}}^{\delta} \int_{\mathbb{T}} u_1 u_2 u_3 u_4 dx dt \lesssim 
\prod_{j = 1}^2 \| u_j\|_{X^{0, \frac{3}{8}, {\delta}}}  \| u_3\|_{X^{0, 0+, {\delta}}}  \|u_4\|_{L^p({\mathbb{T}}\times [-{\delta}, {\delta}])}.
\end{equation}
\end{lemma}

{
\noindent}
Recall  that \eqref{det1} is the essential multilinear estimate for local well-posedness of the cubic NLS in $L^2({\mathbb{T}})$
by Bourgain \cite{Bourgain:1993p453}.

\begin{proof}
Let ${\widetilde}{u}_j$ be an extension of $u_j$ onto ${\mathbb{R}}$.
Then, by H\"older inequality and \eqref{L4}, we have
\begin{equation} 
\text{LHS of } \eqref{det1}
\leq \prod_{j = 1}^4 \|u_j\|_{L^4_{x, t}({\mathbb{T}}\times [-{\delta}, {\delta}])}
\lesssim \prod_{j = 1}^4 \| {\widetilde}{u}_j\|_{X^{0, \frac{3}{8}, {\delta}}}.\label{det1-1}
\end{equation}

{
\noindent}
Hence, \eqref{det1} follows since \eqref{det1-1} holds for any extensions ${\widetilde}{u}_j$.
The other estimates \eqref{det2}, \eqref{det3}, and \eqref{det4}
follow in a similar manner by H\"older inequality:
\begin{align*}
1 & =  \tfrac{1}{3+}+\tfrac{1}{3+}+\tfrac{1}{3+}+\tfrac{1}{p} \quad \text{for }   \eqref{det2},\\
1 & =  \tfrac{1}{2+}+\tfrac{1}{2+}+\tfrac{1}{p}+\tfrac{1}{p} \quad \text{for } \eqref{det3},\\
1 & =  \tfrac{1}{4}+\tfrac{1}{4}+\tfrac{1}{2+}+\tfrac{1}{p} \quad \text{for }  \eqref{det4},
\end{align*}

{
\noindent}
with \eqref{L4} and \eqref{L3}. 
\end{proof}

\subsection{Probabilistic Lemmata}
In this subsection, we present several probabilistic lemmata related to the Gaussian random variables.
In the following, $\{g_n\}_{n\in\mathbb{Z}}$ denotes a family of independent standard complex valued Gaussian random variables
on a probability space $(\Omega, \mathcal{F}, \mathbb{P})$.
\begin{lemma}
\label{LEM:prob1} Let ${\varepsilon}, \beta > 0$ and ${\delta} \ll 1$. Then, we have 
\begin{equation}
|g_n(\omega)| \leq C {\delta}^{-\frac{\beta}{2}} {\langle {n} \rangle}^{\varepsilon} 
\end{equation}
	
{
\noindent} 
for all $n \in \mathbb{Z}$ for $\omega$ outside an exceptional set of measure $< e^{-\frac{1}{{\delta}^c}}$. 
\end{lemma}
\begin{proof}
	Recall from \cite{Oh:2009p791} that we have 
	$\mathbb{P}( \sup_n {\langle {n} \rangle}^{-{\varepsilon}} |g_n(\omega)| > K ) \leq e^{-cK^2}$
	for sufficiently large $K>0$.	
	Now, choose $K \sim {\delta}^{-\frac{\beta}{2}}$. 
\end{proof}

\begin{lemma} \label{LEM:prob2} 
Let $f^\omega(x, t) = \sum c_n g_n(\omega) e^{i(nx + n^2t)} $. Then, for $p \geq 2$, there exists ${\delta}_0 > 0$ such that
	\[ \mathbb{P} ( \|f^\omega\|_{L^p(\mathbb{T}\times [-{\delta}, {\delta}])} > C\|c_n\|_{l^2_n} ) < e^{-\frac{1}{{\delta}^c} }\]
	
	{
\noindent} for ${\delta} \leq {\delta}_0$. 
\end{lemma}

{
\noindent}
This lemma is in the spirit of Paley-Zygmund \cite{PZ}.
In particular, it  says that the linear solution with random initial data
satisfies much better Strichartz estimates (with large probability.)
Compare with the deterministic case, where Strichartz estimates hold only for $p \leq 4$
(and for $p\leq 6$ with a slight loss of derivative.)

\begin{proof}
	By separating the real and imaginary parts, assume that $g_n$ is real-valued without loss of generality. From the general Gaussian bound (c.f. Burq-Tzvetkov \cite{Burq:2008p623}), there exists $C>0$ such that
	\[ \big\|\sum_n c_n g_n(\omega) \big\|_{L^r(\Omega)} \leq C \sqrt{r} \|c_n\|_{l^2_n}\]
	
	{
\noindent} for every $r \geq 2$ and every $\{c_n\}_{n \in \mathbb{Z}} \in l^2_n$. (This is also immediate from the hypercontractivity property as well. See \cite{Tzvetkov:2010p1443}.) By Minkowski integral inequality, we have 
	\begin{align*}
		\mathbb{E}\big( \|f^\omega\|_{L^p_{x, t}(\mathbb{T} \times [-{\delta}, {\delta}])}^r\big)^\frac{1}{r} &\leq \big\|\|f^\omega\|_{L^r(\Omega)}\big\|_{L^p_{x, t}} \lesssim \sqrt{r} \big\| \|c_n\|_{l^2_n} \big\|_{L^p_{x, t}(\mathbb{T} \times [-{\delta}, {\delta}])} \\
		&\lesssim \sqrt{r}\, {\delta}^\frac{1}{p} \|c_n\|_{l^2_n} 
	\end{align*}
	
	{
\noindent} for $r \geq p$. Then, by Chebyshev inequality, we have 
	\begin{align*}
		\mathbb{P} (\|f^\omega\|_{L^p(\mathbb{T} \times [-{\delta}, {\delta}])} > {\lambda} ) \leq C^r {\lambda}^{-r} r^\frac{r}{2} {\delta}^\frac{r}{p} \|c_n\|_{l^2_n}^r. 
	\end{align*}
	
	{
\noindent} Let ${\lambda} = C r {\delta}^\frac{1}{p} \|c_n\|_{l^2_n}$ 
	and $ r = {\delta}^{c}$ with $c = \frac{1}{p}$. Then, we have
	\[ \mathbb{P} (\|f^\omega\|_{L^p(\mathbb{T} \times [-{\delta}, {\delta}])} > C  \|c_n\|_{l^2_n} ) 
	\leq e^{-r \ln \sqrt{r}} \leq e^{-\frac{1}{{\delta}^{c}}},\]
	
	{
\noindent} for ${\delta}$ sufficiently small such that $ r \geq p$. 
It follows from the proof that ${\delta}_0 \sim e^{-p \ln p}$.
\end{proof}

The following lemma 
follows from the hypercontractivity of the Ornstein-Uhlenbeck semigroup,
related to products of Gaussian random variables. 
See Ledoux-Talagrand \cite{Ledoux} and Janson \cite{Janson}.
A nice summary is given by Tzvetkov \cite[Sections 3 and 4]{Tzvetkov:2010p1443}.

\begin{lemma} \label{LEM:hyper}
For fixed $n \in \mathbb{Z}$, 
let 
\[ D_n = \{ (n_1, n_2, n_3) \in \mathbb{Z}^3: n = n_1 - n_2 + n_3, \  n_2 \ne n_1,\ n_2\ne n_3, \ n_1\ne n_3\}.\]

{
\noindent}
Given $\{a_{n_1, n_2, n_3}\} \in l^2(D_n)$, 
define $F_n$ by 
\begin{align*}
	F_n (\omega):= \sum_{\substack{n = n_1 - n_2 + n_3\\ n_2 \ne n_1, n_3\\n_1\ne n_3}} a_{n_1, n_2, n_3} g_{n_1}(\omega){\overline}{g_{n_2}}(\omega)g_{n_3}(\omega).
\end{align*}

{
\noindent}
Then, 
there exists $c> 0$ such that, for ${\lambda} > 0$, we have
\begin{equation}\label{eq:hyper}
 \mathbb{P} (|F_n(\omega)| \geq {\lambda}) \leq \exp (-c \| F_n\|_{L^2(\Omega)}^{-\frac{2}{3}} {\lambda}^{\frac{2}{3}}).
 \end{equation}

\end{lemma}

\begin{proof}
By Propositions 3.1 and 3.3 in \cite{Tzvetkov:2010p1443}, we have 
\[\|F_n\|_{L^p(\Omega)} \leq p^\frac{3}{2} \|F_n\|_{L^2(\Omega)},\] 

{
\noindent}
for all $2 \leq p <\infty$.
Then, \eqref{eq:hyper} follows from Lemma 4.5 in \cite{Tzvetkov:2010p1443}. 
\end{proof}

\section{Local Theory} \label{SEC:LWP}

\subsection{Basic Setup} \label{SUBSEC:LWP1}

Consider the Duhamel formulation \eqref{NLS3} of the Wick ordered NLS.
As mentioned before, when ${\alpha} \leq \frac{1}{2}$, 
the linear part $S(t)u_0^\omega \notin L^2({\mathbb{T}})$
almost surely.
Nonetheless,
we show that the nonlinear part lies in a smoother space $H^s (\mathbb{T})$ for some $s \geq 0$. 
More precisely, we prove that for each small ${\delta}> 0$, 
 there exists $\Omega_{\delta}$ with complemental measure $< e^{-\frac{1}{{\delta}^c}}$ 
such that ${\Gamma}$ defined in \eqref{NLS3} is a contraction on $S(t) u_0^\omega + B$ for 
$\omega \in \Omega_{\delta}$, where $B$ denotes the ball of radius 1 in $X^{s, \frac{1}{2}+, {\delta}}$ for some $s \geq 0$.
i.e. we construct a contraction centered at the linear solution.

Given $u$ on ${\mathbb{T}}\times [-{\delta}, {\delta}]$, let ${\widetilde}{u}$ be an extension of $u$ onto ${\mathbb{T}} \times {\mathbb{R}}$.
By the nonhomogeneous linear estimate \cite{Bourgain:1993p453}, \cite{Ginibre:1997p1264},
we have
\begin{align}
	 	\bigg\| \int_0^t S(t - t') \mathcal{N}(u) (t') d t'\bigg\|_{X^{s, \frac{1}{2}+, {\delta}}}
	& \leq \bigg\|\eta_{_{\delta}}(t) \int_0^t S(t - t') \mathcal{N}({\widetilde}{u}) (t') d t'\bigg\|_{X^{s, \frac{1}{2}+}} \notag \\
	& \lesssim \| \mathcal{N}({\widetilde}{u}) \|_{X^{s, -\frac{1}{2}+}}, \label{duhamel}
\end{align}

{
\noindent} where $\eta_{_{\delta}}$ is a smooth cutoff on $[-2{\delta}, 2{\delta}]$. 
Then, Theorem \ref{THM:LWP} follows once we  prove 
\begin{equation}
	\label{trilinear1} \| \mathcal{N}({\widetilde}{u}) \|_{X^{s, -\frac{1}{2}+}} \lesssim {\delta}^\theta, \quad \text{for some } \theta > 0 
\end{equation}

{
\noindent} for $\omega \in \Omega_{\delta}$ with $\mathbb{P}(\Omega^c_{\delta}) < e^{-\frac{1}{{\delta}^c}}$
(for {\it some} extension ${\widetilde}{u}$ of $u$.)
From the embedding $X^{s, \frac{1}{2}+, {\delta}} \subset C([-{\delta}, {\delta}]:H^s)$, 
it follows that \eqref{duhamel} and \eqref{trilinear1} imply that the nonlinear part of the solution $u^\omega$ is in 
 $C([-{\delta}, {\delta}]:H^s)$ with large probability.
Now, write $\mathcal{N}(u) $ as follows: 
\begin{align}
	\label{nonlinear1} \mathcal{N}(u) & = u |u|^2 - 2u \fint \ |u|^2 \notag \\
	& = \sum_{n_2 \ne n_1, n_3} {\widehat}{u}(n_1){\overline}{{\widehat}{u}(n_2)}{\widehat}{u}(n_3) e^{i(n_1 - n_2 + n_3)x} - \sum_n {\widehat}{u}(n)|{\widehat}{u}(n)|^2 e^{inx} =: \mathcal{N}_1(u) - \mathcal{N}_2(u). 
\end{align}

{
\noindent} 
Here, the condition $n_2 \ne n_1, n_3$ in the sum for $\mathcal{N}_1(u)$ 
is a shorthand notation for $n_2 \ne n_1$ and $n_2 \ne n_3$.
This shorthand notation is used in the remaining part of the paper.

In the following subsections, 
we will prove \eqref{trilinear1} by separately estimating the contributions from $\mathcal{N}_1({\widetilde}{u}) $ and 
$\mathcal{N}_2({\widetilde}{u}) $.
In particular, we choose an extension ${\widetilde}{u}$ in  $S(t) u_0^\omega +X^{s, \frac{1}{2}+}$
of 
$u \in S(t) u_0^\omega + B$. i.e. $u = S(t) u_0^\omega + v$ for some $v$ with 
$ \|v \|_{X^{s, \frac{1}{2}+, {\delta}}} \leq 1$.

By regarding $\mathcal{N}_1$ and $\mathcal{N}_2$
as trilinear operators, we write
\begin{align}
\label{NN1}
& \mathcal{N}_1(u_1, u_2, u_3) = \sum_{n_2 \ne n_1, n_3} {\widehat}{u}_1(n_1, t){\overline}{{\widehat}{u}_2(n_2, t)}{\widehat}{u}_3(n_3, t) e^{i(n_1-n_2+n_3)x}, \\
\label{NN2}
& \mathcal{N}_2(u_1, u_2, u_3) = \sum_n {\widehat}{u}_1(n, t){\overline}{{\widehat}{u}_2(n, t)}{\widehat}{u}_3(n, t) e^{inx}. 
\end{align}

{
\noindent}
Then, we prove \eqref{trilinear1}
by carrying out case-by-case analysis
on  \[\|\mathcal{N}_1(u_1, u_2, u_3)\|_{X^{s, -\frac{1}{2}+}}
\quad \text{ and }\quad
\|\mathcal{N}_2(u_1, u_2, u_3)\|_{X^{s, -\frac{1}{2}+}},\]

{
\noindent}
where $u_j$ is taken to be either of type
\begin{itemize}
\item[(I)] linear part: {\it random, less regular} 
	  \[\ u_j (x, t) = \sum_{n } \frac{g_n(\omega)}{\sqrt{1+|n|^{2{\alpha}}}} e^{i(nx + n^2t)}\]
\item[(II)]	 nonlinear part: {\it deterministic, smoother}
	 \[ \ u_j = {\widetilde}{v}_j \text{, where ${\widetilde}{v}_j$ is an extension of $v_j$ with } \|v_j \|_{X^{s, \frac{1}{2}+, {\delta}}} \leq 1. \]
\end{itemize}

{
\noindent} In the following, we may insert the smooth cutoff function $\eta_{_{\delta}}$ supported on $[-2{\delta}, 2{\delta}]$ 
(or the sharp cutoff function $\chi_{_{\delta}}$ supported on $[-{\delta}, {\delta}]$) without stating explicitly.
This merely corresponds to taking different extensions,
and does not cause any problem since our goal is to prove \eqref{trilinear1} for {\it some}
extension ${\widetilde}{u}$ of $u$.

Note that \eqref{duhamel} and \eqref{trilinear1} imply only the boundedness of the map ${\Gamma}$ in \eqref{NLS3}
from $S(t) u_0^\omega + B$ into itself (for ${\delta}>0$ small). In establishing the contraction property, one needs to consider 
the difference ${\Gamma} u_1 - {\Gamma} u_2$ for $u_1, u_2 \in S(t) u_0^\omega + B$. We omit details since the computation  follows in a similar manner. Lastly, suppose that $u_0 = u_0^\omega$ is a good initial condition such that ${\Gamma}$ is a contraction on $S(t) u_0 + B$. Let ${\widetilde}{u}_0$ be a function on $\mathbb{T}$ such that $\| u_0 - {\widetilde}{u}_0\|_{H^s} < \frac{1}{10} $. Denote by ${\widetilde}{\Gamma}$ the solution map corresponding to the initial condition ${\widetilde}{u}_0$. Then, one can show that ${\widetilde}{\Gamma}$ is also a contraction on $S(t) u_0 + B$ for ${\delta}$ sufficiently small. Moreover, we have
\[ \| u (t) - {\widetilde}{u}(t) \|_{H^s} \leq C \|u_0 - {\widetilde}{u}_0 \|_{H^s}\]

{
\noindent} for $|t| \leq {\delta}$, where ${\widetilde}{u}$ is the solution with the initial condition ${\widetilde}{u}_0$. For details, see \cite{Bourgain:1993p453}, \cite{Bourgain:1996p446}.

\subsection{Estimate on $\mathcal{N}_2$}  \label{SUBSEC:LWP2}

In this subsection, we prove the easier part of the estimate \eqref{trilinear1}: 
\begin{equation}
	\label{trilinear2} \| \mathcal{N}_2(u_1, u_2, u_3)\|_{X^{s, -\frac{1}{2}+}} \lesssim {\delta}^\theta 
\end{equation}

{
\noindent} for some $ \theta > 0$, 
outside an exceptional set of measure $e^{-\frac{1}{{\delta}^c}}$, where $\mathcal{N}_2$ is as in \eqref{NN2}
and $u_j$ is either of type (I) or (II).
We have 
\begin{equation}
	\text{LHS of } \eqref{trilinear2} = \bigg\| \frac{{\langle {n} \rangle}^s}{{\langle {\tau - n^2} \rangle}^{\frac{1}{2}-}} \operatorname*{\int}_{\tau = \tau_1 - \tau_2 + \tau_3} {\widehat}{u}_1(n, \tau_1){\overline}{{\widehat}{u}_2(n, \tau_2)}{\widehat}{u}_3(n, \tau_3) d\tau_1 d\tau_2 \bigg\|_{l^2_n L^2_\tau} . 
\label{easy1} 
\end{equation}

{
\noindent} In the following,  we may replace $u_j$ by $\eta_{_{\delta}}u_j$ if necessary, 
where $\eta_{_{\delta}}$ the smooth cutoff function supported on $[-2{\delta}, 2{\delta}]$.

\medskip

{
\noindent} $\bullet$ {\bf Case (a):} $u_j$ of type (II), $j = 1, \dots, 3$.

By H\"older inequality with $p$ large ($\frac{1}{2} =\frac{1}{2+} + \frac{1}{p}$), we have 
\begin{align*}
	\eqref{easy1} \lesssim \sup_n \|{\langle {\tau - n^2} \rangle}^{-\frac{1}{2}+}\|_{L^{2+}_\tau} \Big\| {\langle {n} \rangle}^s\operatorname*{\int}_{\tau = \tau_1 - \tau_2 + \tau_3} {\widehat}{u}_1(n, \tau_1){\overline}{{\widehat}{u}_2(n, \tau_2)}{\widehat}{u}_3(n, \tau_3) d\tau_1 d\tau_2 \Big\|_{l^2_{n} L^p_\tau}  
\end{align*}

{
\noindent} By Young and H\"older inequalities, 
\begin{align*}
	\lesssim \big\| {\langle {n} \rangle}^s \prod_{j = 1}^3 \| {\widehat}{{\widetilde}{v}}_j (n, \tau) \|_{L^{\frac{3}{2}-}_\tau} \big\|_{l^2_n} \lesssim \big\| {\langle {n} \rangle}^s \prod_{j = 1}^3 \| {\langle {\tau - n^2} \rangle}^{\frac{1}{6}+} {\widehat}{{\widetilde}{v}}_j (n, \tau) \|_{L^{2}_\tau} \big\|_{l^2_n} 
\end{align*}

{
\noindent} By  H\"older inequality and $l^2_n \subset l^6_n$, we have for $s \geq 0$ 
\begin{align*}
	\lesssim  \prod_{j = 1}^3 \| {\langle {n} \rangle}^\frac{s}{3} {\langle {\tau - n^2} \rangle}^{\frac{1}{6}+} {\widehat}{{\widetilde}{v}}_j (n, \tau) \|_{l^6_n L^2_\tau} \leq  \prod_{j = 1}^3 \| {\widetilde}{v}_j \|_{X^{\frac{s}{3}, \frac{1}{6}+}},
\end{align*}

{
\noindent}
for any extension ${\widetilde}{v}_j$ of $v_j$ with  $\|v_j \|_{X^{s, \frac{1}{2}+, {\delta}}} \leq 1$.
Hence, by definition \eqref{Xsb2} and Lemma \ref{LEM:timedecay}, we have
\begin{align*}
	\eqref{easy1} \lesssim   
	\prod_{j = 1}^3 \|v_j \|_{X^{\frac{s}{3}, \frac{1}{6}+, {\delta}}}
	\lesssim {\delta}^{1-} \prod_{j = 1}^3 \| v_j \|_{X^{\frac{s}{3}, \frac{1}{2}+, {\delta}}} \leq {\delta}^{1-}. 
\end{align*}

{
\noindent} $\bullet$ {\bf Case (b):} $u_j$ of type (I), $j = 1, \dots, 3$.

By Lemma \ref{LEM:prob1}, we have $|g_n (\omega)| \leq C {\delta}^{-\frac{\beta}{2}} {\langle {n} \rangle}^{\varepsilon}$ for $\omega$ outside an exceptional set of measure $< e^{-\frac{1}{{\delta}^c}}$. Then, by H\"older inequality with $p$ large ($\frac{1}{2} =\frac{1}{2+} + \frac{1}{p}$) and Young's inequality with \eqref{decay}, 
\begin{align*}
	\eqref{easy1} & \lesssim \sup_n \|{\langle {\tau - n^2} \rangle}^{-\frac{1}{2}+}\|_{L^{2+}_\tau}\\
	&\hphantom{XXX}\times \Big\| {\langle {n} \rangle}^{s-3{\alpha}} |g_n|^3 \operatorname*{\int}_{\tau = \tau_1 - \tau_2 + \tau_3} {\widehat}{\eta_{_{\delta}}}(\tau_1 - n^2){\overline}{{\widehat}{\eta_{_{\delta}}}(\tau_2 - n^2)}{\widehat}{\eta_{_{\delta}}}(\tau_3 - n^2) d\tau_1 d\tau_2 \Big\|_{l^2_{n} L^p_\tau}\\
	& \lesssim {\delta}^{1-} \|{\langle {n} \rangle}^{s-3{\alpha}} |g_n (\omega)|^3 \|_{l^2_n} \lesssim {\delta}^{1 -\frac{3}{2}\beta-} \|{\langle {n} \rangle}^{s-3{\alpha}+ 3{\varepsilon}} \|_{l^2_n} \lesssim {\delta}^{1-} 
\end{align*}

{
\noindent} as long as $2s - 6 {\alpha} + 6 {\varepsilon} < -1$ or $ {\alpha} > \frac{1}{3}s + \frac{1}{6}$.

{
\noindent} $\bullet$ {\bf Case (c):} Exactly two $u_j$'s of type (I). Say $u_1({\hspace{0.5mm}\text{I}\hspace{0.5mm}})$, $u_2({\hspace{0.5mm}\text{I}\hspace{0.5mm}})$, and $u_3({\text{I \hspace{-2.8mm} I} })$. 

By H\"older inequality with $p$ large, Young's inequality with \eqref{decay}, and Lemma \ref{LEM:prob1}, we have 
\begin{align*}
	\eqref{easy1} & \lesssim \sup_n \|{\langle {\tau - n^2} \rangle}^{-\frac{1}{2}+}\|_{L^{2+}_\tau} \\
	& \hphantom{XX}\times \Big\| {\langle {n} \rangle}^{s-2{\alpha}} |g_n|^2 \operatorname*{\int}_{\tau = \tau_1 - \tau_2 + \tau_3} {\widehat}{\eta_{_{\delta}}}(\tau_1 - n^2){\overline}{{\widehat}{\eta_{_{\delta}}}(\tau_2 - n^2)}{\widehat}{{\widetilde}{v}}_3(n, \tau_3) d\tau_1 d\tau_2 \Big\|_{l^2_{n} L^p_\tau}\\
	& \lesssim {\delta}^{\frac{1}{2}-} \big(\sup_n {\langle {n} \rangle}^{-2{\alpha}} |g_n|^2\big) \|{\langle {n} \rangle}^{s} {\widehat}{{\widetilde}{v}}_3 (n, \tau) \|_{l^2_n L^2_\tau} 
	\lesssim {\delta}^{\frac{1}{2}-\beta-} \|{\widetilde}{v}_3 \|_{X^{s, 0}}, 
\end{align*}

{
\noindent} for ${\alpha} > 0$ outside an exceptional set of measure $< e^{-\frac{1}{\delta^c}}$,
where  ${\widetilde}{v}_3$ is any extension of $v_3$ with  $\|v_3 \|_{X^{s, \frac{1}{2}+, {\delta}}} \leq 1$.
Hence, by definition \eqref{Xsb2} and Lemma \ref{LEM:timedecay}, we have
\begin{align*}
\eqref{easy1} 
\lesssim {\delta}^{1 -\beta-} \|v_3 \|_{X^{s, \frac{1}{2}+, {\delta}}} \leq {\delta}^{1-} .
\end{align*}

{
\noindent} $\bullet$ {\bf Case (d):} Exactly one $u_j$ of type (I). Say $u_1({\hspace{0.5mm}\text{I}\hspace{0.5mm}})$, $u_2({\text{I \hspace{-2.8mm} I} })$, and $u_3({\text{I \hspace{-2.8mm} I} })$.

By H\"older with $p$ large, Young's inequality with \eqref{decay}, and Lemma \ref{LEM:prob1}, we have 
\begin{align*}
	\eqref{easy1} & \lesssim \sup_n \|{\langle {\tau - n^2} \rangle}^{-\frac{1}{2}+}\|_{L^{2+}_\tau} \\
	& \hphantom{XX}\times \Big\| {\langle {n} \rangle}^{s-{\alpha}} |g_n| \operatorname*{\int}_{\tau = \tau_1 - \tau_2 + \tau_3} {\widehat}{\eta_{_{\delta}}}(\tau_1 - n^2){\overline}{{\widehat}{{\widetilde}{v}}_2(n, \tau_2)}{\widehat}{{\widetilde}{v}}_3(n, \tau_3) d\tau_1 d\tau_2 \Big\|_{l^2_{n} L^p_\tau}\\
	& \lesssim {\delta}^{\frac{1}{2}-} \big(\sup_n {\langle {n} \rangle}^{-s-{\alpha}} |g_n|\big) \Big\| \prod_{j = 2}^3 \| {\langle {n} \rangle}^s {\widehat}{{\widetilde}{v}}_j (n, \tau)\|_{L^\frac{4}{3}_\tau} \Big\|_{l^2_{n}}\\
	\intertext{By H\"older inequality in $n$ ($\frac{1}{2} = \frac{1}{4}+ \frac{1}{4}$) and in $\tau$ ($\frac{3}{4} = \frac{1}{2} + \frac{1}{4}$) with $l^2_n \subset l^4_n$,} 
	& \lesssim {\delta}^{\frac{1}{2}-\frac{\beta}{2} - } \prod_{j = 2}^3 \|{\langle {n} \rangle}^{s} {\langle {\tau- n^2} \rangle}^{\frac{1}{4}+} {\widehat}{{\widetilde}{v}}_j (n, \tau) \|_{l^4_n L^2_\tau} 
	 \leq {\delta}^{\frac{1}{2}-\frac{\beta}{2} - } 
	\prod_{j = 2}^3 \|{\widetilde}{v}_j \|_{X^{s, \frac{1}{4}+}},
\end{align*}

{
\noindent} for ${\alpha} > -s$ outside an exceptional set of measure $< e^{-\frac{1}{\delta^c}}$,
where  ${\widetilde}{v}_j$, $j = 2, 3$ are any extensions of $v_j$ with  $\|v_j \|_{X^{s, \frac{1}{2}+, {\delta}}} \leq 1$.
Hence, by definition \eqref{Xsb2} and Lemma \ref{LEM:timedecay}, we have
\begin{align*}	
	\eqref{easy1} \lesssim {\delta}^{1-\frac{\beta}{2} - } 
	\prod_{j = 2}^3 \|v_j \|_{X^{s, \frac{1}{2}+, {\delta}}}
	 \lesssim {\delta}^{1-} .
\end{align*}

\begin{remark} \label{REM:local}\rm
In this subsection, we carefully used the definition \eqref{Xsb2} of the local-in-time space $X^{s, b, {\delta}}$.
Strictly speaking, such a care must be taken in all the subsequent nonlinear analysis.
However, this is a routine work and, for simplicity of presentation, we write estimates 
directly with 
$\|u_j\|_{X^{s, b, {\delta}}}$ in the following, 
meaning that the same estimates hold with $\|{\widetilde}{u}_j\|_{X^{s, b}}$ 
for any extension ${\widetilde}{u}_j$ of $u_j$
(and thus we can take the infimum over ${\widetilde}{u}_j$.)

\end{remark}

\subsection{Estimate on $\mathcal{N}_1 $: High Modulation Cases}  \label{SUBSEC:LWP3}

In the next two subsections, we prove the main part of the estimate \eqref{trilinear1}: 
\begin{equation}
	\label{trilinear3} \| \mathcal{N}_1(u_1, u_2, u_3) \|_{X^{s, -\frac{1}{2}+}} \lesssim {\delta}^\theta 
\end{equation}

{
\noindent} for some $ \theta > 0$, 
outside an exceptional set of measure $e^{-\frac{1}{{\delta}^c}}$, where $\mathcal{N}_1$ is as in \eqref{NN1}
and $u_j$ is either of type (I) or (II).

In (most of) the following,\footnote{Basically, we only need to dyadically decompose the function $u_j$ of type $({\hspace{0.5mm}\text{I}\hspace{0.5mm}})$.} we assume that $u_1, u_2, u_3$
are dyadically decomposed with frequencies of size $N_1, N_2, N_3$, respectively.
As in \cite{Bourgain:1996p446}, 
let $N^1, N^2, N^3$ be the decreasing ordering of $N_1, N_2, N_3$ and $u^1, u^2, u^3$ be the corresponding $u_j$-factors. Also, let ${\sigma}^1, {\sigma}^2, {\sigma}^3$ denote the corresponding ${\sigma}_j := {\langle {\tau_j - n_j^2} \rangle}$. In the following, we use superscripts to imply that the functions (or variables) are arranged in the decreasing order of the spatial frequencies $N_1, N_2, N_3$.

In the rest of this subsection, we consider basic cases. 
Using duality, we can estimate \eqref{trilinear3} by 
\begin{equation}
	\label{duality1} \int_{-{\delta}}^{\delta} \int_{\mathbb{T}} ({\langle {
\partial_x} \rangle}^s u^1) u^2 u^3 \cdot v \, dx dt 
\end{equation}

{
\noindent} where $\| v\|_{X^{0, \frac{1}{2}-, {\delta}}} \leq 1$ (with the complex conjugate on an appropriate $u^j$.)
Note that in \eqref{duality1}, we implicitly inserted the sharp cutoff function $\chi_{_{\delta}}$
(in one of the factors $u^j$.)

\medskip

{
\noindent} $\bullet$ {\bf Case (A):} $u^1$ and $u^2$ are of type $({\text{I \hspace{-2.8mm} I} })$.

Suppose that  $u^3$ is of type $({\text{I \hspace{-2.8mm} I} })$.
In this case, there is no need of apply dyadic on $u^1, u^2$, and $u^3$.
By Lemmata \ref{LEM:deterministic} (a) and  \ref{LEM:timedecay}, we have 
\begin{equation*}
	\eqref{duality1} 
	\lesssim {\delta}^{\frac{1}{2}-} \| u^1\|_{X^{s, \frac{1}{2}, {\delta}}} \| u^2\|_{X^{0, \frac{1}{2}, {\delta}}}\| u^3\|_{X^{0, \frac{1}{2}, {\delta}}} 
	\| v\|_{X^{0, \frac{1}{2}-, {\delta}}}
	\leq {\delta}^{\frac{1}{2}-} 
\end{equation*}

{
\noindent} as long as $s \geq 0$. 

Next, suppose that $u^3$ is of type $({\hspace{0.5mm}\text{I}\hspace{0.5mm}})$ i.e. $u^3 = S(t) u_0$.
In this case, we do not need to apply dyadic decomposition on $u^1$ and $u^2$.
Namely, for a fixed dyadic block $N^3$ for $u^3$ of type $({\hspace{0.5mm}\text{I}\hspace{0.5mm}})$, 
with a slight abuse of notation, 
we  use $u^1$ and $u^2$ to denote the sums of $u^j$ over the dyadic blocks $N^j \geq N^3$, $j = 1, 2$.

By Lemma \ref{LEM:deterministic} (b) with $p$ large followed by
Lemma \ref{LEM:prob2}, we have 
\begin{align*}
	\eqref{duality1} 
	& \lesssim  \| u^1\|_{X^{s, \frac{1}{4}+, {\delta}}} \| u^2\|_{X^{0, \frac{1}{4}+, {\delta}}} \| u^3\|_{L^p} 
	\| v\|_{X^{0,\frac{1}{4}+, {\delta}}} \\
	& \lesssim (N^3)^{\frac{1}{2}-{\alpha}+} \| u^1\|_{X^{s, \frac{1}{4}+, {\delta}}} \| u^2\|_{X^{0, \frac{1}{4}+, {\delta}}} \| v\|_{X^{0, \frac{1}{4}+, {\delta}}} 
\end{align*}

{
\noindent} outside an exceptional set of measure $< e^{-\frac{1}{{\delta}^c}}$. If ${\langle {\tau_j - n_j^2} \rangle}^{\frac{1}{4}-} \gtrsim (N^3)^{\frac{1}{2}-{\alpha}+}$ for $u_j$ of type $({\text{I \hspace{-2.8mm} I} })$, or if ${\langle {\tau - n^2} \rangle}^{\frac{1}{4}-} \gtrsim (N^3)^{\frac{1}{2}-{\alpha}+}$, then \eqref{trilinear3} follows with $\theta = \frac{1}{2}-$ in view of Lemma \ref{LEM:timedecay}.\footnote{This 
is to say that by inserting a cutoff (on the Fourier side)
on the region
satisfying ${\langle {\tau_j - n_j^2} \rangle}^{\frac{1}{4}-} \gtrsim (N^3)^{\frac{1}{2}-{\alpha}+}$ for $u_j$ of type $({\text{I \hspace{-2.8mm} I} })$, or ${\langle {\tau - n^2} \rangle}^{\frac{1}{4}-} \gtrsim (N^3)^{\frac{1}{2}-{\alpha}+}$, 
we can establish \eqref{trilinear3} with $\theta = \frac{1}{2}-$.}

Hence, it remains to estimate the contribution to \eqref{duality1}
with a cutoff (on the Fourier side)  
on the region
satisfying
\begin{equation}
	\label{case0} {\langle {\tau - n^2} \rangle} \ll (N^3)^{2-4{\alpha}+}, \text{ and } {\langle {\tau_j - n_j^2} \rangle} \ll (N^3)^{2-4{\alpha}+} \text{ if } u_j \text{ of type }({\text{I \hspace{-2.8mm} I} }). 
\end{equation}

\medskip

{
\noindent} $\bullet$ {\bf Case (B):} $u^1$ of type $({\text{I \hspace{-2.8mm} I} })$, and $u^2$ of type $({\hspace{0.5mm}\text{I}\hspace{0.5mm}})$.

In this case, we do not need to apply dyadic decomposition on $u^1$.
Namely, for a fixed dyadic block $N^2$ for $u^2$ of type $({\hspace{0.5mm}\text{I}\hspace{0.5mm}})$, 
we use $u^1$ to denote the sum of $u^1$ over the dyadic blocks $N^1 \geq N^2$.

First, suppose that $u^3$ is of type $({\text{I \hspace{-2.8mm} I} })$. 
By Lemma \ref{LEM:deterministic} (b) with $p$ large followed by
Lemma \ref{LEM:prob2}, we have 
\begin{align*}
	\eqref{duality1} & \lesssim 
	\|u^1\|_{X^{s, \frac{1}{4}+, {\delta}}} \|u^2\|_{L^p} \|u^3\|_{X^{0, \frac{1}{4}+, {\delta}}}\|v\|_{X^{0, \frac{1}{4}+, {\delta}}} \\
	& \lesssim (N^2)^{\frac{1}{2}-{\alpha}+}\|u^1\|_{X^{s, \frac{1}{4}+, {\delta}}} \|u^3\|_{X^{0, \frac{1}{4}+, {\delta}}}
	\|v\|_{X^{0, \frac{1}{4}+, {\delta}}} 
\end{align*}

{
\noindent} outside an exceptional set of size $<e^{-\frac{1}{{\delta}^c}}$. If ${\langle {\tau_j - n_j^2} \rangle}^{\frac{1}{4}-} \gtrsim (N^2)^{\frac{1}{2}-{\alpha}+}$ for $u_j$ of type $({\text{I \hspace{-2.8mm} I} })$, or if ${\langle {\tau - n^2} \rangle}^{\frac{1}{4}-} \gtrsim (N^2)^{\frac{1}{2}-{\alpha}+}$, then \eqref{trilinear3} follows with $\theta = \frac{1}{2}-$ in view of Lemma \ref{LEM:timedecay}. 

Hence, it remains to estimate the contribution to \eqref{duality1}
from the region satisfying
\begin{equation}
	\label{caseA} {\langle {\tau - n^2} \rangle} \ll (N^2)^{2-4{\alpha}+}, \text{ and } {\langle {\tau_j - n_j^2} \rangle} \ll (N^2)^{2-4{\alpha}+} \text{ if } u_j \text{ of type }({\text{I \hspace{-2.8mm} I} }) 
\end{equation}

{
\noindent}
in the following.

Next, suppose that $u^3$ is of type $({\hspace{0.5mm}\text{I}\hspace{0.5mm}})$. 
By Lemma \ref{LEM:deterministic} (c) with $p$ large followed by
 Lemma \ref{LEM:prob2}, we have 
\begin{align*}
	\eqref{duality1} & \lesssim 
	\|u^1\|_{X^{s, 0+, {\delta}}} \|u^2\|_{L^p} \| u^3\|_{L^{p}}\|v\|_{X^{0, 0+, {\delta}}}\\
	& \lesssim (N^2)^{1-2{\alpha}+}\|u^1\|_{X^{s, 0+, {\delta}}}\|v\|_{X^{0, 0+, {\delta}}}. 
\end{align*}

{
\noindent} outside an exceptional set of measure $<e^{-\frac{1}{{\delta}^c}}$. If $({\sigma}^1)^{\frac{1}{2}-} \gtrsim (N^2)^{1-2{\alpha}+}$ or if ${\langle {\tau - n^2} \rangle}^{\frac{1}{2}-} \gtrsim (N^2)^{1-2{\alpha}+}$, then \eqref{trilinear3} follows with $\theta = \frac{1}{2}-$ in view of Lemma \ref{LEM:timedecay}. 
Hence, it remains to estimate the contribution to \eqref{duality1}
from the region satisfying \eqref{caseA} as well.

\medskip

{
\noindent} $\bullet$ {\bf Case (C):} $u^1$ of type $({\hspace{0.5mm}\text{I}\hspace{0.5mm}})$, and $u^2$, $u^3$ of type $({\text{I \hspace{-2.8mm} I} })$.

Suppose ${\langle {\tau - n^2} \rangle} \gg \max({\sigma}^2, {\sigma}^3)$. 
By Lemma \ref{LEM:deterministic} (d) with $p$ large followed by
 Lemmata \ref{LEM:prob2} and \ref{LEM:timedecay}, we have 
\begin{align*}
	\eqref{duality1} & \leq (N^1)^s \|u^1\|_{L^p}
	\|u^2\|_{X^{0, \frac{3}{8}, {\delta}}}\|u^3\|_{X^{0, \frac{3}{8}, {\delta}}}\|v\|_{X^{0, 0+, {\delta}}} \\
	 & \lesssim (N^1)^{s+\frac{1}{2}-{\alpha}+}\|u^2\|_{X^{0, \frac{3}{8}, {\delta}}}\|u^3\|_{X^{0, \frac{3}{8}, {\delta}}}\|v\|_{X^{0, 0+, {\delta}}} \\
	&\lesssim {\delta}^{\frac{1}{4}-} (N^1)^{s+\frac{1}{2}-{\alpha}+}\|u^2\|_{X^{0, \frac{1}{2}, {\delta}}} \|u^3\|_{X^{0, \frac{1}{2}, {\delta}}}\|v\|_{X^{0, 0+, {\delta}}} 
\end{align*}

{
\noindent} outside an exceptional set of measure $<e^{-\frac{1}{{\delta}^c}}$. Hence, \eqref{trilinear3} follows as long as ${\langle {\tau - n^2} \rangle} \gtrsim (N^1)^{2s + 1 - 2{\alpha}+}$. Similar results hold if ${\sigma}^2 \gg \max({\sigma}^3, {\langle {\tau-n^2} \rangle})$ 
or ${\sigma}^3 \gtrsim \max({\sigma}^2, {\langle {\tau-n^2} \rangle})$. 

Hence, it remains to estimate the contribution to \eqref{duality1}
from the region satisfying
\begin{equation}
	\label{caseB} {\langle {\tau - n^2} \rangle} \ll (N^1)^{2s + 1 - 2{\alpha}+}, \text{ and } {\langle {\tau_j - n_j^2} \rangle} \ll (N^1)^{2s + 1 - 2{\alpha}+} \text{ if } u_j \text{ of type }({\text{I \hspace{-2.8mm} I} }). 
\end{equation}

\medskip

{
\noindent} $\bullet$ {\bf Case (D):} $u^1$ of type $({\hspace{0.5mm}\text{I}\hspace{0.5mm}})$, and either $u^2({\hspace{0.5mm}\text{I}\hspace{0.5mm}})$, $u^3({\text{I \hspace{-2.8mm} I} })$ or $u^2({\text{I \hspace{-2.8mm} I} })$, $u^3({\hspace{0.5mm}\text{I}\hspace{0.5mm}})$.

Suppose that $u^2$ is of type $({\hspace{0.5mm}\text{I}\hspace{0.5mm}})$ and that $u^3$ is of type $({\text{I \hspace{-2.8mm} I} })$. Moreover, suppose ${\langle {\tau - n^2} \rangle} \gg {\sigma}^3$. 
By Lemma \ref{LEM:deterministic} (c) with $p$ large followed by
 Lemmata \ref{LEM:prob2} and \ref{LEM:timedecay}, we have 
\begin{align*}
	\eqref{duality1} & \leq (N^1)^s \|u^1\|_{L^p} \|u^2\|_{L^{p}}\|u^3\|_{X^{0, 0+, {\delta}}}\|v\|_{X^{0, 0, {\delta}}}\\
	& \lesssim (N^1)^{s+1-2{\alpha}+}\|u^3\|_{X^{0, 0+, {\delta}}}\|v\|_{X^{0, 0, {\delta}}} \\
	&\lesssim {\delta}^{\frac{1}{2}-} (N^1)^{s+1-2{\alpha}+}\|u^3\|_{X^{0, \frac{1}{2}, {\delta}}}\|v\|_{X^{0, 0, {\delta}}} 
\end{align*}

{
\noindent} outside an exceptional set of measure $<e^{-\frac{1}{{\delta}^c}}$. Hence, \eqref{trilinear3} follows as long as ${\langle {\tau - n^2} \rangle} \gtrsim (N^1)^{2s + 2 - 4{\alpha}+}$. Similar results hold if ${\sigma}^3 \gtrsim {\langle {\tau-n^2} \rangle}$, (or $u^2$ is of type $({\text{I \hspace{-2.8mm} I} })$ and $u^3$ is of type $({\hspace{0.5mm}\text{I}\hspace{0.5mm}})$.) 

Hence, it remains to estimate the contribution to \eqref{duality1}
from the region satisfying
\begin{equation}
	\label{caseC} {\langle {\tau - n^2} \rangle} \ll (N^1)^{2s + 2 - 4{\alpha}+}, \text{ and } {\langle {\tau_j - n_j^2} \rangle} \ll (N^1)^{2s + 2 - 4{\alpha}+} \text{ if } u_j \text{ of type }({\text{I \hspace{-2.8mm} I} }). 
\end{equation}

\medskip

{
\noindent} {\bf Summary:} Given a function $v(x, t)$, we can write $v$ as 
\begin{align}
	\label{v1} v (x, t)= \int {\langle {\lambda} \rangle}^{-\frac{1}{2}-} \Big( \sum_n {\langle {n} \rangle}^{2s} {\langle {\lambda} \rangle}^{1+} |{\widehat}{v}(n, n^2 + {\lambda})|^2 \Big)^\frac{1}{2} \Big\{e^{i {\lambda} t} \sum_n a_{\lambda} (n) e^{i(nx + n^2 t)} \Big\} d {\lambda} 
\end{align}

{
\noindent} where $a_{\lambda} (n) = \frac{{\widehat}{v}(n, n^2 + {\lambda})} {( \sum_m {\langle {m} \rangle}^{2s} |{\widehat}{v}(m, m^2 + {\lambda})|^2 )^\frac{1}{2}}$. Note that $\sum_n {\langle {n} \rangle}^{2s} |a_{\lambda}(n)|^2 = 1$. For $\|v\|_{X^{s, \frac{1}{2}+}}\leq 1$, we have 
\begin{equation}
	\label{v2} \int_{|{\lambda}| < K } {\langle {\lambda} \rangle}^{-\frac{1}{2}-} 
	\Big( \sum_n {\langle {n} \rangle}^{2s} {\langle {\lambda} \rangle}^{1+} |{\widehat}{v}(n, n^2 + {\lambda})|^2 \Big)^\frac{1}{2} d {\lambda} \lesssim 1 
\end{equation}

{
\noindent}
by Cauchy-Schwarz inequality. See (22) and (23) in \cite{Bourgain:1996p446}. Note that \eqref{v1} is a standard representation for functions in $X^{s, b}$ for $b> \frac{1}{2}$. For example, see Klainerman-Selberg \cite{Klainerman:2002p743}. 

\medskip
{
\noindent}
$\bullet$ {\bf Case 1:}
First, we consider the case if any of $u_j$ is of type (II).
From Cases (A)--(D), we assume that 
${\langle {\tau - n^2} \rangle} \ll K = K(N^j)$ for $j = 1, 2$, or $3$ in the following.
By H\"older inequality, we have
\begin{align*}
\|{\mathcal{N}}_1\|_{X^{s, -\frac{1}{2}+{\varepsilon}}}
& = \bigg(\sum_n \int {\langle {n} \rangle}^{2s} \frac{|{\widehat}{{\mathcal{N}}_1}(n, \tau)|^2}{{\langle {\tau - n^2} \rangle}^{1-2{\varepsilon}}}d\tau \bigg)^\frac{1}{2}
= \bigg(\sum_n \int {\langle {n} \rangle}^{2s} \frac{|{\widehat}{{\mathcal{N}}_1}(n, {\lambda} + n^2)|^2}{{\langle {\lambda} \rangle}^{1-2{\varepsilon}}}d{\lambda} \bigg)^\frac{1}{2}\\
& \lesssim K^{\varepsilon} 
\big\|{\langle {n} \rangle}^s {\widehat}{{\mathcal{N}}_1}(n, {\lambda} + n^2) \big\|_{L^\infty_{\lambda} l^2_n}.
\end{align*}

{
\noindent} Then, letting $* = \{ (n_1, n_2, n_3) \in\mathbb{Z}^3: n = n_1 - n_2 + n_3, \ n_2 \ne n_1, n_3\}$ 
and $**_n = \{ (\tau_1, \tau_2, \tau_3) \in \mathbb{R}^3: \tau = {\lambda} + n^2 = \tau_1 - \tau_2 + \tau_3 \}$, we have 
\begin{align}
	 \text{LHS of } \eqref{trilinear3} 
	 & \lesssim K^{0+} \sup_{{\langle {\lambda} \rangle}\ll K} \bigg\| \sum_{*} {\langle {n^1} \rangle}^s \int_{**_n}
	 \prod_{j = 1}^ 3 {\widehat}{u}_j(n_j, \tau_j)d\tau_1 d \tau_2 \bigg\|_{l^2_n} ,
\label{reduction1}
\end{align}

{
\noindent} where ${\widehat}{u}_j(n_j, \tau_j) = \frac{g_{n_j}(\omega){\delta} (\tau_j - n_j^2)}{\sqrt{1 + |n_j|^{2{\alpha}}}}$ or
\[{\widehat}{u}_j(n_j, \tau_j) = \int_{\{|{\lambda}_j| < K \}} {\langle {{\lambda}_j} \rangle}^{-\frac{1}{2}-} c_j({\lambda}_j) a_{{\lambda}_j}(n_j) {\delta} (\tau_j - n_j^2 - {\lambda}_j) d {\lambda}_j \]

{
\noindent}
with $\sum_{n_j} {\langle {n_j} \rangle}^{2s} |a_{{\lambda}_j}(n_j)|^2 \leq 1$ and  $c_j ({\lambda}_j) = \Big(\sum_{m_j} {\langle {m_j} \rangle}^{2s} {\langle {{\lambda}_j} \rangle}^{1+} |{\widehat}{u}_j(m_j, n_j^2 + {\lambda}_j)|^2 \Big)^\frac{1}{2}$ . 
For $j$ such that  $u_j$ is of type (II),  we can pull the integral in the corresponding ${\lambda}_j$ outside the $l^2_n$-norm via Minkowski integral inequality. 
Then, for fixed $n$, $n_j$, ${\lambda}$, and ${\lambda}_j$, 
by integrating in $\tau_1$ and $\tau_2$, we obtain
\[ \int_{**_n} \prod_{j = 1}^3 {\delta}(\tau_j - n_j^2 - {\widetilde}{\lambda}_j) d\tau_1d\tau_2
= \begin{cases}
1, & n^2 - n_1^2 + n_2^2 - n_3^2  + {\lambda} - {\widetilde}{\lambda}_1 + {\widetilde}{\lambda}_2 - {\widetilde}{\lambda}_3 = 0,\\
0, & \text{ otherwise,}
\end{cases}\]

{
\noindent}
where
${\widetilde}{\lambda}_j = 0$ or ${\lambda}_j$, corresponding to type(I) or (II).

For example, consider the case when  $u_1$ and $u_2$ are of type (II) and $u_3$ is of type (I).
Then, from \eqref{reduction1}, we have\footnote{We  drop the complex conjugate in the following
when it plays no role.}  
\begin{align}
 \bigg\| \sum_{*} & {\langle {n^1} \rangle}^s \int_{**_n}
 	 \prod_{j = 1}^ 3 {\widehat}{u}_j(n_j, \tau_j)d\tau_1 d \tau_2 \bigg\|_{l^2_n}\notag \\ 
		 & \lesssim  \int \prod_{j = 1}^2 \chi_{\{{\langle {{\lambda}_j} \rangle} < K \}} {\langle {{\lambda}_j} \rangle}^{-\frac{1}{2}-} c_j({\lambda}_j) \bigg\| \sum_{*} {\langle {n^1} \rangle}^s \prod_{k = 1}^ 2 a_{{\lambda}_k}(n_k)\frac{g_{n_3}(\omega)}{\sqrt{1 + |n_3|^{2{\alpha}}}} \bigg\|_{l^2_n} d{\lambda}_1d{\lambda}_2 \notag \\
	& \lesssim  \sup_{{\lambda}_1, {\lambda}_2} \bigg\| \sum_{*} {\langle {n^1} \rangle}^s \prod_{j = 1}^2 a_{{\lambda}_j}(n_j)\frac{g_{n_3}(\omega)}{\sqrt{1 + |n_3|^{2{\alpha}}}}\bigg\|_{l^2_n}, 
	\label{reduction2}
\end{align}

{
\noindent} where the last inequality follows from Cauchy-Schwarz inequality and \eqref{v2}. 
Note that if $u_j$ is supported on $[-{\delta}, {\delta}]$ in time,
then, in view of (the proof of) Lemma \ref{LEM:timedecay}, we can gain ${\delta}^\theta$ for small $\theta > 0$
in \eqref{reduction2}
by making the power in ${\langle {\lambda} \rangle}^{-\frac{1}{2}-}$ 
slightly larger (keeping it less than $-\frac{1}{2}$)
in \eqref{v2}.

\medskip
{
\noindent}
$\bullet$ {\bf Case 2:}
Next, we consider the case when all $u_j$'s are of type (I).
From \eqref{ALGEBRA}, we have 
\begin{equation}
|\tau - n^2| = |2(n_2-n_1)(n_2-n_3)| \lesssim (N^1)^2.
\label{sigmabound}
\end{equation}

{
\noindent}
By an argument similar to the proof of Lemma \ref{LEM:timedecay}, 
we have
\begin{align*}
\|{\mathcal{N}}_1\|_{X^{s, -\frac{1}{2}+{\varepsilon},{\delta}}}
& \lesssim {\delta}^\theta \|{\mathcal{N}}_1\|_{X^{s, -\frac{1}{2}+2{\varepsilon},{\delta}}}\\
& \leq {\delta}^\theta 
\bigg\|{\langle {\tau- n^2} \rangle}^{-\frac{1}{2}+2{\varepsilon}} \sum_* {\langle {n^1} \rangle}^s 
\int_{**_n} \prod_{j = 1}^3 \frac{g_{n_j}{\delta}(\tau_j - n_j^2)}{\sqrt{1+|n_j|^{2{\alpha}}}}
d\tau_1d\tau_2\bigg\|_{l^2_n L^2_\tau}
\end{align*}

{
\noindent}
for small $\theta > 0$.
By integrating in $\tau_1$ and $\tau_2$, we have
\[ \int_{**_n} \prod_{j = 1}^3 {\delta}(\tau_j - n_j^2) d\tau_1d\tau_2
= {\delta}(\tau - n_1^2 + n_2^2 - n_3^2).\]

{
\noindent}
Hence, for fixed $n$, we have
\begin{align*}
 \bigg\|{\langle {\tau- & n^2} \rangle}^{-\frac{1}{2}+2{\varepsilon}} \sum_* {\langle {n^1} \rangle}^s 
\int_{**_n} \prod_{j = 1}^3 \frac{g_{n_j}{\delta}(\tau_j - n_j^2)}{\sqrt{1+|n_j|^{2{\alpha}}}}
d\tau_1d\tau_2\bigg\|_{ L^2_\tau}\\
& = 
\bigg( \int {\langle {\tau- n^2} \rangle}^{-1+4{\varepsilon}} 
\bigg|\sum_{\substack{n = n_1 - n_2 + n_3\\  n_2 \ne n_1, n_3}}
{\langle {n^1} \rangle}^s 
 \prod_{j = 1}^3 \frac{g_{n_j}}{\sqrt{1+|n_j|^{2{\alpha}}}}
{\delta}(\tau - n_1^2 + n_2^2 - n_3^2)\bigg|^2d\tau\bigg)^\frac{1}{2}\\
& = 
\bigg( \int_{|\mu| \lesssim (N^1)^2}
{\langle {\mu} \rangle}^{-1+4{\varepsilon}} \bigg)^\frac{1}{2}
\sup_{|\mu| \lesssim (N^1)^2}
\bigg|\sum_{\substack{n = n_1 - n_2 + n_3\\  n_2 \ne n_1, n_3\\n^2 = n_1^2 + n_2^2 - n_3^2+ \mu}}
{\langle {n^1} \rangle}^s 
 \prod_{j = 1}^3 \frac{g_{n_j}}{\sqrt{1+|n_j|^{2{\alpha}}}}
\bigg|\\
& \lesssim
(N^1)^{s+4{\varepsilon}}
\sup_{|\mu| \lesssim (N^1)^2}
\bigg|\sum_{\substack{n = n_1 - n_2 + n_3\\  n_2 \ne n_1, n_3\\n^2 = n_1^2 + n_2^2 - n_3^2+ \mu}}
 \prod_{j = 1}^3 \frac{g_{n_j}}{\sqrt{1+|n_j|^{2{\alpha}}}}
\bigg|.
\end{align*}

{
\noindent}
Then, we can take $l^2$-summation in $n$.

\medskip

Therefore, we can reduce the estimate \eqref{trilinear3} into the following two cases (with $\theta = 0+$):

\medskip

{
\noindent} $\bullet$ $u^1$ is of type $({\text{I \hspace{-2.8mm} I} })$:

In this case, we do not need to apply dyadic decomposition on $u^1$.
Namely, for a fixed dyadic block $N^2$ for $u^2$, 
with a slight abuse of notation, 
we use $u^1$ to denote the sum of $u^1$ over the dyadic blocks $N^1 \geq N^2$.

From \eqref{case0} and \eqref{caseA}, we can assume that ${\sigma}_j \ll (N^3)^{2-4{\alpha}+}$ or $(N^2)^{2-4{\alpha}+}$ for $u_j$ of type $({\text{I \hspace{-2.8mm} I} })$. Then, by \eqref{v1} and \eqref{v2}, we can bound \eqref{trilinear3} as follows: 
\begin{align}
	 \eqref{trilinear3} \lesssim {\delta}^{\theta} M(N^2, N^3) \bigg( \sum_n \Big| \sum_{\substack{ n = n_1 - n_2 + n_3 \\
	n_2 \ne n_1, n_3\\
	n^2 = n_1^2 - n_2^2 + n_3^2 + \mu}} a_1(n_1){\overline}{a_2(n_2)}a_3(n_3) \Big|^2 \bigg)^\frac{1}{2}, 
\label{u2}
\end{align}

{
\noindent} where $\sum_{n} |a^1(n)|^2 \leq 1$, $a^j(n) = \frac{g_n(\omega)}{\sqrt{1 + |n|^{2{\alpha}}}}$ or $\sum_{|n| \sim N^j} |a^j(n)|^2 \leq (N^j)^{-2s}$ for $j = 2, 3$, and 
\begin{tabbing}
	\hspace{1cm} \= Case (A): \= $M(N^2, N^3) = ( N^3)^{0+}$ \= and \= $|\mu| \ll (N^3)^{2-4{\alpha}+}$ \\
	\> Case (B): \> $M(N^2, N^3) = ( N^2)^{0+}$ \> and \> $|\mu| \ll (N^2)^{2-4{\alpha}+}$. 
\end{tabbing}

\medskip 

{
\noindent} $\bullet$ $u^1$ is of type $({\hspace{0.5mm}\text{I}\hspace{0.5mm}})$:

From \eqref{caseB} and \eqref{caseC}, we can assume that ${\sigma}_j \ll (N^1)^{2s + 1 - 2 {\alpha}+}$ or $(N^1)^{2s + 2 - 4 {\alpha}+}$ for $u_j$ of type $({\text{I \hspace{-2.8mm} I} })$. Then, by \eqref{v1} and \eqref{v2}, we can bound \eqref{trilinear3} as follows: 
\begin{align}
	 \eqref{trilinear3} \lesssim {\delta}^{\theta} (N^1)^{s+} \bigg( \sum_{|n| \lesssim N^1} \Big| \sum_{\substack{ n = n_1 - n_2 + n_3 \\
	n_2 \ne n_1, n_3\\
	n^2 = n_1^2 - n_2^2 + n_3^2 + \mu}} a_1(n_1){\overline}{a_2(n_2)}a_3(n_3) \Big|^2 \bigg)^\frac{1}{2}, 
\label{u1}
\end{align}

{
\noindent} where $a^1(n) = \frac{g_n(\omega)}{\sqrt{1 + |n|^{2{\alpha}}}}$, 
$a^j(n) = \frac{g_n(\omega)}{\sqrt{1 + |n|^{2{\alpha}}}}$ or $\sum_{|n| \sim N^j} |a^j(n)|^2 \leq (N^j)^{-2s}$ for $j = 2, 3$, and 
\begin{tabbing}
	\hspace{1cm} \= Case (C): \hspace{5mm} \= $|\mu| \ll (N^1)^{2s + 1 - 2 {\alpha}+}$ \\
	\> Case (D): \> $|\mu| \ll (N^1)^{2s + 2 - 4 {\alpha}+}$ \\
	\> All type (I): \> $|\mu| \ll (N^1)^2$, 
\end{tabbing}

{
\noindent} Note that all the spatial frequencies are dyadically decomposed in this case.

\medskip

Suppose $|n_2| > 10 (|n_1| + |n_3|)$. Then, on the one hand, $|\mu| \sim |(n_2 - n_1) (n_2 - n_3)| \sim |n_2|^2 \sim (N^1)^2$ by \eqref{ALGEBRA}. 
On the other hand, if $u^1 = u_2$ is of type $({\text{I \hspace{-2.8mm} I} })$, we have $|\mu| \ll (N^2)^{2- 4{\alpha}+} \ll (N^1)^2$ as long as ${\alpha} > 0$. If $u^1 = u_2$ is of type $({\hspace{0.5mm}\text{I}\hspace{0.5mm}})$, we have $|\mu| \ll (N^1)^{2s + 2 - 4{\alpha}+} \ll (N^1)^2$ since ${\alpha} > \frac{s}{2}$. In both cases, we would have a contradiction. Hence, we can assume that $|n_1| \sim N^1$ or $|n_3| \sim N^1$. Moreover, by symmetry between $u_1$ and $u_3$, we assume $|n_1| \sim N^1$ in the following.

Lastly, we list all the different cases following \cite{Bourgain:1996p446}. We consider these cases in details in the next subsection.
\begin{tabbing}
	\hspace{1cm} \=Case (a): \= $n_1 = N^1({\text{I \hspace{-2.8mm} I} })$, \= $n_2 = N^2({\hspace{0.5mm}\text{I}\hspace{0.5mm}})$, \= $n_3 = N^3({\text{I \hspace{-2.8mm} I} })$ or \= $n_2 = N^3({\hspace{0.5mm}\text{I}\hspace{0.5mm}})$, \= $n_3 = N^2({\text{I \hspace{-2.8mm} I} })$ \\
	
	\>Case (b): \>$n_1 = N^1({\text{I \hspace{-2.8mm} I} })$, \>$n_2 = N^3({\text{I \hspace{-2.8mm} I} })$, \> $n_3 = N^2({\hspace{0.5mm}\text{I}\hspace{0.5mm}})$ or \>$n_2 = N^2({\text{I \hspace{-2.8mm} I} })$, \> $n_3 = N^3({\hspace{0.5mm}\text{I}\hspace{0.5mm}})$ \\
	
	\>Case (c): \> $n_1 = N^1({\hspace{0.5mm}\text{I}\hspace{0.5mm}})$, \>$n_2 = N^2({\text{I \hspace{-2.8mm} I} })$, \>$n_3 = N^3({\text{I \hspace{-2.8mm} I} })$ \\
	
	\>Case (d): \>$n_1 = N^1({\hspace{0.5mm}\text{I}\hspace{0.5mm}})$, \>$n_2 = N^3({\text{I \hspace{-2.8mm} I} })$, \>$n_3 = N^2({\text{I \hspace{-2.8mm} I} })$\\
	
	\>Case (e): \>$n_1 = N^1({\text{I \hspace{-2.8mm} I} })$, \>$n_2 = N^2({\hspace{0.5mm}\text{I}\hspace{0.5mm}})$, \>$n_3 = N^3({\hspace{0.5mm}\text{I}\hspace{0.5mm}})$\\
	
	\>Case (f): \>$n_1 = N^1({\text{I \hspace{-2.8mm} I} })$, \>$n_2 = N^3({\hspace{0.5mm}\text{I}\hspace{0.5mm}})$, \>$n_3 = N^2({\hspace{0.5mm}\text{I}\hspace{0.5mm}})$\\
	
	\>Case (g): \>$n_1 = N^1({\hspace{0.5mm}\text{I}\hspace{0.5mm}})$, \>$n_2 = N^2({\hspace{0.5mm}\text{I}\hspace{0.5mm}})$, \>$n_3 = N^3({\text{I \hspace{-2.8mm} I} })$\\
	
	\>Case (h): \>$n_1 = N^1({\hspace{0.5mm}\text{I}\hspace{0.5mm}})$, \>$n_2 = N^3({\hspace{0.5mm}\text{I}\hspace{0.5mm}})$, \>$n_3 = N^2({\text{I \hspace{-2.8mm} I} })$\\
	
	\>Case (i): \>$n_1 = N^1({\hspace{0.5mm}\text{I}\hspace{0.5mm}})$, \>$n_2 = N^2({\text{I \hspace{-2.8mm} I} })$, \>$n_3 = N^3({\hspace{0.5mm}\text{I}\hspace{0.5mm}})$\\
	
	\>Case (j): \>$n_1 = N^1({\hspace{0.5mm}\text{I}\hspace{0.5mm}})$, \>$n_2 = N^3({\text{I \hspace{-2.8mm} I} })$, \>$n_3 = N^2({\hspace{0.5mm}\text{I}\hspace{0.5mm}})$\\
	
	\>Case (k): \>$n_1 = N^1({\hspace{0.5mm}\text{I}\hspace{0.5mm}})$, \>$n_2 = N^2({\hspace{0.5mm}\text{I}\hspace{0.5mm}})$, \>$n_3 = N^3({\hspace{0.5mm}\text{I}\hspace{0.5mm}})$\\
	
	\>Case (l): \>$n_1 = N^1({\hspace{0.5mm}\text{I}\hspace{0.5mm}})$, \>$n_2 = N^3({\hspace{0.5mm}\text{I}\hspace{0.5mm}})$, \>$n_3 = N^2({\hspace{0.5mm}\text{I}\hspace{0.5mm}})$\\
\end{tabbing}

\subsection{Estimate on $\mathcal{N}_1$: Low Modulation Cases}  \label{SUBSEC:LWP4}

For notational simplicity, we use $|n|^{\alpha} $ for $\sqrt{1+ |n|^{2{\alpha}}}$. 
We may drop a complex conjugate on $u_2$ when it plays no significant role.
Now, let 
\begin{align*} 
	A_n = \{ (n_1, n_2, n_3) \in \mathbb{Z}^3: n = & \ n_1 - n_2 + n_3, |n_j| \sim N_j , j = 2, 3, \\
	& n_2 \ne n_1, n_3, \text{ and } n^2 = n_1^2 - n_2^2 + n_3^2 + \mu\} 
\end{align*}

{
\noindent} and $ B_n = A_n \cap \{ |n_1| \sim N_1 \}. $ Also, from \eqref{ALGEBRA}, we have 
\begin{equation}
	\label{ALGEBRA7} \mu = 2 (n_2 - n_1) (n_2 - n_3) = 2 (n - n_1) (n - n_3). 
\end{equation}

\medskip

{
\noindent} $\bullet$ {\bf Cases (k), (l):} $u_1, u_2, u_3$ of type $({\hspace{0.5mm}\text{I}\hspace{0.5mm}})$. 
\quad
In this case, we have 
\begin{align}
	\label{casek} \eqref{u1} \lesssim {\delta}^{\theta} N_1^{s+} \bigg( \sum_{|n| \lesssim N_1} \Big|\sum_{B_n} \frac{g_{n_1}}{|n_1|^{\alpha}} \frac{{\overline}{g_{n_2}}}{|n_2|^{\alpha}} \frac{g_{n_3}}{|n_3|^{\alpha}} \Big|^2 \bigg)^\frac{1}{2}. 
\end{align}

First, we consider the contribution from $n_1 \ne n_3$. Let 
\begin{align*}
	F_n (\omega):= \sum_{C_n} \frac{g_{n_1}(\omega)}{|n_1|^{\alpha}} \frac{{\overline}{g_{n_2}}(\omega)}{|n_2|^{\alpha}} \frac{g_{n_3}(\omega)}{|n_3|^{\alpha}}, 
\end{align*}

{
\noindent} where $ C_n = B_n \cap \{ n_1 \ne n_3\}. $ Then, 
applying Lemma \ref{LEM:hyper} for
with  ${\lambda} = {\delta}^{-\frac{3}{2}\beta} N_1^{\frac{3}{2}{\varepsilon}} \| F_n\|_{L^2(\Omega)}$ with ${\varepsilon} = 0+$, we have 
\begin{align}
	\label{chaosestimate} \mathbb{P} (|F_n(\omega)| \geq {\delta}^{-\frac{3}{2}\beta} N_1^{\frac{3}{2}{\varepsilon}}\| F_n\|_{L^2(\Omega)}) \leq e^{-\frac{c'N_1^{\varepsilon}}{ {\delta}^\beta}}. 
\end{align}

{
\noindent} By Lemma \ref{LEM:count1}, we have 
\begin{align*}
	\text{RHS of } \eqref{casek} & \lesssim {\delta}^{\theta-\frac{3}{2}\beta} N_1^{s+\frac{3}{2}{\varepsilon}+} \bigg( \sum_{|n| \lesssim N_1} \sum_{C_n} \frac{1}{|n_1|^{2{\alpha}}|n_2|^{2{\alpha}}|n_3|^{2{\alpha}}} \bigg)^\frac{1}{2}\\
	& \lesssim {\delta}^{\theta-\frac{3}{2}\beta} N_1^{s -{\alpha} +\frac{3}{2}{\varepsilon}+} (N^2)^{-{\alpha}} (N^3)^{-{\alpha}+\frac{1}{2}} \\
	& \lesssim 
	\begin{cases}
		{\delta}^{\theta-\frac{3}{2}\beta} N_1^{s -3{\alpha} + \frac{1}{2} +\frac{3}{2}{\varepsilon}+} & \text{ for } {\alpha} \leq \frac{1}{4} \\
		{\delta}^{\theta-\frac{3}{2}\beta} N_1^{s -{\alpha} +\frac{3}{2}{\varepsilon}+} & \text{ for }{\alpha} \geq \frac{1}{4} 
	\end{cases}
	\\
	& \leq {\delta}^{\theta-\frac{3}{2}\beta} \prod_{j = 1}^3 N_j^{0-}, \ \left\{
	\begin{array}{ll}
		\text{for } {\alpha} > \frac{s}{3} + \frac{1}{6} & \text{ (with } {\alpha} \leq \frac{1}{4}) \\
		\text{for } {\alpha} > s & \text{ (with }{\alpha} \geq \frac{1}{4}) 
	\end{array}
	\right. \notag 
\end{align*}

{
\noindent} outside an exceptional set of measure
\begin{equation}
\label{EXCEPT1}
< \sum_{|n| \lesssim N_1} e^{-\frac{c'N_1^{\varepsilon}}{{\delta}^\beta}} \lesssim N_1 e^{-\frac{c'N_1^{\varepsilon}}{{\delta}^\beta}} \leq N_1^{0-} e^{-\frac{c'}{{\delta}^\beta} N_1^{\varepsilon} +(1+) \log N_1} < N_1^{0-} e^{-\frac{1}{{\delta}^{c}}}.
\end{equation}

{
\noindent} Note that in this case we need to make sure that the measures of these exceptional sets corresponding to different dyadic blocks are indeed summable and bounded by $e^{-\frac{1}{{\delta}^c}}$. We may not be explicit about this point in other cases. e.g. Cases (A)--(D) in Subsection \ref{SUBSEC:LWP3}. We do not encounter this issue in using Lemma \ref{LEM:prob1} since it gives one exceptional set of measure $<e^{-\frac{1}{{\delta}^c}}$ for all the frequencies.

Now, consider the contribution from $n_1 = n_3$. It follows from \eqref{ALGEBRA7} that there is at most one choice of $(n_1, n_2, n_3)$ for each fixed $n$. Thus, $\sum_{|n| \lesssim N_1} \big|\sum_{B_n, \, n_1 = n_3} 1\big|^2 = \sum_{|n| \lesssim N_1} \sum_{B_n, \, n_1 = n_3} 1$. Hence, by Lemmata \ref{LEM:count1} and \ref{LEM:prob1}, we have 
\begin{align}
	\text{RHS of } \eqref{casek} & \lesssim {\delta}^{\theta-\frac{3}{2}\beta} N_1^{s -2{\alpha} + 2{\varepsilon}+} N_2^{-{\alpha} + \frac{1}{2} + {\varepsilon}} \leq {\delta}^{\theta-\frac{3}{2}\beta}\prod_{j = 1}^3 N_j^{0-} 
	\label{ZK}
\end{align}

{
\noindent}  for ${\alpha} > \frac{s}{3} + \frac{1}{6}$ outside an exceptional set of measure $< e^{-\frac{1}{{\delta}^c}}$.

\medskip

{
\noindent} $\bullet$ {\bf Case (a):} (Case (b) can be treated in a similar way by replacing $n_2$ and $n_3$.)

In this case, we have $\mu = 2 (n_2 - n_1) (n_2 - n_3) = o( (N_2)^{2-4{\alpha}+})$. 
This implies that $|n|, |n_1|, |n_3| \lesssim N_2^q$ for some $q > 0$ since $n_2 \ne n_1, n_3$. 
Now, fix $n$.
Then, it follows from \eqref{DIVISOR}
that 
\begin{equation}\label{A1}
\sum_{A_n} 1 \lesssim N_2^{\varepsilon}.
\end{equation}

{
\noindent}
Then, by Lemma \ref{LEM:prob1} and Cauchy-Schwarz inequality, we have 
\begin{align}
	\label{caseaa} \eqref{u2} & 
	\lesssim {\delta}^{\theta-\frac{\beta}{2}} (N_2)^{-{\alpha} + \frac{1}{2}{\varepsilon} +} 
	\bigg( \sum_n  \Big(\sum_{A_n}|a_1(n_1)|^2|a_3(n_3)|^2\Big)
	 \Big(\sum_{A_n}1\Big)\bigg)^\frac{1}{2} \notag \\
	\intertext{By  \eqref{A1}, we have } 
	& \lesssim {\delta}^{\theta-\frac{\beta}{2}} N_2^{-{\alpha}+{\varepsilon}+} 
	\Big( \sum_n  \sum_{A_n}|a_1(n_1)|^2|a_3(n_3)|^2
	 \Big)^\frac{1}{2} \notag \\
		& \lesssim {\delta}^{\theta-\frac{\beta}{2}} N_2^{-{\alpha}+{\varepsilon}+} N_3^{-s}\leq {\delta}^{\theta'} N_2^{0-} N_3^{0-} 
\end{align}

{
\noindent} for ${\alpha} > 0$ and $s\geq 0 $ outside an exceptional set of measure $< e^{-\frac{1}{{\delta}^c}}$.
Note that $|n_3| \lesssim N_2^q$ is crucial in the last inequality of \eqref{caseaa} when $s = 0$, $n_2 = N^3$, and $n_3 = N^2$. 

In Case (b), we have $\mu = 2 (n_2 - n_1) (n_2 - n_3) = o( (N_3)^{2-4{\alpha}+})$, which implies that $|n|, |n_1|, |n_2| \lesssim N_3^q$ for some $q > 0$ since $n_2 \ne n_1, n_3$. The rest of the argument follows as above by replacing $n_2$ and $n_3$.

\medskip

{
\noindent} $\bullet$ {\bf Case (c):} (Case (d) can be treated in a similar way by replacing $n_2$ and $n_3$.)

Let $b_2(n_2) = |n_2|^s a_2(n_2)$. Then, we have $\sum_{|n_2|\sim N_2} |b_2(n_2)|^2 \lesssim 1$. By Lemma \ref{LEM:prob1} and Cauchy-Schwarz inequality on $n_3$ in the inner sum, 
\begin{align*}
	\eqref{u1} \lesssim {\delta}^{\theta-\frac{\beta}{2}} N_1^{s -{\alpha} +{\varepsilon}+} N_2^{-s} N_3^{-s} \Big( \sum_{|n| \lesssim N^1} \sum_{B_n} |b_2(n_2)|^2 \Big)^\frac{1}{2} 
\end{align*}

{
\noindent} outside an exceptional set of measure $< e^{-\frac{1}{{\delta}^c}}$. 
For fixed $n_2$, it follows from (the proof of) Lemma \ref{LEM:count1} that there are at most $N_1^{0+}$ terms in the sum. 
Hence, we have 
\begin{align*}
	\eqref{u1} \lesssim {\delta}^{\theta-\frac{\beta}{2}} N_1^{s -{\alpha} +{\varepsilon}+} 
	N_2^{-s} N_3^{-s} \leq {\delta}^{\theta'}N_1^{0-} N_2^{0-} N_3^{0-} 
\end{align*}

{
\noindent} for ${\alpha} > s \geq 0$.

\medskip

{
\noindent} $\bullet$ {\bf Case (e):} (Case (f) is basically the same.)

In this case, we have $ |\mu| = |2 (n_2 - n_1) (n_2 - n_3)| \ll N_2^{2-4{\alpha}+} $. 
Fix $n$.
Then, from \eqref{DIVISOR}, 
there are at most $d(\mu)  = O(N_2^{0+})$ many choices for $n_2$ and $n_3$.
Then, by Lemma \ref{LEM:prob1}, Cauchy-Schwarz inequality, and \eqref{A1}, we have
\begin{align*}
	\eqref{u2} 
& \lesssim {\delta}^{\theta-\beta} 
	N_2^{-{\alpha}+{\varepsilon}+} N_3^{-{\alpha}} \bigg( \sum_{|n| \lesssim N_2^q} 
	\Big(\sum_{A_n} |a_1(n_1)|^2\Big) \Big(\sum_{A_n} 1\Big) \bigg)^\frac{1}{2} \\
& \lesssim {\delta}^{\theta-\beta} 
	N_2^{-{\alpha}+\frac{3}{2}{\varepsilon}+} N_3^{-{\alpha}} \Big( \sum_{|n| \lesssim N_2^q} \sum_{A_n} |a_1(n_1)|^2 \Big)^\frac{1}{2} \\
& \lesssim {\delta}^{\theta-\beta} N_2^{-{\alpha}+2{\varepsilon}+} N_3^{ -{\alpha}} \leq {\delta}^{\theta'}N_2^{0-} N_3^{0-} 
\end{align*}

{
\noindent} for $ {\alpha} > 0$ outside an exceptional set of measure $<e^{-\frac{1}{{\delta}^c}}$
(with some $q>0$ as in Case (a).)
In the above computation, we used 
\[ \sum_{|n| \lesssim N_2^q} \sum_{A_n} |a_1(n_1)|^2
\lesssim N_2^{\varepsilon} \sum_{n_1} |a_1(n_1)|^2 \leq N_2^{\varepsilon}\]

{
\noindent}
by first summing over $n_2$ (for fixed $n_1$) and then over $n_1$.

\medskip

{
\noindent} $\bullet$ {\bf Case (g):} (Cases (h), (i), (j)  are basically the same.)

Fix $n$.
Then, from \eqref{DIVISOR}, 
there are at most $d(\mu)  = O(N_1^{0+})$ many choices for $n_2$ and $n_3$.
Thus, we have $\sum_{A_n} 1 \lesssim N_1^{\varepsilon}.$
Then, by Lemma \ref{LEM:prob1} and Cauchy-Schwarz inequality as before,  we have
\begin{align*}
	\eqref{u1} 
& \lesssim {\delta}^{\theta-\beta} 
	N_1^{s-{\alpha}+{\varepsilon}+} N_2^{-{\alpha}+ \frac{1}{2}{\varepsilon}} \Big( \sum_{|n| \lesssim N_1} 
	\sum_{A_n} |a_3(n_3)|^2\Big)^\frac{1}{2} \\
& \lesssim {\delta}^{\theta-\beta} 
	N_1^{s-{\alpha}+\frac{3}{2}{\varepsilon}+} N_2^{-{\alpha}+ \frac{1}{2}{\varepsilon}} N_3^{-s}
 \leq {\delta}^{\theta'}\prod_{j = 1}^3 N_j^{0-} 
\end{align*}

{
\noindent} for $ {\alpha} > s\geq 0$ outside an exceptional set of measure $<e^{-\frac{1}{{\delta}^c}}$.

\medskip

This completes the proof of Theorem \ref{THM:LWP}.

\section{Global Theory}  \label{SEC:GWP}

In this section, we prove almost sure global well-posedness of \eqref{NLS2}.

\subsection{Reduction of Theorem \ref{THM:GWP1} to Proposition \ref{PROP:HNLS} }  \label{SUBSEC:GWP1}

In this subsection, we first prove Theorem \ref{THM:GWP1}, assuming the following proposition.
Heuristically speaking, 
this  says 
``almost'' almost sure global well-posedness (Proposition \ref{THM:GWP2})
implies almost sure global well-posedness (Theorem \ref{THM:GWP1}.)

\begin{proposition}
	\label{THM:GWP2} Let ${\alpha} \in ( \frac{5}{12}, \frac{1}{2}]$. Given $T> 0$ and ${\varepsilon} >0$, there exists $\Omega_{T, {\varepsilon}} \in \mathcal{F}$ with the following properties:
	\begin{enumerate}
		\item[(i)] $\mathbb{P}(\Omega_{T, {\varepsilon}}^c) = \rho_{\alpha} \circ u_0(\Omega_{T, {\varepsilon}}^c) < {\varepsilon}$, 
				where $\rho_{\alpha}$ is the Gaussian probability measure on $H^{{\alpha}-\frac{1}{2}-}({\mathbb{T}})$ defined in \eqref{Gaussian1}
		and $u_0$ is viewed as a map $u_0:\Omega \to H^{{\alpha}-\frac{1}{2}-}(\mathbb{T})$.
		
		\item[(ii)] For each $\omega \in \Omega_{T, {\varepsilon}}$ there exists a (unique) solution $u$ of \eqref{NLS2} in
		\[e^{-i {
\partial_x}^2 t}u_0 + C([-T, T];L^2(\mathbb{T})) \subset C([-T, T];H^{{\alpha} - \frac{1}{2}-}(\mathbb{T}))\]
		with the initial condition $u_0^\omega$ given by \eqref{IV}. 
			Here, the uniqueness holds in a very mild sense. See Remark \ref{REM:unique}.
	\end{enumerate}
\end{proposition}
\begin{proof}
	[Proof of Theorem \ref{THM:GWP1}] For fixed ${\varepsilon} > 0$, let $T_j = 2^j$ and ${\varepsilon}_j = 2^{-j} {\varepsilon}$. Apply Proposition \ref{THM:GWP2} and construct $\Omega_{T_j, {\varepsilon}_j}$. Then, let $\Omega_{\varepsilon} = \bigcap_{j = 1}^\infty \Omega_{T_j, {\varepsilon}_j}$. Note that \eqref{NLS2} is globally well-posed on $\Omega_{\varepsilon}$ with $\mathbb{P} (\Omega_{\varepsilon}^c) < {\varepsilon}$. Now, let ${\widetilde}{\Omega} = \bigcup_{{\varepsilon} > 0} \Omega_{\varepsilon}$. Then, \eqref{NLS2} is globally well-posed on ${\widetilde}{\Omega}$ and $\mathbb{P} ({\widetilde}{\Omega}^c) = 0$. 
\end{proof}

Now, we present the proof of Proposition \ref{THM:GWP2}. 
\begin{proof}
	[Proof of Proposition \ref{THM:GWP2}]
	
	First, recall the following argument which relates the time of local existence ${\delta}$ and the size of the initial condition. Consider \eqref{NLS2}. 
We briefly review the deterministic $L^2$-local theory. 
For $t \in [-{\delta}, {\delta}]$, \eqref{NLS3} is equivalent to 	
\[ u(t) = S(t) u_0 \pm i \int_0^t S(t - t') \mathcal{N}(\chi_{\delta}(t') u) (t') d t'.\] 

{
\noindent}
By \eqref{duhamel},  we have 
	\begin{align*}
		 \| u \|_{X^{0, \frac{1}{2}+{\varepsilon}_1, {\delta}}} 
		& \leq C_0\|u_0\|_{L^2} + C_1\|  \mathcal{N}(\chi_{_{\delta}} {\widetilde}{u})\|_{X^{0, -\frac{1}{2}+{\varepsilon}_1}} \\
\intertext{for any extension ${\widetilde}{u}$ of $u$.
By duality (against $v$ in $X^{0, \frac{1}{2}-{\varepsilon}_1}$)
with Lemma \ref{LEM:deterministic} (a) followed by Lemma \ref{LEM:timedecay},}		
		& \leq C_0\|u_0\|_{L^2} + C_2{\delta}^{\frac{1}{2}-{\varepsilon}_1-{\varepsilon}_2}\|{\widetilde}{u}\|^3_{X^{0, \frac{1}{2}+{\varepsilon}_1}} 
	\end{align*}
	
	{
\noindent} 
	for some small ${\varepsilon}_2>0$. Hence, we obtain
		\begin{align}
	\label{local} 	 \| u \|_{X^{0, \frac{1}{2}+, {\delta}}} 
		& \leq C_0\|u_0\|_{L^2} + C_2{\delta}^{\frac{1}{2}-{\varepsilon}_1-{\varepsilon}_2}\|u\|^3_{X^{0, \frac{1}{2}+{\varepsilon}_1, {\delta}}}.
	\end{align}
	
		{
\noindent}
	Note that the ``loss'' ${\varepsilon}_1$ comes from the fact that 
	$b = \frac{1}{2}+{\varepsilon}_1$ is greater than $ \frac{1}{2}$
	and ${\varepsilon}_2$ comes from Lemma 	\ref{LEM:timedecay}.		
	Therefore, in proving local well-posedness via the fixed point argument, we require 
	\begin{equation}
		\label{localtime} {\delta}^{\frac{1}{2}-{\varepsilon}_1-{\varepsilon}_2} \| u \|_{X^{0, \frac{1}{2}+, {\delta}}}^2 \lesssim 1 
	\end{equation}
	
	{
\noindent} on the ball $\{ u: \| u \|_{X^{0, \frac{1}{2}+, {\delta}}} \leq 2C_0\|u_0\|_{L^2}\}$. Hence, we can choose ${\delta} \sim \|u_0\|_{L^2}^{-(4+\theta)}$ with $\theta = 0+$.
	
	Let $T>0$ and ${\varepsilon}>0$ be given, and we continue the argument from Subsection \ref{SUBSEC:1GWP}. First, in view of the large deviation estimate \eqref{largedevi}, choose $K \sim \big(\log \frac{1}{\varepsilon}\big)^\frac{1}{2}$ so that $\mathbb{P} ( \| u_0(\omega)\|_{H^s} \geq K ) \leq \frac{1}{2}{\varepsilon}.$ In the following, we assume $\| u_0\|_{H^s} \leq K$.
	Now, fix ${\delta} \sim N^{(4+\theta)s} K^{-(4+\theta)}$ with $\theta = 0+$.
For fixed ${\alpha} \leq \frac{1}{2}$,  $ s= {\alpha} - \frac{1}{2}- < 0$ is also fixed.
Hence, we can write
\begin{equation}
	\label{DL} {\delta} \sim N^{4s - } K^{-4-}, 
\end{equation}
	
	\smallskip
	
	Before proceeding further, we present an important proposition whose proof is given in the remaining part of the paper. 
	\begin{proposition}
		\label{PROP:HNLS} Let $ s= {\alpha} - \frac{1}{2}-$ with ${\alpha} \in ( \frac{5}{12}, \frac{1}{2}]$. Given $T> 0$ and $K> 0$, there exists $N$ sufficiently large with ${\delta} \sim N^{4s-} K^{-4-}$ such that the following holds. Suppose that 
		\begin{equation}
			\label{ujbound} \|u^j(t)\|_{X^{0, \frac{1}{2}+}[(j-1){\delta}, j{\delta}]} \leq C N^{-s}K 
		\end{equation}
		
		{
\noindent} such that ${\delta}^{\frac{1}{2}-}\|u^j(t)\|_{X^{0, \frac{1}{2}+}[(j-1){\delta}, j{\delta}]}^2 \lesssim 1$ (see \eqref{localtime}) for $j = 1, \cdots, [\frac{T}{\delta}]$. Write the solution $v^j$ of the following difference equation: 
		\begin{equation}
			\label{HNLSj} 
			\begin{cases}
				i {
\partial_t} v^j - {
\partial_x}^2 v^j \pm (\mathcal{N} (u^j + v^j) - \mathcal{N}(u^j)) = 0 \\
				v^j|_{t= (j-1){\delta}} = \psi_{j-1} := \sum_{|n|> N} \frac{g_n(\omega)e^{i (j - 1) {\delta} n^2}}{\sqrt{1+|n|^{2{\alpha}}}} e^{inx} 
			\end{cases}
		\end{equation}
		
		{
\noindent} as $v^j (t) = S(t-(j-1){\delta})\psi_{j-1} + w^j(t)$. Then, \eqref{HNLSj} is locally well-posed on the time interval $[(j-1) {\delta}, j{\delta}]$ except on a set of measure $e^{-\frac{1}{{\delta}^c}}$ for each $j = 1, \cdots, [\frac{T}{\delta}]$. Moreover, we have the following bound on the nonlinear terms: 
		\begin{equation}
			\label{wjbound} \sum_{j = 1}^{[T/{\delta}]} \|w^j(j{\delta})\|_{L^2} \lesssim N^{-s}K. 
		\end{equation}
	\end{proposition}

\begin{remark} \rm
In Proposition \ref{PROP:HNLS}, we do not assume that $u^j$ is deterministic.
In our application, $u^j$ is indeed random -- not even independent from $\psi^{j-1}$ and $v^j$.
\end{remark}
	
	Now, we continue the proof of Proposition \ref{THM:GWP2}. Our choice of ${\delta}$ guarantees that \eqref{LNLS1} is well-posed on $[0, {\delta}]$ with the bound \eqref{u1bound}. Then, by Proposition \ref{PROP:HNLS}, \eqref{HNLS1} is well-posed on $[0, {\delta}]$ except on a set of measure $e^{-\frac{1}{{\delta}^c}}$ with the bound \eqref{w1bound}, which in turn shows that \eqref{LNLS2} is well-posed on $[{\delta}, 2{\delta}]$ with the bound \eqref{u2bound}. 
	
	Write the solution $v^2$ of \eqref{HNLS2} as $v^2 (t) = S(t-{\delta})\psi_1 + w^2(t)$. It follows from \eqref{u2bound} and Proposition \ref{PROP:HNLS} that \eqref{HNLS2} is well-posed on the time interval $[{\delta}, 2{\delta}]$ except on a set of measure $e^{-\frac{1}{{\delta}^c}}$. Moreover, we have 
	\begin{equation}
		\label{w2bound} \sum_{j = 1}^2 \|w^j(j{\delta})\|_{L^2} \lesssim N^{-s}K. 
	\end{equation}
	
	At time $t = 2{\delta}$, write $u (2{\delta}) = \phi_2 + \psi_2$, where $\phi_2 := u^2(2{\delta}) + w^2(2{\delta})$ and $\psi_2 := S({\delta}) \psi_1 = S(2{\delta}) \psi_0$. Then, \eqref{w2bound} guarantees that the solution $u^3$ to 
	\begin{equation}
		\label{LNLSj} 
		\begin{cases}
			i {
\partial_t} u^j - {
\partial_x}^2 u^j \pm \mathcal{N}(u^j) = 0 \\
			u^j|_{t= (j-1) {\delta}} = \phi_{j-1} 
		\end{cases}
	\end{equation}
	
	{
\noindent} with $j = 3$ satisfies 
	\begin{equation}
		\label{u3bound} \| u^3 \|_{X^{0, \frac{1}{2}+}[2{\delta}, 3{\delta}]} \leq \| \phi_0 \|_{L^2} + \sum_{j = 1}^2 \|w^j(j{\delta})\|_{L^2} \lesssim N^{-s}K. 
	\end{equation}
	
	Clearly, we can iterate this argument to show that \eqref{NLS2} is well-posed on $[0, T]$, assuming \eqref{wjbound}. Lastly, note that the measure of the exceptional sets can be estimated by 
	\begin{align*}
		\Big[\frac{T}{\delta}\Big] e^{-\frac{1}{{\delta}^c}} \leq e^{\ln \frac{T}{\delta} -\frac{1}{{\delta}^c}} \leq e^{ -\frac{1}{2}\frac{1}{{\delta}^c}} < \frac{1}{2}{\varepsilon} 
	\end{align*}
	
	{
\noindent} for sufficiently small ${\delta} >0$, i.e. for sufficiently large $N = N(T, {\varepsilon})$. This completes the proof of Proposition \ref{THM:GWP2}. 
\end{proof}

\subsection{Basic Setup} \label{SUBSEC:GWP2}

In the remaining part of the paper, we prove Proposition \ref{PROP:HNLS}. In the following, fix $T> 0 $ and $K > 0$, and let $ s= {\alpha} - \frac{1}{2}-$ and \eqref{DL}:
\begin{equation*}
	{\delta} \sim N^{4s-} K^{-4-}, 
\end{equation*}

{
\noindent} where $N = N(T, K)$ to be determined later.

First, consider the following difference equation: 
\begin{equation}
	\label{HNLSjj} 
	\begin{cases}
		i {
\partial_t} v - {
\partial_x}^2 v \pm (\mathcal{N} (u^0 + v) - \mathcal{N}(u^0)) = 0 \\
		v|_{t= 0} = \psi = \sum_{|n|> N} \frac{c_n g_n(\omega)}{\sqrt{1+|n|^{2{\alpha}}}} e^{inx} 
	\end{cases}
\end{equation}

{
\noindent} where $|c_n| = 1$ for all $n\in \mathbb{Z}$ and $u^0$ is a given function such that 
\begin{equation}
	\label{ujjbound} \|u^0(t)\|_{X^{0, \frac{1}{2}+, {\delta}}} \leq C N^{-s}K 
\end{equation}

{
\noindent} satisfying \eqref{localtime}. Let $w$ denote the nonlinear part of the solution $v$ of \eqref{HNLSjj}. i.e. it is given by 
\begin{equation}
	\label{wjj} w (t) := w(t; v, \psi, u^0) = \pm i \int_{0}^t S(t - t')\big(\mathcal{N} (u^0 + v) - \mathcal{N}(u^0)\big)(t') dt' 
\end{equation}

{
\noindent} for $ t \in [ 0, {\delta}]$. From the linear estimate \eqref{duhamel}, 
we have 
\begin{equation} \label{duhamel2}
\|w({\delta})\|_{L^2} \lesssim \|\eta_{_{\delta}}(t) w\|_{X^{0, \frac{1}{2}+{\varepsilon}_1, {\delta}}}
\lesssim \| \mathcal{N} ({\widetilde}{u^0} + {\widetilde}{v}) - \mathcal{N}({\widetilde}{u^0})\|_{X^{0, -\frac{1}{2}+{\varepsilon}_1}},
\end{equation}

{
\noindent}
for some small ${\varepsilon}_1>0$, where ${\widetilde}{u^0}$ and $ {\widetilde}{v}$ are extensions of $u^0$ and $v$, respectively.

{\it Suppose} that we have 
\begin{equation}
	\label{size1} \| \mathcal{N} ({\widetilde}{u^0} + {\widetilde}{v}) - \mathcal{N}({\widetilde}{u^0})\|_{X^{0, -\frac{1}{2}+}} \lesssim N^{3s - {\gamma}} 
\end{equation}

{
\noindent} with some small ${\gamma} >0$ except on a set of measure $e^{-\frac{1}{{\delta}^c}}$
(for any extensions ${\widetilde}{u^0}$ and $ {\widetilde}{v}$  of $u^0$ and $v$.) 
Then, it follows that the mapping ${\Gamma}$ defined by 
\begin{equation}
	\label{GNLS} {\Gamma} v(t) := S(t) \psi +w(t; v, \psi, u^0) 
\end{equation}

{
\noindent} is a contraction on $S(t) \psi^\omega + B$ on the time interval $[0, {\delta}]$ except on a set of measure $e^{-\frac{1}{{\delta}^c}}$, where $B$ denotes the ball of radius $\sim N^{3s-{\gamma} }$ in $X^{0, \frac{1}{2}+}_{[0,  {\delta}]}$. Moreover, from \eqref{DL}, \eqref{duhamel2},  and \eqref{size1}, we have 
\begin{align}
	\label{wjjbound} \frac{T}{\delta} \|w({\delta})\|_{L^2} \lesssim T {\delta}^{-1} N^{3s-{\gamma}} \lesssim T K^{4+} N^{-s}N^{ -{\gamma}+ } \lesssim N^{-s}K 
\end{align}

{
\noindent} for sufficiently large $N = N(T, K)$. Note that \eqref{duhamel2} and \eqref{size1} imply only the boundedness of the map ${\Gamma}$ from $S(t) \psi^\omega + B$ into itself. In establishing the contraction property, 
one needs to consider the difference ${\Gamma} v_1 - {\Gamma} v_2$ for $v_1, v_2 \in S(t) \psi^\omega + B$.
We omit details.

Finally, note that the bound \eqref{ujbound} on $u^j$ is uniform in $j$ in Proposition \ref{PROP:HNLS}. 
Hence, the above local well-posedness result can be applied to \eqref{HNLSj} on $[(j - 1){\delta}, j{\delta}]$ for $j = 1, \cdots, [\frac{T}{\delta}]$, and moreover \eqref{wjbound} follows from \eqref{wjjbound}. Therefore, it remains to prove \eqref{size1} for ${\alpha} \in ( \frac{5}{12}, \frac{1}{2}]$ (and for large $N$.)

\medskip

Note that  \eqref{size1} follows, once we prove 
\begin{equation}
	\label{size2} \| \mathcal{N}_j (u_1, u_2, u_3) \|_{X^{0, -\frac{1}{2}+{\varepsilon}_1}} \lesssim N^{3s - {\gamma}}, \ j = 1, 2, 
\end{equation}

{
\noindent} except on a set of measure $e^{-\frac{1}{{\delta}^c}}$, where 
${\mathcal{N}}_j$ is as in \eqref{NN1} or \eqref{NN2}, and $u_j$ is either of type 
\begin{itemize}
	\item[(I)] linear part: random, less regular
	\[u_j (x, t) = S(t) \psi= \sum_{|n| > N } \frac{c_n g_n(\omega)}{\sqrt{1+|n|^{2{\alpha}}}} e^{i(nx + n^2t)} \text{ with } |c_n| = 1, \text{ or }\]
	\item[(II)] smoother:
	\begin{itemize}
	\item[(II.a)] ``high frequency'' nonlinear part: small
	\begin{equation}
			\label{IIa} 
		\ u_j = {\widetilde}{w}, \text{ where ${\widetilde}{w}$ is an extension of $w$} \text{ with } 
		\|w \|_{X^{0, \frac{1}{2}+{\varepsilon}_1, {\delta}}} \lesssim N^{3s-{\gamma}},
	\end{equation}
	\item[(II.b)] ``low frequency'' input: large
	\begin{align} \label{IIb} 
			 u_j = {\widetilde}{u^0}, & \text{ where ${\widetilde}{u^0}$ is an extension of $u^0$}
			 \text{ with } \|u^0 \|_{X^{0, \frac{1}{2}+{\varepsilon}_1, {\delta}}} \lesssim N^{-s}K  \\ 
			 & 			 \text{ satisfying } \eqref{localtime}:{\delta}^{\frac{1}{2}-{\varepsilon}_1 -{\varepsilon}_2} 
			 \| u^0 \|_{X^{0, \frac{1}{2}+{\varepsilon}_1, {\delta}}}^2 \lesssim 1,  \notag 
	\end{align}
		\end{itemize}
\end{itemize}

{
\noindent} {\it except} for the case $u_j = u^0$ for all $j= 1, 2, 3$. We may insert the smooth cutoff function $\eta_{_{\delta}}$ supported on $[-2{\delta}, 2{\delta}]$ if necessary.

Note that $u^0$ has a much larger norm than $w$ since $s <0$. 
Thus, without loss of generality, 
we assume that $u_j = u^0$ if $u_j$ is of type (II), unless $u_j$ is of type (II) for {\it all} $j= 1, 2, 3$. In the latter case, we may assume that two of $u_j$'s are $u^0$ and the remaining $u_j$ is $w$., and it suffices to prove 
\begin{equation}
	\label{size3} \| \mathcal{N}_j (u^0, u^0, w) \|_{X^{0, -\frac{1}{2}+{\varepsilon}_1}} \lesssim N^{3s - {\gamma}}, \ j = 1, 2, 
\end{equation}

{
\noindent} {\it assuming}  \eqref{localtime}. In the following subsections, we prove \eqref{size2} by separately estimating the contributions from $\mathcal{N}_1$ and $\mathcal{N}_2$. 
Indeed, except for Case (A) in Subsection \ref{SUBSEC:GWP4}
(namely with $u^0$, $u^0$, and $w$),
we can prove \eqref{size2} with $N^{3s-{\gamma}-}$ instead of $N^{3s - {\gamma}}$.

In the following,  we write estimates 
directly with 
$\|u_j\|_{X^{s, b, {\delta}}}$  for simplicity of presentation,
meaning that the same estimates hold with $\|{\widetilde}{u}_j\|_{X^{s, b}}$ 
for any extension ${\widetilde}{u}_j$ of $u_j$
(and thus we can take the infimum over ${\widetilde}{u}_j$.)
See Remark \ref{REM:local}.

\subsection{Estimate on $\mathcal{N}_2$} \label{SUBSEC:GWP3}

In this subsection, we prove the estimate \eqref{size2} for $\mathcal{N}_2 (u_1, u_2, u_3)$ defined in \eqref{NN2}. 
We need to estimate
\begin{align}
	\label{easy1b}
	\| \mathcal{N}_2 (u_1, u_2, u_3 & ) \|_{X^{0, -\frac{1}{2}+}} 
	= \bigg\| \frac{1}{{\langle {\tau - n^2} \rangle}^{\frac{1}{2}-}} \operatorname*{\int}_{\tau = \tau_1 - \tau_2 + \tau_3} {\widehat}{u}_1(n, \tau_1){\overline}{{\widehat}{u}_2(n, \tau_2)}{\widehat}{u}_3(n, \tau_3) d\tau_1 d\tau_2 \bigg\|_{l^2_n L^2_\tau} \notag \\
	\intertext{By H\"older inequality with $p$ large ($\frac{1}{2} =\frac{1}{2+} + \frac{1}{p}$), } & \lesssim \sup_n \|{\langle {\tau - n^2} \rangle}^{-\frac{1}{2}+}\|_{L^{2+}_\tau} \Big\| \operatorname*{\int}_{\tau = \tau_1 - \tau_2 + \tau_3} {\widehat}{u}_1(n, \tau_1){\overline}{{\widehat}{u}_2(n, \tau_2)}{\widehat}{u}_3(n, \tau_3) d\tau_1 d\tau_2 \Big\|_{l^2_{n} L^p_\tau} . 
\end{align}

{
\noindent} In the following, we omit details if the computation is basically the same as in 
Subsection \ref{SUBSEC:LWP3}.
Recall ${\delta} \sim N^{4s-}K^{-4-}$
from \eqref{DL}.
We assume that $N$ is sufficiently large in the following.

\medskip

{
\noindent} $\bullet$ {\bf Case (a):} $u_j$ of type (II), $j = 1, \dots, 3$.

In this case, we prove \eqref{size3}. By Young and H\"older inequalities in $\tau$, followed by H\"older in $n$, $l^2_n \subset l^6_n$, and Lemma \ref{LEM:timedecay}, we have 
\begin{align*}
	\eqref{easy1b} & \lesssim \prod_{j = 1}^3 \| {\langle {\tau - n^2} \rangle}^{\frac{1}{6}+} {\widehat}{u}_j (n, \tau) \|_{l^6_n L^2_\tau} \leq {\delta}^{1-} \| u^0 \|_{X^{0, \frac{1}{2}+, {\delta}}}^2 \| w \|_{X^{0, \frac{1}{2}+, {\delta}}} \\
	& \lesssim {\delta}^{\frac{1}{2}-} N^{3s - {\gamma} } \lesssim N^{3s-{\gamma}-} 
\end{align*}

{
\noindent} for $s \leq 0 $.

{
\noindent} $\bullet$ {\bf Case (b):} $u_j$ of type (I), $j = 1, \dots, 3$.

By Lemma \ref{LEM:prob1} and  Young's inequality, we have
\begin{align*}
	\eqref{easy1b} & \lesssim {\delta}^{1-} \|{\langle {n} \rangle}^{-3{\alpha}} |g_n (\omega)|^3 \|_{l^2_{|n| > N}} \lesssim {\delta}^{1 -\frac{3}{2}\beta-} \|{\langle {n} \rangle}^{-3{\alpha}+ 3{\varepsilon}} \|_{l^2_{|n| > N}} \\
	& \lesssim {\delta}^{1 -\frac{3}{2}\beta-} N^{-3{\alpha}+ \frac{1}{2}+ 3{\varepsilon}} \lesssim N^{3s-2{\alpha} + } K^{-4-} \lesssim N^{3s -{\gamma}-} 
\end{align*}

{
\noindent} for $ {\alpha} > \frac{1}{2}{\gamma} > 0$
outside an exceptional set of measure $< e^{-\frac{1}{{\delta}^{c}}}$.

{
\noindent} $\bullet$ {\bf Case (c):} Exactly two $u_j$'s of type (I). Say $u_1({\hspace{0.5mm}\text{I}\hspace{0.5mm}})$, $u_2({\hspace{0.5mm}\text{I}\hspace{0.5mm}})$, and $u_3({\text{I \hspace{-2.8mm} I} })$. 

By Young's inequality and Lemmata \ref{LEM:timedecay} and \ref{LEM:prob1}, we have 
\begin{align*}
	\eqref{easy1b} & \lesssim {\delta}^{\frac{1}{2}-} \big(\sup_{|n|>N} {\langle {n} \rangle}^{-2{\alpha}} |g_n|^2\big) \big\| {\widehat}{u^0} (n, \tau) \big\|_{l^2_n L^2_\tau} \lesssim {\delta}^{1 -\beta-} N^{-2{\alpha}+ 2{\varepsilon}}\|u^0 \|_{X^{0, \frac{1}{2}+, {\delta}}}\\
	&\lesssim N^{3s-2{\alpha} + } K^{-3-} \lesssim N^{3s -{\gamma}-} 
\end{align*}

{
\noindent} for $ {\alpha} > \frac{1}{2}{\gamma} > 0$ outside an exceptional set of measure $< e^{-\frac{1}{{\delta}^c}}$.

{
\noindent} $\bullet$ {\bf Case (d):} Exactly one $u_j$ of type (I). Say $u_1({\hspace{0.5mm}\text{I}\hspace{0.5mm}})$, $u_2({\text{I \hspace{-2.8mm} I} })$, and $u_3({\text{I \hspace{-2.8mm} I} })$.

By Young's inequality, followed by H\"older inequality in $n$ ($\frac{1}{2} = \frac{1}{4}+ \frac{1}{4}$) and in $\tau$ ($\frac{3}{4} = \frac{1}{2} + \frac{1}{4}$) and Lemmata \ref{LEM:timedecay} and \ref{LEM:prob1}, we have 
\begin{align*}
	\eqref{easy1b} & \lesssim {\delta}^{\frac{1}{2}-} \big(\sup_{|n| >N} {\langle {n} \rangle}^{-{\alpha}} |g_n|\big) \Big\| \big\| {\widehat}{u^0} (n, \tau)\big\|_{L^\frac{4}{3}_\tau}^2 \Big\|_{l^2_{n}}\\
	& \lesssim {\delta}^{\frac{1}{2}-\frac{\beta}{2} - } N^{-{\alpha}+{\varepsilon}} \sup_n \|{\langle {\tau- n^2} \rangle}^{-\frac{1}{4}-}\|^2_{L^4_\tau} \| {\langle {\tau- n^2} \rangle}^{\frac{1}{4}+} {\widehat}{u^0} (n, \tau) \|^2_{l^4_n L^2_\tau} \\
	& \lesssim {\delta}^{1-\frac{\beta}{2} - } N^{-{\alpha}+{\varepsilon}} \| {\langle {\tau- n^2} \rangle}^\frac{1}{2} {\widehat}{v}_j (n, \tau) \|_{l^4_n L^2_\tau}^2 \lesssim N^{2s-{\alpha}+}K^{-2-} \lesssim N^{3s -{\gamma}-} 
\end{align*}

{
\noindent} for ${\alpha} > \frac{1}{4} + \frac{1}{2}{\gamma} >\frac{1}{4}$ outside an exceptional set of measure $< e^{-\frac{1}{{\delta}^c}}$. 

\subsection{Estimate on $\mathcal{N}_1$: High Modulation Cases} \label{SUBSEC:GWP4}

In the next two subsections, we prove the main part of the estimate \eqref{size2}: 
\begin{equation}
	\label{trilinear3b} \| \mathcal{N}_1(u_1, u_2, u_3)\|_{X^{0, -\frac{1}{2}+{\varepsilon}_1, {\delta}}} \lesssim N^{3s -{\gamma}} 
\end{equation}

{
\noindent} for some small $ {\gamma} > 0$, 
where ${\mathcal{N}}_1$ is as in \eqref{NN1} and $u_j$ is of type (I) or (II). Once again, we omit details in the following when the computation basically follows from Subsection \ref{SUBSEC:LWP4}. 

Using duality, we can estimate \eqref{trilinear3b} by 
\begin{equation}
	\label{duality1b} \iint u^1 u^2 u^3 \cdot v \, dx dt 
\end{equation}

{
\noindent} where $\| v\|_{X^{0, \frac{1}{2}-{\varepsilon}_1, {\delta}}} \leq 1$ (with the complex conjugate on an appropriate $u^j$.)
We assume that $N$ is sufficiently large in the following.

\medskip

{
\noindent} $\bullet$ {\bf Case (A):} $u^1$ and $u^2$ are of type $({\text{I \hspace{-2.8mm} I} })$.

Suppose that $u^3$ is of type $({\text{I \hspace{-2.8mm} I} })$. In this case, we prove \eqref{size3} instead of \eqref{trilinear3b}. 
By Lemmata \ref{LEM:deterministic} (a) and \ref{LEM:timedecay} with \eqref{IIa} and \eqref{IIb}
(also see \eqref{localtime}), we have 
\begin{align*}
	\eqref{duality1b} 
	& \lesssim {\delta}^{\frac{1}{2}-{\varepsilon}_1-{\varepsilon}_2} \| u^0\|^2_{X^{0, \frac{1}{2}, {\delta}}} \| w\|_{X^{0, \frac{1}{2}, {\delta}}} 
	\| v\|_{X^{0, \frac{1}{2}-{\varepsilon}_1, {\delta}}}\\
	& \lesssim   \| w\|_{X^{0, \frac{1}{2}, {\delta}}} 
		\lesssim N^{3s-{\gamma}}. 
\end{align*}

Next, suppose that $u^3$ is of type $({\hspace{0.5mm}\text{I}\hspace{0.5mm}})$ i.e. $u^3 = S(t) u_0$.
In this case, we do not need to apply dyadic decomposition on $u^1$ and $u^2$.
Namely, for a fixed dyadic block $N^3$ for $u^3$ of type $({\hspace{0.5mm}\text{I}\hspace{0.5mm}})$, 
with a slight abuse of notation, 
we  use $u^1$ and $u^2$ to denote the sums of $u^j$ over the dyadic blocks $N^j \geq N^3$, $j = 1, 2$.

By Lemma \ref{LEM:deterministic} (b) with $p$ large followed by Lemma \ref{LEM:prob2}, we have 
\begin{align*}
			\eqref{duality1b} 
			\lesssim (N^3)^{\frac{1}{2}-{\alpha}+} \| u^0\|^2_{X^{0, \frac{1}{4}+, {\delta}}} \| v\|_{X^{0, \frac{1}{4}+, {\delta}}} 
\end{align*}

{
\noindent} outside an exceptional set of measure $< e^{-\frac{1}{{\delta}^c}}$. If ${\langle {\tau_j - n_j^2} \rangle}^{\frac{1}{4}-} \gtrsim (N^3)^{\frac{1}{2}-{\alpha}+} N^{-3s+{\gamma}+{\widetilde}{\varepsilon}}$ for $u_j$ of type $({\text{I \hspace{-2.8mm} I} })$, or if ${\langle {\tau - n^2} \rangle}^{\frac{1}{4}-} \gtrsim (N^3)^{\frac{1}{2}-{\alpha}+} N^{-3s+{\gamma}+{\widetilde}{\varepsilon}}$, then it follows 
from Lemma \ref{LEM:timedecay}, \eqref{DL}, and \eqref{IIb} that 
\begin{align*}
	\eqref{duality1b} \lesssim {\delta}^{\frac{1}{2}-} N^{-2s} K^2 N^{3s-{\gamma}-{\widetilde}{\varepsilon}} \lesssim N^{3s-{\gamma}-} 
\end{align*}

{
\noindent} for $N$ sufficiently large. Recall $N^3 > N$, $s = {\alpha} - \frac{1}{2}-$, and ${\gamma} = 0+$. 

Hence, it remains to estimate the contribution to \eqref{trilinear3b}
from the region satisfying
\begin{equation}
	\label{case0b} {\langle {\tau - n^2} \rangle} \ll (N^3)^{8-16{\alpha}+}, \text{ and } {\langle {\tau_j - n_j^2} \rangle} \ll (N^3)^{8-16{\alpha}+} \text{ if } u_j \text{ of type }({\text{I \hspace{-2.8mm} I} }) 
\end{equation}
in the following.

\medskip

{
\noindent} $\bullet$ {\bf Case (B):} $u^1$ of type $({\text{I \hspace{-2.8mm} I} })$, and $u^2$ of type $({\hspace{0.5mm}\text{I}\hspace{0.5mm}})$.

In this case, we do not need to apply dyadic decomposition on $u^1$.
Namely, for a fixed dyadic block $N^2$ for $u^2$ of type $({\hspace{0.5mm}\text{I}\hspace{0.5mm}})$, 
we use $u^1$ to denote the sum of $u^1$ over the dyadic blocks $N^1 \geq N^2$.

{
\noindent} $\circ$ Subcase (B.1): $u^3$ is of type $({\text{I \hspace{-2.8mm} I} })$. 
By Lemma \ref{LEM:deterministic} (b) with $p$ large followed by Lemma \ref{LEM:prob2}, we have 
\begin{align*}
	\eqref{duality1b} 
	\lesssim (N^2)^{\frac{1}{2}-{\alpha}+}\|u^0\|^2_{X^{0, \frac{1}{4}+, {\delta}}} \|v\|_{X^{0, \frac{1}{4}+, {\delta}}} 
\end{align*}

{
\noindent} outside an exceptional set of size $<e^{-\frac{1}{{\delta}^c}}$. If ${\langle {\tau_j - n_j^2} \rangle}^{\frac{1}{4}-} \gtrsim (N^2)^{\frac{1}{2}-{\alpha}+}N^{-3s+{\gamma}+}$ for $u_j$ of type $({\text{I \hspace{-2.8mm} I} })$, or if ${\langle {\tau - n^2} \rangle}^{\frac{1}{4}-} \gtrsim (N^2)^{\frac{1}{2}-{\alpha}+}N^{-3s+{\gamma}+}$, then \eqref{trilinear3b} follows as in Case (A). 

Hence, it remains to estimate the contribution to \eqref{trilinear3b}
from the region satisfying
\begin{equation}
	\label{caseAb} {\langle {\tau - n^2} \rangle} \ll (N^2)^{8-16{\alpha}+}, \text{ and } {\langle {\tau_j - n_j^2} \rangle} \ll (N^2)^{8-16{\alpha}+} \text{ if } u_j \text{ of type }({\text{I \hspace{-2.8mm} I} }). 
\end{equation}

{
\noindent} $\circ$ Subcase (B.2): $u^3$ is of type $({\hspace{0.5mm}\text{I}\hspace{0.5mm}})$. 
By Lemma \ref{LEM:deterministic} (b) with $p$ large followed by Lemma \ref{LEM:prob2}, we have 
\begin{align*}
	\eqref{duality1b} 
	\lesssim (N^2)^{1-2{\alpha}+}\|u^0\|_{X^{0, 0+, {\delta}}}\|v\|_{X^{0, 0+, {\delta}}} 
\end{align*}

{
\noindent} outside an exceptional set of measure $<e^{-\frac{1}{{\delta}^c}}$. If $({\sigma}^1)^{\frac{1}{2}-} \gtrsim (N^2)^{1-2{\alpha}+}N^{-2s+{\gamma}+}$ or if ${\langle {\tau - n^2} \rangle}^{\frac{1}{2}-} \gtrsim (N^2)^{1-2{\alpha}+}N^{-2s+{\gamma}+}$, 
then \eqref{trilinear3b} follows from Lemma \ref{LEM:timedecay}, \eqref{DL}, and \eqref{IIb}. 

Hence, it remains to estimate the contribution to \eqref{trilinear3b}
from the region satisfying
\begin{equation}
	\label{caseB2} {\langle {\tau - n^2} \rangle} \ll (N^2)^{4-8{\alpha}+}, \text{ and } {\langle {\tau_j - n_j^2} \rangle} \ll (N^2)^{4-8{\alpha}+} \text{ if } u_j \text{ of type }({\text{I \hspace{-2.8mm} I} }). 
\end{equation}

\medskip

{
\noindent} $\bullet$ {\bf Case (C):} $u^1$ of type $({\hspace{0.5mm}\text{I}\hspace{0.5mm}})$, and $u^2$, $u^3$ of type $({\text{I \hspace{-2.8mm} I} })$.

Dyadically decompose all the spatial frequencies. Suppose ${\langle {\tau - n^2} \rangle} \gg \max({\sigma}^2, {\sigma}^3)$. 
By Lemma \ref{LEM:deterministic} (c) with $p$ large, Lemmata \ref{LEM:prob2} and \ref{LEM:timedecay},
and \eqref{IIb}, we have 
\begin{align*}
	\eqref{duality1b}  
	 \lesssim (N^1)^{\frac{1}{2}-{\alpha}+}\|u^0\|_{X^{0, \frac{3}{8}, {\delta}}}^2\|v\|_{X^{0, 0+, {\delta}}} 
	\lesssim {\delta}^{\frac{1}{4}-} (N^1)^{\frac{1}{2}-{\alpha}+} N^{-2s}K^2 \|v\|_{X^{0, 0+}} 
\end{align*}

{
\noindent} outside an exceptional set of measure $<e^{-\frac{1}{{\delta}^c}}$. 
Hence, as before, \eqref{trilinear3b} follows as long as ${\langle {\tau - n^2} \rangle}^{\frac{1}{2}-} \gtrsim (N^1)^{ \frac{1}{2} - {\alpha}+}N^{-4s+{\gamma}+}$. Similar results hold if ${\sigma}^2 \gg \max({\sigma}^3, {\langle {\tau-n^2} \rangle})$ or ${\sigma}^3 \gtrsim \max({\sigma}^2, {\langle {\tau-n^2} \rangle})$. 

Hence, it remains to estimate the contribution to \eqref{trilinear3b}
from the region satisfying
\begin{equation}
	\label{caseBb} {\langle {\tau - n^2} \rangle} \ll (N^1)^{5 - 10{\alpha}+}, \text{ and } {\langle {\tau_j - n_j^2} \rangle} \ll (N^1)^{5 - 10{\alpha}+} \text{ if } u_j \text{ of type }({\text{I \hspace{-2.8mm} I} }). 
\end{equation}

\medskip

{
\noindent} $\bullet$ {\bf Case (D):} $u^1$ of type $({\hspace{0.5mm}\text{I}\hspace{0.5mm}})$, and either $u^2({\hspace{0.5mm}\text{I}\hspace{0.5mm}})$, $u^3({\text{I \hspace{-2.8mm} I} })$ or $u^2({\text{I \hspace{-2.8mm} I} })$, $u^3({\hspace{0.5mm}\text{I}\hspace{0.5mm}})$.

Suppose that $u^2$ is of type $({\hspace{0.5mm}\text{I}\hspace{0.5mm}})$ and that $u^3$ is of type $({\text{I \hspace{-2.8mm} I} })$. Moreover, suppose ${\langle {\tau - n^2} \rangle} \gg {\sigma}^3$. 
By Lemma \ref{LEM:deterministic} (c) with $p$ large, 
 Lemmata \ref{LEM:prob2} and \ref{LEM:timedecay}, and \eqref{IIb}, we have 
\begin{align*}
	\eqref{duality1b} 
	 \lesssim (N^1)^{1-2{\alpha}+}\|u^0\|_{X^{0, 0+}}\|v\|_{X^{0, 0}} 
	\lesssim {\delta}^{\frac{1}{2}-} (N^1)^{1-2{\alpha}+}N^{-s}K\|v\|_{X^{0, 0}} 
\end{align*}

{
\noindent} outside an exceptional set of measure $<e^{-\frac{1}{{\delta}^c}}$. Hence, \eqref{trilinear3b} follows as long as ${\langle {\tau - n^2} \rangle}^{\frac{1}{2}-} \gtrsim (N^1)^{1 - 2{\alpha}+}N^{-2s +{\gamma}+}$. Similar results hold if ${\sigma}^3 \gtrsim {\langle {\tau-n^2} \rangle}$, (or $u^2$ is of type $({\text{I \hspace{-2.8mm} I} })$ and $u^3$ is of type $({\hspace{0.5mm}\text{I}\hspace{0.5mm}})$.) 

Hence, it remains to estimate the contribution to \eqref{trilinear3b}
from the region satisfying
\begin{equation}
	\label{caseCb} {\langle {\tau - n^2} \rangle} \ll (N^1)^{4 - 8{\alpha}+}, \text{ and } {\langle {\tau_j - n_j^2} \rangle} \ll (N^1)^{4 - 8{\alpha}+} \text{ if } u_j \text{ of type }({\text{I \hspace{-2.8mm} I} }). 
\end{equation}

\medskip

{
\noindent} {\bf Summary:} 
By repeating the computation in Subsection \ref{SUBSEC:LWP4},
we can reduce the estimate into the following two cases (with $\theta = 0+$):.

\medskip

{
\noindent} $\bullet$ $u^1$ is of type $({\text{I \hspace{-2.8mm} I} })$: By \eqref{v1} and \eqref{v2}, we can bound \eqref{trilinear3b} as follows: 
\begin{align}
	\label{u2b} \eqref{trilinear3b} \lesssim {\delta}^\theta 
	M(N, N^2, N^3) \bigg( \sum_n \Big| \sum_{\substack{ n = n_1 - n_2 + n_3 \\
	n_2 \ne n_1, n_3\\
	n^2 = n_1^2 - n_2^2 + n_3^2 + \mu}} a_1(n_1){\overline}{a_2(n_2)}a_3(n_3) \Big|^2 \bigg)^\frac{1}{2}, 
\end{align}

{
\noindent} where $\sum_{n} |a^1(n)|^2 \leq 1$, $a^2(n) = \frac{g_{n}(\omega)}{1 + |n|^{\alpha}}$, $a^3(n) = \frac{g_{n}(\omega)}{1 + |n|^{\alpha}}$ or $\sum_{|n| \sim N^3} |a^3(n)|^2 \leq 1$, and 
\begin{tabbing}
	\hspace{1cm} \=Case (A): \hspace{1cm}\=$M(N, N^2, N^3) = (N^3)^{0+} N^{-2s} $ \=and \=$|\mu| \ll (N^3)^{8-16{\alpha}+}$ \\
	
	\>Subcase (B.1): \>$M(N, N^2, N^3) = (N^2)^{0+} N^{-2s}$ \>and \>$|\mu| \ll (N^2)^{8-16{\alpha}+}$ \\
	
	\>Subcase (B.2): \>$M(N, N^2, N^3) = (N^2)^{0+} N^{-s}$ \>and \>$|\mu| \ll (N^2)^{4-8{\alpha}+}$. 
\end{tabbing}
Note that we did not apply dyadic decomposition on $N^1$.

\medskip 

{
\noindent} $\bullet$ $u^1$ is of type $({\hspace{0.5mm}\text{I}\hspace{0.5mm}})$: By \eqref{v1} and \eqref{v2}, we can bound \eqref{trilinear3b} as follows: 
\begin{align}
	\label{u1b} \eqref{trilinear3b} \lesssim {\delta}^\theta (N^1)^{0+} M(N) \bigg( \sum_{|n| \lesssim N^1} \Big| \sum_{\substack{ n = n_1 - n_2 + n_3 \\
	n_2 \ne n_1, n_3\\
	n^2 = n_1^2 - n_2^2 + n_3^2 + \mu}} a_1(n_1){\overline}{a_2(n_2)}a_3(n_3) \Big|^2 \bigg)^\frac{1}{2}, 
\end{align}

{
\noindent} where $a^1(n) = \frac{g_{n}(\omega)}{1 + |n|^{\alpha}}$, $a^j(n) = \frac{g_{n}(\omega)}{1 + |n|^{\alpha}}$ or $\sum_{|n| \sim N^j} |a^j(n)|^2 \leq 1$ for $j = 2, 3$, and 
\begin{tabbing}
	\hspace{1cm} \=Case (C): \hspace{1cm}\=$M(N) = N^{-2s} $ \=and \=$|\mu| \ll (N^1)^{5-10{\alpha}+}$ \\
	
	\>Case (D): \>$M(N) = N^{-s}$ \>and \>$|\mu| \ll (N^1)^{4-8{\alpha}+}$\\
	
	\>All type ({\hspace{0.5mm}\text{I}\hspace{0.5mm}}): \>$M(N) = 1$ \>and \>$|\mu| \lesssim (N^1)^2$.
\end{tabbing}
Note that all the spatial frequencies are dyadically decomposed.

\medskip

By symmetry between $u_1$ and $u_3$, we assume $|n_1| \sim N^1$ or $|n_2| \sim N^1$ in the following. Moreover, in Subcase (B.2) and Case (D), we may assume that $|n_1| \sim N^1$. If not, say, we have $|n_2| > 10 (|n_1| + |n_3|)$. Then, $|\mu| \sim |(n_2 - n_1) (n_2 - n_3)| \sim |n_2|^2 \sim (N^1)^2$ by \eqref{ALGEBRA}. In these two cases, we have $|\mu| \ll (N^j)^{4- 8{\alpha}+} \ll (N^1)^2$ as long as ${\alpha} > \frac{1}{4}$. i.e. we would have a contradiction.

Lastly, we list all the different cases as before.
We consider these cases in details in the next subsection.

{
\noindent} $\bullet$ $n_1 = N^1$: 
\begin{tabbing}
	\hspace{7mm} \=Case (a): \= $n_1 = N^1({\text{I \hspace{-2.8mm} I} })$, \= $n_2 = N^2({\hspace{0.5mm}\text{I}\hspace{0.5mm}})$, \= $n_3 = N^3({\text{I \hspace{-2.8mm} I} })$ or \= $n_2 = N^3({\hspace{0.5mm}\text{I}\hspace{0.5mm}})$, \= $n_3 = N^2({\text{I \hspace{-2.8mm} I} })$ \\
	
	\>Case (b): \>$n_1 = N^1({\text{I \hspace{-2.8mm} I} })$, \>$n_2 = N^3({\text{I \hspace{-2.8mm} I} })$, \> $n_3 = N^2({\hspace{0.5mm}\text{I}\hspace{0.5mm}})$ or \>$n_2 = N^2({\text{I \hspace{-2.8mm} I} })$, \> $n_3 = N^3({\hspace{0.5mm}\text{I}\hspace{0.5mm}})$ \\
	
	\>Case (c): \> $n_1 = N^1({\hspace{0.5mm}\text{I}\hspace{0.5mm}})$, \>$n_2 = N^2({\text{I \hspace{-2.8mm} I} })$, \>$n_3 = N^3({\text{I \hspace{-2.8mm} I} })$ \\
	
	\>Case (d): \>$n_1 = N^1({\hspace{0.5mm}\text{I}\hspace{0.5mm}})$, \>$n_2 = N^3({\text{I \hspace{-2.8mm} I} })$, \>$n_3 = N^2({\text{I \hspace{-2.8mm} I} })$\\
	
	\>Case (e): \>$n_1 = N^1({\text{I \hspace{-2.8mm} I} })$, \>$n_2 = N^2({\hspace{0.5mm}\text{I}\hspace{0.5mm}})$, \>$n_3 = N^3({\hspace{0.5mm}\text{I}\hspace{0.5mm}})$\\
	
	\>Case (f): \>$n_1 = N^1({\text{I \hspace{-2.8mm} I} })$, \>$n_2 = N^3({\hspace{0.5mm}\text{I}\hspace{0.5mm}})$, \>$n_3 = N^2({\hspace{0.5mm}\text{I}\hspace{0.5mm}})$\\
	
	\>Case (g): \>$n_1 = N^1({\hspace{0.5mm}\text{I}\hspace{0.5mm}})$, \>$n_2 = N^2({\hspace{0.5mm}\text{I}\hspace{0.5mm}})$, \>$n_3 = N^3({\text{I \hspace{-2.8mm} I} })$\\
	
	\>Case (h): \>$n_1 = N^1({\hspace{0.5mm}\text{I}\hspace{0.5mm}})$, \>$n_2 = N^3({\hspace{0.5mm}\text{I}\hspace{0.5mm}})$, \>$n_3 = N^2({\text{I \hspace{-2.8mm} I} })$\\
	
	\>Case (i): \>$n_1 = N^1({\hspace{0.5mm}\text{I}\hspace{0.5mm}})$, \>$n_2 = N^2({\text{I \hspace{-2.8mm} I} })$, \>$n_3 = N^3({\hspace{0.5mm}\text{I}\hspace{0.5mm}})$\\
	
	\>Case (j): \>$n_1 = N^1({\hspace{0.5mm}\text{I}\hspace{0.5mm}})$, \>$n_2 = N^3({\text{I \hspace{-2.8mm} I} })$, \>$n_3 = N^2({\hspace{0.5mm}\text{I}\hspace{0.5mm}})$\\
	
	\>Case (k): \>All type ({\hspace{0.5mm}\text{I}\hspace{0.5mm}})\\
	
	
\end{tabbing}

{
\noindent} $\bullet$ $n_2 = N^1$: 
\begin{tabbing}
	\hspace{7mm} \=Case (a'): \= $n_2 = N^1({\text{I \hspace{-2.8mm} I} })$, \= $n_1 = N^2({\hspace{0.5mm}\text{I}\hspace{0.5mm}})$, \= $n_3 = N^3({\text{I \hspace{-2.8mm} I} })$ or \= $n_1 = N^3({\hspace{0.5mm}\text{I}\hspace{0.5mm}})$, \= $n_3 = N^2({\text{I \hspace{-2.8mm} I} })$ \\
	
	\>Case (b'): \>$n_2 = N^1({\text{I \hspace{-2.8mm} I} })$, \>$n_1 = N^3({\text{I \hspace{-2.8mm} I} })$, \> $n_3 = N^2({\hspace{0.5mm}\text{I}\hspace{0.5mm}})$ or \>$n_1 = N^2({\text{I \hspace{-2.8mm} I} })$, \> $n_3 = N^3({\hspace{0.5mm}\text{I}\hspace{0.5mm}})$ \\
	
	\>Case (c'): \> $n_2 = N^1({\hspace{0.5mm}\text{I}\hspace{0.5mm}})$, \>$n_1 = N^2({\text{I \hspace{-2.8mm} I} })$, \>$n_3 = N^3({\text{I \hspace{-2.8mm} I} })$ \\
	
	\>Case (d'): \>$n_2 = N^1({\hspace{0.5mm}\text{I}\hspace{0.5mm}})$, \>$n_1 = N^3({\text{I \hspace{-2.8mm} I} })$, \>$n_3 = N^2({\text{I \hspace{-2.8mm} I} })$\\
	
	\>Case (k'): \>All type ({\hspace{0.5mm}\text{I}\hspace{0.5mm}})
\end{tabbing}

\subsection{Estimate on $\mathcal{N}_1$: Low Modulation Cases} \label{SUBSEC:GWP5}

As before, we use $|n|^{\alpha} $ for $1+ |n|^{\alpha}$ and drop a complex conjugate on $u_2$ when it plays no significant role. 
Let $A_n$ and $B_n$ be as in Subsection \ref{SUBSEC:LWP4}.
Recall \[\mu = 2 (n_2 - n_1) (n_2 - n_3) = 2 (n - n_1) (n - n_3) \] 

{
\noindent}
from \eqref{ALGEBRA7}, $s = {\alpha} - \frac{1}{2}-$, and $N_j > N$ if $u_j$ is of type ({\hspace{0.5mm}\text{I}\hspace{0.5mm}}).

\medskip

{
\noindent} $\bullet$ {\bf Cases (k), (k'):} $u_1, u_2, u_3$ of type $({\hspace{0.5mm}\text{I}\hspace{0.5mm}})$. \ \ 
In this case, we have 
\begin{align}
	\label{casekb} \eqref{u1b} \lesssim {\delta}^{\theta} (N^1)^{0+} \bigg( \sum_{|n| \lesssim N^1} \Big|\sum_{B_n} \frac{g_{n_1}}{|n_1|^{\alpha}} \frac{{\overline}{g_{n_2}}}{|n_2|^{\alpha}} \frac{g_{n_3}}{|n_3|^{\alpha}} \Big|^2 \bigg)^\frac{1}{2}. 
\end{align}

{
\noindent}
Note that we have $N_1, N_2, N_3 > N$.
First, we consider the contribution from $n_1 \ne n_3$. 
As in Subsection \ref{SUBSEC:LWP4}, 
by \eqref{chaosestimate} and Lemma \ref{LEM:count1}, we have 
\begin{align*}
	\text{RHS of } \eqref{casekb} & \lesssim {\delta}^{\theta-\frac{3}{2}\beta} (N^1)^{\frac{3}{2}{\varepsilon}+} \bigg( \sum_{|n| \lesssim N^1} \sum_{C_n} \frac{1}{|n_1|^{2{\alpha}}|n_2|^{2{\alpha}}|n_3|^{2{\alpha}}} \bigg)^\frac{1}{2}\\
	& \lesssim {\delta}^{\theta-\frac{3}{2}\beta} (N^1)^{-{\alpha} +\frac{3}{2}{\varepsilon}+} (N^2)^{-{\alpha}} (N^3)^{-{\alpha}+\frac{1}{2}} \lesssim N^{ - 3{\alpha} + \frac{1}{2} +} \leq N^{3s -{\gamma}-}\prod_{j = 1}^3 N_j^{0-} 
\end{align*}

{
\noindent} for ${\alpha} > \frac{1}{3} + \frac{1}{6}{\gamma}> \frac{1}{3}$ and sufficiently large $N$ outside an exceptional set of measure
$< (N^1)^{0-} e^{-\frac{1}{{\delta}^{c}}}$ as in \eqref{EXCEPT1}.

The contribution from $n_1 = n_3$  follows 
as in \eqref{ZK}.
By Lemmata \ref{LEM:count1} and \ref{LEM:prob1}, we have 
\begin{align*}
	\text{RHS of } \eqref{casekb} & \lesssim {\delta}^{\theta-\frac{3}{2}\beta} (N^1)^{0+}N_1^{-2{\alpha} + 2{\varepsilon}} N_2^{-{\alpha} + {\varepsilon}}(N^3)^\frac{1}{2} \leq N^{3s-{\gamma}-}\prod_{j = 1}^3 N_j^{0-} 
\end{align*}

{
\noindent} for ${\alpha} > \frac{1}{3} + \frac{1}{6}{\gamma}> \frac{1}{3}$ and sufficiently large $N$ outside an exceptional set of measure $< e^{-\frac{1}{{\delta}^c}}$. \medskip

{
\noindent} $\bullet$ {\bf Case (a) :} (Cases (b), (a'), and (b') can be treated in a similar way by replacing $n_2$ with $n_3$, $n_2$ with $n_1$, and $(n_1, n_2, n_3)$ with $(n_2, n_3, n_1),$ respectively.)

In this case, we have $\mu = 2 (n_2 - n_1) (n_2 - n_3) = o( (N_2)^{8-16{\alpha}+})$.
Thus, by Lemma \ref{LEM:prob1}, Cauchy-Schwarz inequality, and \eqref{A1} as before, we have 
\begin{align*}
	\eqref{u2b} & 
	\lesssim {\delta}^{\theta-\frac{\beta}{2}} (N_2)^{-{\alpha} + \frac{1}{2}{\varepsilon} +} N^{-2s} 
	\bigg( \sum_n  \Big(\sum_{A_n}|a_1(n_1)|^2|a_3(n_3)|^2\Big)
	 \Big(\sum_{A_n}1\Big)\bigg)^\frac{1}{2} \notag \\
		& \lesssim {\delta}^{\theta-\frac{\beta}{2}} N_2^{-{\alpha}+{\varepsilon}+} N^{-2s}
	\Big( \sum_n  \sum_{A_n}|a_1(n_1)|^2|a_3(n_3)|^2
	 \Big)^\frac{1}{2} \notag \\
		& \lesssim {\delta}^{\theta-\frac{\beta}{2}} N_2^{-{\alpha}+{\varepsilon}+} N^{-2s}
		\leq N^{3s-{\gamma}-} N_2^{0-} N_3^{0-} 
\end{align*}

{
\noindent} 
for ${\alpha} > \frac{5}{12}+\frac{1}{6}{\gamma} > \frac{5}{12}$
and sufficiently large $N$
outside an exceptional set of measure $< e^{-\frac{1}{{\delta}^c}}$.

\medskip

{
\noindent} $\bullet$ {\bf Case (c):} (Case (d) can be treated in a similar way by replacing $n_2$ and $n_3$.)

 By Lemma \ref{LEM:prob1} and H\"older inequality on $n_3$ in the inner sum, 
\begin{align*}
	\eqref{u1b} \lesssim {\delta}^{\theta-\frac{\beta}{2}} N_1^{ -{\alpha} +{\varepsilon}+} N^{-2s} 
	 \Big( \sum_{|n| \lesssim N^1} \sum_{B_n} |a_2(n_2)|^2 \Big)^\frac{1}{2} 
\end{align*}

{
\noindent} outside an exceptional set of measure $< e^{-\frac{1}{{\delta}^c}}$. 
For fixed $n_2$, it follows from (the proof of) Lemma \ref{LEM:count1} that there are at most $N_1^{0+}$ terms in the sum. 
Hence, we have 
\begin{align*}
	\eqref{u1b} \lesssim {\delta}^{\theta-\frac{\beta}{2}} N_1^{ -{\alpha} +{\varepsilon}+} 
	N^{-2s}  \leq N^{3s-{\gamma} -} \prod_{j = 1}^3 N_j^{0-}
\end{align*}

{
\noindent} 
for ${\alpha} > \frac{5}{12}+\frac{1}{6}{\gamma} > \frac{5}{12}$
 and sufficiently large $N$.

\medskip

{
\noindent} $\bullet$ {\bf Case (e) :} (Case (f) is basically the same.)

In this case, we have $ |\mu| = |2 (n_2 - n_1) (n_2 - n_3)| \ll  N_2^{4-8{\alpha}+} $. 
This implies that $|n|, |n_1|, |n_3| \lesssim N_2^q$
for some $q> 0$ since $n_2 \ne n_1, n_3$.
Then, by Lemma \ref{LEM:prob1}, Cauchy-Schwarz inequality, and \eqref{A1} as before, 
we have
\begin{align*}
	\eqref{u2b} 
& \lesssim {\delta}^{\theta-\beta} 
	N_2^{-{\alpha}+{\varepsilon}+} N_3^{-{\alpha}} N^{-s}\bigg( \sum_{|n| \lesssim N_2^q} 
	\Big(\sum_{A_n} |a_1(n_1)|^2\Big) \Big(\sum_{A_n} 1\Big) \bigg)^\frac{1}{2} \\
& \lesssim {\delta}^{\theta-\beta} 
	N_2^{-{\alpha}+\frac{3}{2}{\varepsilon}+} N_3^{-{\alpha}} N^{-s}\Big( \sum_{|n| \lesssim N_2^q} \sum_{A_n} |a_1(n_1)|^2 \Big)^\frac{1}{2} \\
& \lesssim {\delta}^{\theta-\beta} N_2^{-{\alpha}+2{\varepsilon}+} N_3^{ -{\alpha}} N^{-s}
\leq N^{3s-{\gamma}-}N_2^{0-} N_3^{0-} 
\end{align*}

{
\noindent} for $ {\alpha} > \frac{1}{3} + \frac{1}{6}{\gamma}>\frac{1}{3}$ and sufficiently large $N$ outside an exceptional set of measure
$<e^{-\frac{1}{{\delta}^c}}$.

\medskip

{
\noindent} $\bullet$ {\bf Case (g) :} (Cases (h), (i), (j) are basically the same.)

By Lemma \ref{LEM:prob1} and Cauchy-Schwarz inequality as before,  we have
\begin{align*}
	\eqref{u1b} 
& \lesssim {\delta}^{\theta-\beta} 
	N_1^{-{\alpha}+{\varepsilon}+} N_2^{-{\alpha}+ \frac{1}{2}{\varepsilon}} N^{-s}\Big( \sum_{|n| \lesssim N_1} 
	\sum_{A_n} |a_3(n_3)|^2\Big)^\frac{1}{2} \\
& \lesssim {\delta}^{\theta-\beta} 
	N_1^{-{\alpha}+\frac{3}{2}{\varepsilon}+} N_2^{-{\alpha}+ \frac{1}{2}{\varepsilon}} N^{-s}
 \leq N^{3s-{\gamma}-}\prod_{j = 1}^3 N_j^{0-} 
\end{align*}

{
\noindent} for $ {\alpha} > \frac{1}{3} + \frac{1}{6}{\gamma}>\frac{1}{3}$ and sufficiently large $N$ outside an exceptional set of measure
$<e^{-\frac{1}{{\delta}^c}}$.

\begin{remark} \rm
It is worthwhile to note that 
the worst case occurs:
\begin{itemize}
\item for all type (I) in the local theory.
\item for one (I) and two (II.b) in the global theory.
\end{itemize}

{
\noindent}
These cases yield the conditions on the values of ${\alpha}$ in Theorems \ref{THM:LWP} and \ref{THM:GWP1}.

\end{remark}

\medskip

\noindent {\bf Acknowledgments:} The authors would like to thank Prof.~Kenji Nakanishi for the conversation at Institut Henri Poincar\'e. 
They are also grateful to Prof.~Nicolas Burq for remarks on a preliminary draft.
Lastly, they would like to express their gratitude to the anonymous referees for thoughtful
comments that have improved this paper. 

	
	
	\bibliographystyle{plain}
	
	
	\begin{thebibliography}{99}

	\bibitem{Benyi:2010p842}
	B{\'e}nyi, {\'A}.;  Oh, T.
	\newblock {\it Modulation spaces, Wiener amalgam spaces, and Brownian motions,}
	\newblock to appear in Adv. Math. 

	
	\bibitem{Bourgain:1993p453}
	Bourgain, J.
	\newblock 
	{\it Fourier transform restriction phenomena for certain lattice subsets and applications 
	to nonlinear evolution equations. I. Schr\"odinger equations,}  
		\newblock Geom. Funct. Anal.  3  (1993),  no. 2, 107--156.

\bibitem{Bourgain:1994p435}
	Bourgain, J.
	\newblock {\it Periodic nonlinear Schr{\"o}dinger equation and invariant measures,}
	\newblock  Comm. Math. Phys.  166  (1994),  no. 1, 1--26.

	\bibitem{Bourgain:1994p540}
	Bourgain, J.
	\newblock {\it On the Cauchy and invariant measure problem for the periodic Zakharov system,}
	\newblock Duke Math. J.  76  (1994),  no. 1, 175--202.

  

	\bibitem{Bourgain:1996p446}
	Bourgain, J.
	\newblock {\it Invariant measures for the 2 $D$-defocusing nonlinear Schr\"odinger equation,}
	\newblock   Comm. Math. Phys.  176  (1996),  no. 2, 421--445.

	\bibitem{Bourgain:1998p434}
	Bourgain, J.
	\newblock {\it Refinements of Strichartz' inequality and applications to 2$D$-NLS with critical nonlinearity,}
	\newblock Internat. Math. Res. Notices 1998, no. 5, 253--283. 

\bibitem{BOPCMI}
	Bourgain, J.
	\newblock {\it Nonlinear Schr\"odinger equations,}
	\newblock  Hyperbolic equations and frequency interactions (Park City, UT, 1995),  3--157, 
	IAS/Park City Math. Ser., 5, Amer. Math. Soc., Providence, RI, 1999. 
	
	\bibitem{Burq:2002p911}
Burq, N.; G\'erard, P.; Tzvetkov, N.
	\newblock {\it An instability property of the nonlinear Schr\"odinger equation on $S^d$,}
	\newblock    Math. Res. Lett.  9  (2002),  no. 2-3, 323--335. 

	\bibitem{Burq:2007p1542}
Burq, N.; Tzvetkov, N.
	\newblock {\it Invariant measure for a three dimensional nonlinear wave equation,}
	\newblock Int. Math. Res. Not. IMRN  2007,  no. 22, Art. ID rnm108, 26 pp. 

	\bibitem{Burq:2008p624}
Burq, N.; Tzvetkov, N.
	\newblock {\it Random data Cauchy theory for supercritical wave equations. I. Local theory, }
	 \newblock  Invent. Math.  173  (2008),  no. 3, 449--475.

	\bibitem{Burq:2008p623}
	Burq, N.;  Tzvetkov, N.
	\newblock {\it Random data Cauchy theory for supercritical wave equations. II. A global existence result,}
	 \newblock  Invent. Math.  173  (2008),  no. 3, 477--496.

	\bibitem{Christ:2007p1011}
	Christ, M.
	\newblock {\it Power series solution of a nonlinear Schr\"odinger equation,}
	\newblock   Mathematical aspects of nonlinear dispersive equations,  131--155,
Ann. of Math. Stud., 163, Princeton Univ. Press, Princeton, NJ, 2007. 

	\bibitem{Christ:2003p1180}
	Christ, M.; Colliander, J.; Tao, T.
	\newblock {Instability of the periodic nonlinear Schr\"odinger equation,}
	\newblock arXiv:math/0311227v1 [math.AP].
	
	\bibitem{Christ:2003p838}
	Christ, M.; Colliander, J.; Tao, T.
	\newblock {\it Asymptotics, frequency modulation, and low regularity ill-posedness for canonical defocusing equations,}
	\newblock Amer. J. Math.  125  (2003),  no. 6, 1235--1293. 

	\bibitem{Ginibre:1997p1264}
	Ginibre, J.; Tsutsumi, Y.; Velo, G.
	\newblock {\it On the Cauchy problem for the Zakharov system,}
	\newblock J. Funct. Anal.  151  (1997),  no. 2, 384--436.

 

	\bibitem{Grunrock:2008p659}
	Gr{\"u}nrock, A.; Herr, S.
	\newblock {\it Low regularity local well-posedness of the derivative nonlinear Schr\"odinger equation with periodic initial data,}
	\newblock SIAM J. Math. Anal. 39 (2008), no. 6, 1890--1920. 
  

\bibitem{HW}
Hardy, G. H.; Wright, E. M. 
	\newblock {\it An introduction to the theory of numbers,} Fifth edition.
	\newblock The Clarendon Press, Oxford University Press, New York, 1979. xvi+426 pp. 

\bibitem{Janson} Janson, S. 
\newblock {\it Gaussian Hilbert Spaces,}
\newblock Cambridge Tracts in Mathematics, 129. Cambridge University Press,
Cambridge, 1997. x+340 pp.

	\bibitem{Kenig:2001p1478}
	Kenig, C.; Ponce, G.; Vega, L.
	\newblock {\it On the ill-posedness of some canonical dispersive equations,}
	\newblock  Duke Math. J.  106  (2001),  no. 3, 617--633.

	\bibitem{Klainerman:2002p743}
	Klainerman, S.;  Selberg, S.
	\newblock {\it Bilinear estimates and applications to nonlinear wave equations,}
	\newblock  Commun. Contemp. Math.  4  (2002),  no. 2, 223--295. 

	\bibitem{Koch:2007p782}
	Koch, H.; Tataru, D.
	\newblock {\it A priori bounds for the 1D cubic NLS in negative Sobolev spaces,}
	\newblock Int. Math. Res. Not. IMRN 2007, no. 16, Art. ID rnm053, 36 pp. 

  

	\bibitem{Kuo:1975p724}
	Kuo, H. 
	\newblock {\it Gaussian measures in Banach spaces,}
	\newblock Lecture Notes in Mathematics, Vol. 463. Springer-Verlag, Berlin-New York, 1975. vi+224 pp.

	\bibitem{Lebowitz:1988p737}
	Lebowitz, J.L.; Rose, H.A.; Speer, E.R.
	\newblock {\it Statistical mechanics of the nonlinear Schr\"odinger equation,}
	\newblock J. Statist. Phys.  50  (1988),  no. 3-4, 657--687. 

\bibitem{Ledoux} Ledoux, M.; Talagrand, M.
\newblock {\it Probability in Banach spaces. Isoperimetry and Processes,}
\newblock Ergebnisse der Mathematik und ihrer Grenzgebiete (3) [Results in
Mathematics and Related Areas (3)], 23. Springer-Verlag, Berlin,
1991. xii+480 pp.

	\bibitem{Molinet:2009p365}
	Molinet, L.
	\newblock {\it On ill-posedness for the one-dimensional periodic cubic Schr\"odinger equation,}
	 \newblock Math. Res. Lett.  16  (2009),  no. 1, 111--120. 

	
	
	\bibitem{Oh:2009p791}
	Oh, T.
	\newblock {\it Invariant Gibbs measures and a.s. global well posedness for coupled KdV systems,}
	\newblock  Differential Integral Equations  22  (2009),  no. 7--8, 637--668.

\bibitem{OhSBO}
	Oh, T.
	\newblock {\it Invariance of the Gibbs measure for the Schrödinger-Benjamin-Ono system,}
	\newblock SIAM J. Math. Anal.  41  (2009/10),  no. 6, 2207--2225.

\bibitem{Oh:2009p792}
	Oh, T.
	\newblock {\it Invariance of the white noise for KdV,}  
	\newblock Comm. Math. Phys.  292  (2009),  no. 1, 217--236.
  Also, see {\it Erratum: ``Invariance of the white noise for KdV''}, in preparation.

\bibitem{Oh:2009p1296}
	Oh, T.
	\newblock {\it White noise for KdV and mKdV on the circle,}
	\newblock 	RIMS K\^oky\^uroku Bessatsu B18 (2010), 99--124.

\bibitem{OhFE}
Oh, T. 
\newblock {\it Remarks on nonlinear smoothing under randomization for the periodic KdV and the cubic Szeg\"o equation,}
\newblock 	to appear in Funkcial. Ekvac. 
	

\bibitem{Oh:2010p1338}
	Oh, T.; Quastel, J.; Valk\'o, B.
	\newblock {\it Interpolation of Gibbs measures with white noise for Hamiltonian PDE,} 
	\newblock 	arXiv:1005.3957v1  [math.PR].

\bibitem{SULEM}
	Oh, T.; Sulem, C.
	\newblock {\it On the one-dimensional cubic nonlinear Schr\"odinger equation below $L^2$,} 
	\newblock to appear in Kyoto J. Math. 

\bibitem{PZ}
Paley, R.; Zygmund, A.
	\newblock {\it On some series of functions (1), (2), (3),} 
	\newblock Proc. Camb. Phil. Soc. 26, (1930), 337--357; 26, (1930), 458--474;
	28, (1933), 190--205.

	\bibitem{Quastel:2008p796}
	Quastel, J.; Valk{\'o}, B.
	\newblock {\it KdV preserves white noise,}
	\newblock   Comm. Math. Phys.  277  (2008),  no. 3, 707--714. 

	\bibitem{Thomann:2009p1427}
	Thomann, L.
	\newblock Random data Cauchy problem for supercritical Schr\"odinger equations.
	\newblock  Ann. Inst. H. Poincar\'e Anal. Non Lin\'eaire  26  (2009),  no. 6, 2385--2402. 

	\bibitem{Tsutsumi:1987p799}
	Tsutsumi, Y.
	\newblock {\it $L^2$-solutions for nonlinear Schr\"odinger equations and nonlinear groups,}
	\newblock Funkcial. Ekvac.  30  (1987),  no. 1, 115--125.

	

	\bibitem{Tzvetkov:2006p801}
Tzvetkov, N.
	\newblock {\it Invariant measures for the nonlinear Schr\"odinger equation on the disc,}
	\newblock Dyn. Partial Differ. Equ.  3  (2006),  no. 2, 111--160.

	\bibitem{Tzvetkov:2008p736}
	Tzvetkov, N.
	\newblock {\it Invariant measures for the defocusing nonlinear Schr\"odinger equation,}
	\newblock Ann. Inst. Fourier (Grenoble)  58  (2008),  no. 7, 2543--2604.

\bibitem{Tzvetkov:2010p1443}
	Tzvetkov, N.
	\newblock {\it Construction of a Gibbs measure associated to the periodic Benjamin-Ono equation,}
	\newblock Probab. Theory Related Fields  146  (2010),  no. 3-4, 481--514. 

	\bibitem{Zhidkov:1994p834}
	Zhidkov, P.E.
	\newblock {\it An invariant measure for a nonlinear wave equation,}
	\newblock Nonlinear Anal.  22  (1994),  no. 3, 319--325. 

	\bibitem{Zhidkov:2001p831}
	Zhidkov, P.E.
	\newblock {\it Korteweg-de Vries and nonlinear Schr\"odinger equations: qualitative theory,}
	\newblock  Lecture Notes in Mathematics, 1756. Springer-Verlag, Berlin, 2001. vi+147 pp.

	\end{thebibliography}

\end{document} 

