
\documentclass[a4paper,twoside,11pt]{article} 

\usepackage[english]{babel} \usepackage{lmodern}
\usepackage[T1]{fontenc}
\usepackage[latin9]{inputenc}	

\newlength{\defaultparindent}
\setlength{\defaultparindent}{\parindent}

\usepackage{latexsym}
\usepackage{amsmath}
\usepackage{amsfonts}
\usepackage{amsthm}
\usepackage{bbold}
\usepackage{multirow}
\usepackage{hyperref}
\hypersetup{colorlinks=true,citecolor=green,linkcolor= blue}
\usepackage{todonotes} 
\usepackage{soul} 

 

\usepackage[arXiv]{optional} 
 

\opt{AACA}{

}

\opt{x,AACA}{

}

\opt{arXiv,std,JMP,JOPA}{

\newtheorem{MS_theorem}{Theorem}
\newtheorem{MS_lemma}{Lemma}
\newtheorem{MS_Proposition}{Proposition}
\newtheorem{MS_Corollary}[MS_Proposition]{Corollary}
\newtheorem{MS_Algorithm}{Algorithm}
 

 
 
 
 
 
 
 
 
 

 

           

 
	
	
	
	

	
	
}

\opt{JMP}{
}

\def\h_eigen{\eta}
\def\g_eigen{\theta}
 
 
 
 

\begin{document}

\opt{x,std,arXiv,JMP,JOPA}{
\title{{\bf The Boolean SATisfiability Problem in Clifford algebra} 
	}

\author{\\
	\bf{Marco Budinich}\\
	University of Trieste and INFN, Trieste, Italy\\
	\texttt{mbh@ts.infn.it}\\
	}
\date{ \today }
\maketitle
}

\opt{AACA}{
\title[On Spinors of Zero Nullity]{On Spinors of Zero Nullity}

\author{Marco Budinich}
\address{Dipartimento di Fisica\\
	UniversitÃ  di Trieste \& INFN\\
	Via Valerio 2, I - 34127 Trieste, Italy}
\email{mbh@ts.infn.it}
}

\begin{abstract}
We present a formulation of the Boolean Satisfiability Problem in spinor language that allows to give a necessary and sufficient condition for unsatisfiability. With this result we outline an algorithm to test for unsatisfiability with possibly interesting theoretical properties.
\end{abstract}

\opt{AACA}{
\keywords{Clifford algebra, spinors, Fock basis.}
\maketitle
}

\section{Introduction}
\label{Introduction}
\opt{margin_notes}{{\todo}{mbh.note: for paper material see log pp. 689 ff.}}In 1913 {\'{E}}lie Cartan introduced spinors \cite{Cartan_1913, Cartan_1937} and, after more than a century, this field continues to yield rich harvests.
Spinors were later thoroughly investigated by Claude Chevalley \cite{Chevalley_1954} in the mathematical frame of Clifford algebras where they were identified as elements of Minimal Left Ideals of the algebra.

In this paper we write the famous Boolean Satisfiability Problem (SAT) in spinor language and exploit the properties of Clifford algebra to arrive to a necessary and sufficient condition for unsatisfiability.

In section~\ref{SAT_basics} we succintly resume basic properties of {\ensuremath{\mbox{SAT}}}, in section~\ref{SAT_reformulation} we present an equivalent representation of {\ensuremath{\mbox{SAT}}}{} in an Abelian subalgebra of Clifford algebra and we prove more in general that any logical expression can be neatly represented by an idempotent. In the following section~\ref{unSAT_condition} we exploit this formulation to obtain, with a basic result of Clifford algebra, a necessary and sufficient condition for a {\ensuremath{\mbox{SAT}}}{} problem to be unsatisfiable. In final section~\ref{unSAT_algorithm} we use this result to outline an algorithm for {\ensuremath{\mbox{SAT}}}{} problems whose theoretical properties appear promising.

For the convenience of the reader we tried to make this paper as elementary and self-contained as possible.

\section{Satisfiability problem}
\label{SAT_basics}
The Boolean Satisfiability Problem \cite[Section~7.2.2.2]{Knuth_2015} asks for an assignment of logical variables $x_1, x_2, \ldots ,x_m; x_i \in \{\mathrm{T}, \mathrm{F}\}$, that satisfies a given Boolean formula expressed in conjunctive normal form {e.g.\ }
$$
(x_1 \lor \lnot x_2) \land (x_2 \lor x_3) \land ( \lnot x_1 \lor \lnot x_3) \land ( \lnot x_1 \lor \lnot x_2 \lor x_3) \land (x_1 \lor x_2 \lor \lnot x_3)
$$
as a logical AND of $p$ \emph{clauses} $C_j$, the expressions in parenthesis, and each clause is composed by the logical OR of at most $k$ logical variables; in this example $m = 3, p = 5, k = 3$. SAT was the first problem proven to be NP-complete \cite{Cook_1971}; in particular while the case of $k = 2$, 2-{\ensuremath{\mbox{SAT}}}, can be solved in polynomial time, the 3-{\ensuremath{\mbox{SAT}}}{} problem can be solved only in a time that grows exponentially with $m$.

We remark that a 1-{\ensuremath{\mbox{SAT}}}{} formula is just a logical AND of p logical variables that can be satisfied by only one assignment of the variables that is immediately determined scanning the formula. Since, for any assignment of $x_i$, $x_i \land \lnot {x}_i = \mathrm{F}$ the presence of a variable together with its logical complement is a necessary and sufficient condition for a 1-{\ensuremath{\mbox{SAT}}}{} formula to be unsatisfiable.

Using the distributive properties of the logical operators $\lor, \land$ one can expand any given $k$-{\ensuremath{\mbox{SAT}}}{} formula in a logical OR of up to $k^p$ 1-{\ensuremath{\mbox{SAT}}}{} terms. $k^p$ is just an upper bound since terms containing $x_i \land \lnot {x}_i = \mathrm{F}$ can be omitted; strictly the upper bound is actually $\min{(2^m - p, k^p)}$. The final expanded expression can be easily simplified and reordered exploiting the commutativity of the logical operators $\lor, \land$ and the property that for any assignment of $x_i$, $x_i \land x_i = x_i$. With these observation it is easy to see that all ``surviving'' expansion terms are 1-{\ensuremath{\mbox{SAT}}}{} terms that represent a solution of the problem. If, on the contrary, the final expansion is empty this means that there are no assignments of the variables that make the formula true: the problem is unsatisfiable.

In practice this expansion is a bad algorithm for {\ensuremath{\mbox{SAT}}}{} for two reasons: the first is that this method is an overkill since it produces all possible solutions whereas usually one is enough for {\ensuremath{\mbox{SAT}}}{}; the second is that this brute force approach produce a running time that is proportional to the upper number of final terms, that calling $\alpha = \frac{p}{m}$ the ratio of clauses to variables, is {\ensuremath{\mathcal{O}\left({(k^{\alpha})^m}\right)}} whereas the present best algorithms for ${\ensuremath{\mbox{SAT}}}$ \cite{PaturiPudlakSaksZane_2005} run in {\ensuremath{\mathcal{O}\left({1.307^m}\right)}}.

We will put a {\ensuremath{\mbox{SAT}}}{} problem in a more concise form as
\begin{equation}
\label{formula_SAT_std}
{\ensuremath{\mbox{SAT}}} = ({\ensuremath{\rho}}_h + {\ensuremath{\rho}}_j + \cdots + {\ensuremath{\rho}}_k) \cdots ({\ensuremath{\rho}}_t + {\ensuremath{\rho}}_u + \cdots + {\ensuremath{\rho}}_z) \qquad {\ensuremath{\rho}}_i \in \{x_i, {\overline{{x}}}_i \}
\end{equation}
where ${\ensuremath{\rho}}_i$ is a \emph{literal} that represents variable $x_i$ or its complement, ${\overline{{x}}}_i$ for short, the $+$ stands for logical OR and the product for logical AND.

\section{Satisfiability in Clifford algebra}
\label{SAT_reformulation}
Given a SAT problem with $p > 0$ clauses and $m$ logical variables $x_i$ we consider the Clifford algebra ${\ensuremath{{{{\mathcal} C}\ell} {\left( {{\ensuremath{\mathbb{R}}}^{m,m}} \right)}}}$ isomorphic to the algebra of real matrices ${\ensuremath{\mathbb{R}}}(2^m)$. This algebra is more easily manipulated exploiting the properties of its Extended Fock Basis (EFB, see \cite{Budinich_2016} and references therein) with which any algebra element appears as a linear superposition of simple spinors.

We remind that the $2m$ generators of the algebra ${e}_{i}$ form an orthonormal basis of the neutral vector space $V = {\ensuremath{\mathbb{R}}}^{m,m}$ with {e.g.\ }
\begin{equation}
\label{formula_generators}
{e}_i {e}_j + {e}_j {e}_i := {\ensuremath{\left\{ {{e}_i}, {{e}_j} \right\}}} = 2 \delta_{i j} (-1)^{i+1} \qquad i,j = 1,2, \ldots, 2 m
\end{equation}
while the Witt, or null, basis of $V$ is:
\begin{equation}
\label{formula_Witt_basis}
\left\{ \begin{array}{l l l}
p_{i} & = & \frac{1}{2} \left( {e}_{2i-1} + {e}_{2i} \right) \\
q_{i} & = & \frac{1}{2} \left( {e}_{2i-1} - {e}_{2i} \right)
\end{array} \right.
\quad i = 1,2, \ldots, m
\end{equation}
that, with ${e}_{i} {e}_{j} = - {e}_{j} {e}_{i}$, gives
\begin{equation}
\label{formula_Witt_basis_properties}
{\ensuremath{\left\{ {p_{i}}, {p_{j}} \right\}}} = {\ensuremath{\left\{ {q_{i}}, {q_{j}} \right\}}} = 0
\qquad
{\ensuremath{\left\{ {p_{i}}, {q_{j}} \right\}}} = \delta_{i j}
\end{equation}
showing that all $p_i, q_i$ are mutually orthogonal, also to themselves, that implies $p_i^2 = q_i^2 = 0$, at the origin of the name ``null'' given to these vectors. Simple spinors forming EFB are products of $m$ of the null vectors (\ref{formula_Witt_basis}).

To represent {\ensuremath{\mbox{SAT}}}{} problems we will assume that $\mathrm{F}$ is 0 and $\mathrm{T}$ any non zero element. Moreover we will not need the full algebra ${\ensuremath{{{{\mathcal} C}\ell} {\left( {{\ensuremath{\mathbb{R}}}^{m,m}} \right)}}}$ but we will restrict to the even, Abelian, subalgebra $P$ given by the vectorial space spanned by the $2^m$ primitive idempotents ${\mathbb{p}}_i$ of the algebra. We remind the standard properties of the primitive idempotents
\begin{equation}
\label{formula_primitive_idempotents}
{\mathbb{p}}_i^2 = {\mathbb{p}}_i \quad ({\ensuremath{\mathbb{1}}} - {\mathbb{p}}_i)^2 = {\ensuremath{\mathbb{1}}} - {\mathbb{p}}_i \quad {\mathbb{p}}_i ({\ensuremath{\mathbb{1}}} - {\mathbb{p}}_i) = 0 \quad {\mathbb{p}}_i {\mathbb{p}}_j = \delta_{i j} {\mathbb{p}}_i
\end{equation}
and, since ${\ensuremath{{{{\mathcal} C}\ell} {\left( {{\ensuremath{\mathbb{R}}}^{m,m}} \right)}}}$ is a simple algebra, the unit element of the algebra ${\ensuremath{\mathbb{1}}}$ can be expressed as the sum of its primitive idempotents
\begin{equation}
\label{formula_identity_def}
{\ensuremath{\mathbb{1}}} = \sum_{i = 1}^{2^m} {\mathbb{p}}_i = {\ensuremath{\left\{ {q_1}, {p_1} \right\}}} {\ensuremath{\left\{ {q_2}, {p_2} \right\}}} \cdots {\ensuremath{\left\{ {q_m}, {p_m} \right\}}}
\end{equation}
where the second form, a product of $m$ anticommutators, is the expression of identity in EFB, and the full expansion of these anticommutators generate $2^m$ terms each term being one of the primitive idempotents (and a simple spinor). In the isomorphic matrix algebra ${\ensuremath{\mathbb{R}}}(2^m)$ $P$ is usually the subalgebra of diagonal matrices and the primitive idempotents are the $2^m$ diagonal matrices with just a single $1$ on the diagonal.

The subalgebra $P$ contains a subset
\begin{equation}
\label{formula_S_def}
S = \left\{ \sum_{i = 1}^{2^m} \delta_i {\mathbb{p}}_i : \delta_i \in \left\{0, 1 \right\} \right\} \subset P
\end{equation}
that is closed under multiplication but not under addition and is thus not a subalgebra. With primitive idempotent properties (\ref{formula_primitive_idempotents}) it is simple to prove
\opt{margin_notes}{{\todo}{mbh.note: the proof is commented. Is in general any idempotent a sum of primitive idempotents ?}}\begin{MS_Proposition}
\label{S_properties}
$s \in S$ if and only if $s$ is an idempotent, $s^2 = s$
\end{MS_Proposition}
\noindent and thus $S$ is the set of the idempotents, in general not primitive; a simple consequence is that for any $s \in S$ also $({\ensuremath{\mathbb{1}}} - s) \in S$. We remark also that the $2^m$ primitive idempotents ${\mathbb{p}}_i$ form an orthonormal basis of both $S$ and $P$ as vectorial spaces.

To represent Boolean variables in the subalgebra of ${\ensuremath{{{{\mathcal} C}\ell} {\left( {{\ensuremath{\mathbb{R}}}^{m,m}} \right)}}}$ we map literal ${\ensuremath{\rho}}_i \to q_i p_i$ and ${\overline{\ensuremath{\rho}}}_i \to p_i q_i$ and with Witt basis properties (\ref{formula_Witt_basis_properties}) we have
$$
q_i p_i q_i p_i = q_i p_i \quad q_i p_i p_i q_i = 0 \quad q_i p_i q_j p_j = q_j p_j q_i p_i \quad q_i p_i + p_i q_i = 1
$$
that, mapping the logical AND and OR to Clifford product and sum, can be read as the logical relations for literals
$$
{\ensuremath{\rho}}_i \land {\ensuremath{\rho}}_i = {\ensuremath{\rho}}_i \quad {\ensuremath{\rho}}_i \land {\overline{\ensuremath{\rho}}}_i = \mathrm{F} \quad {\ensuremath{\rho}}_i \land {\ensuremath{\rho}}_j = {\ensuremath{\rho}}_j \land {\ensuremath{\rho}}_i \quad {\ensuremath{\rho}}_i \lor {\overline{\ensuremath{\rho}}}_i = \mathrm{T} {\;\; \mathrm{.}}
$$

By proposition~\ref{S_properties} and $q_i p_i q_i p_i = q_i p_i$ descends that all the literals mapped in Clifford algebra belong to the set $S$; it is nevertheless instructive to derive this property directly from EFB formalism applied to {e.g.\ } $q_1 p_1$, with (\ref{formula_identity_def})
$$
q_1 p_1 = q_1 p_1 {\ensuremath{\mathbb{1}}} = q_1 p_1 {\ensuremath{\left\{ {q_2}, {p_2} \right\}}} \cdots {\ensuremath{\left\{ {q_m}, {p_m} \right\}}}
$$
since $q_1 p_1 {\ensuremath{\left\{ {q_1}, {p_1} \right\}}} = q_1 p_1$ (and more in general ${\ensuremath{\rho}}_i {\ensuremath{\left\{ {q_i}, {p_i} \right\}}} = {\ensuremath{\rho}}_i ({\ensuremath{\rho}}_i + {\overline{\ensuremath{\rho}}}_i) = {\ensuremath{\rho}}_i$); the full expansion is thus a sum of $2^{m - 1}$ EFB terms that are primitive idempotents and thus $q_1 p_1 \in S$. From the logical viewpoint this can be interpreted as the property that when ${\ensuremath{\rho}}_1$ is fixed the other, unsepicified, $m-1$ literals ${\ensuremath{\rho}}_2, \ldots, {\ensuremath{\rho}}_m$ can take all possible $2^{m - 1}$ values.

Since the set $S$ is closed under multiplication all product of literals, corresponding to logical AND, are 1-{\ensuremath{\mbox{SAT}}}{} formulas that are in $S$ and thus are idempotents. The generalization of previous formula to the case of a product of an arbitrary number of literals is
$$
{\ensuremath{\rho}}_r {\ensuremath{\rho}}_s \cdots {\ensuremath{\rho}}_t = {\ensuremath{\rho}}_r {\ensuremath{\rho}}_s \cdots {\ensuremath{\rho}}_t {\ensuremath{\mathbb{1}}} = {\ensuremath{\rho}}_r {\ensuremath{\rho}}_s \cdots {\ensuremath{\rho}}_t \prod_{\stackrel{i = 1}{i \ne r, s, \ldots, t}}^m {\ensuremath{\left\{ {q_i}, {p_i} \right\}}} {\;\; \mathrm{.}}
$$

At this point it should be manifest that the $2^m$ primitive idempotents ${\mathbb{p}}_i$ are in one to one correspondence with the possible $2^m$ assignments to the $m$ literals ${\ensuremath{\rho}}_i$, for example given an assignment of the $m$ literals one finds
$$
{\ensuremath{\rho}}_1 {\overline{\ensuremath{\rho}}}_2 \cdots {\ensuremath{\rho}}_m \to q_1 p_1 p_2 q_2 \cdots q_m p_m
$$
that is one of the primitive idempotents of (\ref{formula_identity_def}).

When dealing with logical expressions we must distinguish two cases in which literals may appear: a product of literals may be given the meaning of an assignment of values to logical variables, for example we may interpret ${\ensuremath{\rho}}_i {\ensuremath{\rho}}_j {\overline{\ensuremath{\rho}}}_k$ as ${\ensuremath{\rho}}_i = {\ensuremath{\rho}}_j = \mathrm{T}, {\ensuremath{\rho}}_k = \mathrm{F}$, or as a 1-{\ensuremath{\mbox{SAT}}}{} formula with unassigned literals. With our mapping in Clifford algebra this duality is respected and we can test if an assignment, {e.g.\ } ${\ensuremath{\rho}}_i {\ensuremath{\rho}}_j {\overline{\ensuremath{\rho}}}_k$, satisfies a given formula, {e.g.\ } ${\ensuremath{\rho}}_i {\overline{\ensuremath{\rho}}}_k$ ``substituting'' the assignment in the formula, that in Clifford algebra is performed simply calculating their product: if the result is not zero, $\mathrm{T}$, this means that the given assignment satisfies the formula, in our example
$$
{\ensuremath{\rho}}_i {\overline{\ensuremath{\rho}}}_k \; \; {\ensuremath{\rho}}_i {\ensuremath{\rho}}_j {\overline{\ensuremath{\rho}}}_k = {\ensuremath{\rho}}_i {\ensuremath{\rho}}_j {\overline{\ensuremath{\rho}}}_k \ne 0 \to \mathrm{T}
$$
in this sense we can read ${\ensuremath{\rho}}_i {\overline{\ensuremath{\rho}}}_i = 0$ as the fact that ${\ensuremath{\rho}}_i = \mathrm{F}$ does not satisfy the formula ${\ensuremath{\rho}}_i$ and ${\ensuremath{\rho}}_i {\ensuremath{\rho}}_i = {\ensuremath{\rho}}_i$ as the fact that ${\ensuremath{\rho}}_i = \mathrm{T}$ satisfies formula ${\ensuremath{\rho}}_i$.

We come now to the representation in ${\ensuremath{{{{\mathcal} C}\ell} {\left( {{\ensuremath{\mathbb{R}}}^{m,m}} \right)}}}$ of the logical OR, unfortunately $S$ is not closed under addition and so in general the sum of literals belong to the subalgebra $P$ but not to $S$, for example ${\ensuremath{\rho}}_i + {\ensuremath{\rho}}_i = 2 {\ensuremath{\rho}}_i$ or $({\ensuremath{\rho}}_i + {\ensuremath{\rho}}_j)^2 = {\ensuremath{\rho}}_i + {\ensuremath{\rho}}_j + 2 {\ensuremath{\rho}}_i {\ensuremath{\rho}}_j$ and we realize that the sum in Clifford algebra does not reproduce faithfully the properties of the logical OR. Still the sum will turn out to be useful to map the logical OR of literals. For example we know that logical clause ${\ensuremath{\rho}}_i + {\ensuremath{\rho}}_j$ is satisfied by all assignment but ${\ensuremath{\rho}}_i = {\ensuremath{\rho}}_j = \mathrm{F}$ and this result is reproduced in Clifford algebra where
$$
(q_i p_i + q_j p_j) p_i q_i p_j q_j = 0
$$
whereas all other possible assignments ($q_i p_i p_j q_j, p_i q_i q_j p_j, q_i p_i q_j p_j$) give non zero results and satisfy the formula. It is simple to verify that also
$$
(\delta_i q_i p_i + \delta_j q_j p_j) p_i q_i p_j q_j = 0 \qquad \forall \delta_i, \delta_j \in {\ensuremath{\mathbb{R}}} - \{0\}
$$
whatever the values taken by the real coefficients. This example shows constructively that the field coefficient that may appear in the sums are irrelevant as far as the mapping of a logical formula is concerned. So we can guess that even if $S$ is not closed under addition we are allowed to use the sum to represent the logical OR of literals.
\opt{margin_notes}{{\todo}{mbh.note: old footnote: one could be tempted to use a ``projection'' in $S$ of the sum assuming that all non zero coefficients are brought to $1$ but this would still not be satisfactory since while from the logical viewpoint $({\ensuremath{\rho}}_i + {\ensuremath{\rho}}_j) ({\ensuremath{\rho}}_i + {\ensuremath{\rho}}_j) = {\ensuremath{\rho}}_i + {\ensuremath{\rho}}_j$ even with this ``new sum'' we would get $({\ensuremath{\rho}}_i + {\ensuremath{\rho}}_j) ({\ensuremath{\rho}}_i + {\ensuremath{\rho}}_j) = {\ensuremath{\rho}}_i + {\ensuremath{\rho}}_j + {\ensuremath{\rho}}_i {\ensuremath{\rho}}_j$.}}That this is actually so, at least for the case of {\ensuremath{\mbox{SAT}}}{} problems, is proved by
\begin{MS_Proposition}
\label{SAT_in_Cl}
A given SAT problem (\ref{formula_SAT_std}) admits solution if and only if, the corresponding expression of ${\ensuremath{{{{\mathcal} C}\ell} {\left( {{\ensuremath{\mathbb{R}}}^{m,m}} \right)}}}$
\begin{equation}
\label{formula_SAT_EFB}
{\ensuremath{\mbox{SAT}}} = ({\ensuremath{\rho}}_h + {\ensuremath{\rho}}_j + \cdots {\ensuremath{\rho}}_k) \cdots ({\ensuremath{\rho}}_t + {\ensuremath{\rho}}_u + \cdots {\ensuremath{\rho}}_z) \qquad {\ensuremath{\rho}}_i \in \{q_i p_i, p_i q_i \}
\end{equation}
is different from $0$.
\end{MS_Proposition}

\begin{proof}
the result is immediate observing that by distributivity of $+$ over multiplication in both (\ref{formula_SAT_std}) and (\ref{formula_SAT_EFB}), together with the additional rules ${\ensuremath{\rho}}_i {\ensuremath{\rho}}_i = {\ensuremath{\rho}}_i$ and ${\ensuremath{\rho}}_i {\overline{\ensuremath{\rho}}}_i = 0$ that again hold in both cases, produce identical expansion of the two formulas and that non zero terms, in both cases, identify all and only the assignments of literals that satisfy the {\ensuremath{\mbox{SAT}}}{} formula.
\end{proof}

With this proposition we have transformed our {\ensuremath{\mbox{SAT}}}{} problem in an equivalent calculation in subalgebra $P$ of ${\ensuremath{{{{\mathcal} C}\ell} {\left( {{\ensuremath{\mathbb{R}}}^{m,m}} \right)}}}$ but to proceed we need a better form for (\ref{formula_SAT_EFB}). To do this we deal with the case of the logical NOT operator; by Witt basis properties (\ref{formula_Witt_basis_properties})
$$
q_i p_i + p_i q_i = 1
$$
that in our setting we can read as ${\ensuremath{\rho}}_i + {\overline{\ensuremath{\rho}}}_i = 1$. We thus can guess that ${\overline{\ensuremath{\rho}}}_i = 1 - {\ensuremath{\rho}}_i$ and since in ${\ensuremath{{{{\mathcal} C}\ell} {\left( {{\ensuremath{\mathbb{R}}}^{m,m}} \right)}}}$ $1$ coincides with ${\ensuremath{\mathbb{1}}}$
$$
{\overline{\ensuremath{\rho}}}_i = {\ensuremath{\mathbb{1}}} - {\ensuremath{\rho}}_i
$$
that turns out to be a particular case of the more general
\opt{margin_notes}{{\todo}{mbh.note: remark that there exist many idempotents annihilating ${\ensuremath{\rho}}_r {\ensuremath{\rho}}_s \cdots {\ensuremath{\rho}}_t$ but only one is its complement ${\ensuremath{\mathbb{1}}} - {\ensuremath{\rho}}_r {\ensuremath{\rho}}_s \cdots {\ensuremath{\rho}}_t$}}\begin{MS_Proposition}
\label{complementary_assignment}
Given any logical assignment, namely 1-{\ensuremath{\mbox{SAT}}}{} formula, ${\ensuremath{\rho}}_r {\ensuremath{\rho}}_s \cdots {\ensuremath{\rho}}_t$, its logical complement is
\begin{equation}
\label{formula_complemented_assignement}
{\overline{{{\ensuremath{\rho}}_r {\ensuremath{\rho}}_s \cdots {\ensuremath{\rho}}_t}}} = {\ensuremath{\mathbb{1}}} - {\ensuremath{\rho}}_r {\ensuremath{\rho}}_s \cdots {\ensuremath{\rho}}_t
\end{equation}
\end{MS_Proposition}

\begin{proof}
By idempotents properties one obtains immediately $({\ensuremath{\mathbb{1}}} - {\ensuremath{\rho}}_r {\ensuremath{\rho}}_s \cdots {\ensuremath{\rho}}_t) {\ensuremath{\rho}}_r {\ensuremath{\rho}}_s \cdots {\ensuremath{\rho}}_t = 0$ and the proof is completed verifying that ${\ensuremath{\rho}}_r {\ensuremath{\rho}}_s \cdots {\ensuremath{\rho}}_t$ is the only assignment giving this result.
\end{proof}

We are now ready to give a better form to {\ensuremath{\mbox{SAT}}}{} problems in ${\ensuremath{{{{\mathcal} C}\ell} {\left( {{\ensuremath{\mathbb{R}}}^{m,m}} \right)}}}$

\begin{MS_Proposition}
\label{SAT_in_Cl_2}
A given SAT problem admits solution if and only if
\begin{equation}
\label{formula_SAT_EFB_2}
{\ensuremath{\mbox{SAT}}} = \prod_{j = 1}^p C_j := \prod_{j = 1}^p ({\ensuremath{\mathbb{1}}} - z_j) \ne 0
\end{equation}
where we define $z_j$ as the product of the complemented literals of clause $C_j$.
\end{MS_Proposition}

\begin{proof}
With proposition~\ref{SAT_in_Cl} we just need to prove that from a logical viewpoint each clause $C_j$ is equivalent to ${\ensuremath{\mathbb{1}}} - z_j$ that, in our setting, is equivalent to show that $C_j = 0$ if and only if ${\ensuremath{\mathbb{1}}} - z_j = 0$. With De Morgan's relations and (\ref{formula_complemented_assignement}) we can write clause $C_j$
$$
C_j = ({\ensuremath{\rho}}_r + {\ensuremath{\rho}}_s + \cdots + {\ensuremath{\rho}}_t) = {\overline{{{\overline{{({\ensuremath{\rho}}_r + {\ensuremath{\rho}}_s + \cdots + {\ensuremath{\rho}}_t)}}}}}} = {\overline{{{\overline{\ensuremath{\rho}}}_r {\overline{\ensuremath{\rho}}}_s \cdots {\overline{\ensuremath{\rho}}}_t}}} = {\ensuremath{\mathbb{1}}} - {\overline{\ensuremath{\rho}}}_r {\overline{\ensuremath{\rho}}}_s \cdots {\overline{\ensuremath{\rho}}}_t = {\ensuremath{\mathbb{1}}} - z_j {\;\; \mathrm{.}}
$$
\end{proof}

We remark that while the standard representation of $C_j$ with a sum in general does not belong to $S$ in the equivalent representation ${\ensuremath{\mathbb{1}}} - z_j$ both $z_j$ and ${\ensuremath{\mathbb{1}}} - z_j$ belong to $S$. Expanding the product of two clauses we get
\begin{equation}
\label{formula_z_j_expansion}
({\ensuremath{\mathbb{1}}} - z_j) ({\ensuremath{\mathbb{1}}} - z_k) = {\ensuremath{\mathbb{1}}} - z_j - z_k + z_j z_k
\end{equation}
and $z_j z_k = 0$ if and only if in $z_j$ and $z_k$ appears the same literal in opposite form (${\ensuremath{\rho}}_i {\overline{\ensuremath{\rho}}}_i = 0$). In any way this product is always in $S$ even if the generic terms of the expansion are not in general in $S$, {e.g.\ } $- z_j$. In general the product of $p$ clauses will produce at most $2^p$ terms in the full expansion the first of which is certainly ${\ensuremath{\mathbb{1}}}$ so that, calling $\Delta$ the other terms we can rewrite (\ref{formula_SAT_EFB_2}) as
\begin{equation}
\label{formula_SAT_EFB_3}
{\ensuremath{\mbox{SAT}}} = \prod_{j = 1}^p ({\ensuremath{\mathbb{1}}} - z_j) = {\ensuremath{\mathbb{1}}} - \Delta
\end{equation}
and in this formulation {\ensuremath{\mbox{SAT}}}{} is in $S$ and thus also $\Delta = {\ensuremath{\mathbb{1}}} - {\ensuremath{\mbox{SAT}}}$ is in $S$ and thus all elements of this relation are idempotents.

At this point, since every logical formula can be put in the conjunctive normal form of (\ref{formula_SAT_std}), we have proved the more general result
\begin{MS_Proposition}
\label{logical_formulas_in_S}
any logical formula $L$ can be represented by $l \in S$ and ${\overline{{L}}}$ by ${\ensuremath{\mathbb{1}}} - l$ and both are idempotents of ${\ensuremath{{{{\mathcal} C}\ell} {\left( {{\ensuremath{\mathbb{R}}}^{m,m}} \right)}}}$. Moreover given two logical formulas their equivalence, $L_1 = L_2$, namely the equality for any assignment of the logical variables that enter the logical formulas, correspond to the algebraic equality $l_1 = l_2$ of their corresponding idempotents in $S$.
\end{MS_Proposition}
\begin{proof}
To prove the second part of the proposition it is sufficient to go to the proof of proposition~\ref{SAT_in_Cl} and observe that any logical formula in conjunctive normal form is equivalent to a {\ensuremath{\mbox{SAT}}}{} problem and that the expansion of its logical form (\ref{formula_SAT_std}) give all assignments of the logical variables that satisfy the formula and that these assignments are in one to one correspondence with the expansion of {\ensuremath{\mbox{SAT}}}{} (\ref{formula_SAT_EFB_2}) in $S$.
\end{proof}

We conclude this part observing that a logical system is fully defined when are defined, as in our case, the logical AND and the logical NOT. We can exploit this property to get the correct expression of the logical OR in ${\ensuremath{{{{\mathcal} C}\ell} {\left( {{\ensuremath{\mathbb{R}}}^{m,m}} \right)}}}$. From De Morgan's relation between logical variables $x_i + x_j = {\overline{{{\overline{{x}}}_i {\overline{{x}}}_j}}}$ we get the corresponding relation in ${\ensuremath{{{{\mathcal} C}\ell} {\left( {{\ensuremath{\mathbb{R}}}^{m,m}} \right)}}}$
$$
\mbox{OR}(x_i,x_j) = {\ensuremath{\mathbb{1}}} - ({\ensuremath{\mathbb{1}}} - x_i)({\ensuremath{\mathbb{1}}} - x_j) = x_i + x_j - x_i x_j
$$
and it is simple to check that this expression is in $S$ since
$$
(x_i + x_j - x_i x_j) (x_i + x_j - x_i x_j) = x_i + x_j - x_i x_j
$$
with which the mapping of logical formulas of $m$ logical variables $x_i$ in the set of idempotents $S$ of ${\ensuremath{{{{\mathcal} C}\ell} {\left( {{\ensuremath{\mathbb{R}}}^{m,m}} \right)}}}$ is complete and from now on we can treat any logical expression algebraically in Clifford algebra.

\section{A condition for unsatisfiability}
\label{unSAT_condition}
Exploiting this {\ensuremath{\mbox{SAT}}}{} formulation we prove the central result of this paper:
\opt{margin_notes}{{\todo}{mbh.note: probably the result is correct also for {\ensuremath{\mbox{SAT}}}{} as in (\ref{formula_SAT_EFB})}}\begin{MS_theorem}
\label{SAT_unsat_thm}
A given {\ensuremath{\mbox{SAT}}}{} problem (\ref{formula_SAT_EFB_3}) admits no solution if and only if
$$
{e}_i \; {\ensuremath{\mbox{SAT}}} \; {e}_i^{-1} = {\ensuremath{\mbox{SAT}}} \qquad 1 \le i \le 2 m
$$
where ${e}_i$ are the $2 m$ generators (\ref{formula_generators}) of ${\ensuremath{{{{\mathcal} C}\ell} {\left( {{\ensuremath{\mathbb{R}}}^{m,m}} \right)}}}$.
\end{MS_theorem}
\begin{proof}
We observe first that, by proposition~\ref{logical_formulas_in_S}, it is enough to verify the algebraic equality of these expressions in $S$.

By (\ref{formula_SAT_EFB_3}) ${e}_i \; {\ensuremath{\mbox{SAT}}} \; {e}_i^{-1} = {\ensuremath{\mbox{SAT}}}$ if and only if ${e}_i \Delta {e}_i^{-1} = \Delta$ and we take the latter formulation. It is a standard property of Clifford algebra \cite[Propostion~16.6]{Porteous_1995} that an element of the 
\opt{margin_notes}{{\todo}{mbh.note: probably one could also say more simply that ${\ensuremath{{{{\mathcal} C}\ell} {\left( {{\ensuremath{\mathbb{R}}}^{m,m}} \right)}}}$ is central}}even subalgebra commutes with all generators ${e}_i$ if and only it is of the form $\delta {\ensuremath{\mathbb{1}}}$ for $\delta \in {\ensuremath{\mathbb{R}}}$. So ${e}_i \Delta {e}_i^{-1} = \Delta$ for all $i$ is equivalent to $\Delta = \delta {\ensuremath{\mathbb{1}}}$ but we know that $\Delta \in S$ and thus necessarily $\delta \in \{0, 1\}$. The case $\delta = 0$ implies ${\ensuremath{\mbox{SAT}}} = {\ensuremath{\mathbb{1}}}$ that represents a {\ensuremath{\mbox{SAT}}}{} problem with no clauses, $p = 0$, so $\delta = 1$. With proposition~\ref{SAT_in_Cl_2} applied to form (\ref{formula_SAT_EFB_3}) $\Delta = {\ensuremath{\mathbb{1}}}$ is equivalent to ${\ensuremath{\mbox{SAT}}} = 0$ namely that it is unsatisfiable.
\end{proof}

It is well known that a given {\ensuremath{\mbox{SAT}}}{} problem is unsatisfiable if and only if ${\overline{\ensuremath{\mbox{SAT}}}}$ is a tautology, namely if ${\overline{\ensuremath{\mbox{SAT}}}} = \mathrm{T}$ for all assignments of the logical variables. With proposition~\ref{complementary_assignment} and (\ref{formula_SAT_EFB_3}) ${\overline{\ensuremath{\mbox{SAT}}}} = {\ensuremath{\mathbb{1}}} - {\ensuremath{\mbox{SAT}}} = \Delta$ thus we have
\begin{MS_Corollary}
\label{TAUT_in_Cl}
The representation of a logical expression $\Delta \in S$ is a tautology if and only if $\Delta \ne 0$ and
$$
{e}_i \; \Delta \; {e}_i^{-1} = \Delta \qquad 1 \le i \le 2 m
$$
\end{MS_Corollary}
\noindent so tautologies are represented in $S$ by ${\ensuremath{\mathbb{1}}}$. In the next paragraph we will exploit this result to test unsatisfiability testing if the complementary problem $\Delta$ is a tautology (it results easier to test if $\Delta = {\ensuremath{\mathbb{1}}}$ then to test if ${\ensuremath{\mbox{SAT}}} = 0$).

With (\ref{formula_SAT_EFB_3}) the condition of the theorem~\ref{SAT_unsat_thm} may be written as
\begin{equation}
\label{formula_invariance_condition_2}
{e}_i \; {\ensuremath{\mbox{SAT}}} \; {e}_i^{-1} = \prod_{j = 1}^p ({\ensuremath{\mathbb{1}}} - {e}_i z_j {e}_i^{-1}) = \prod_{j = 1}^p ({\ensuremath{\mathbb{1}}} - z_j) \qquad 1 \le i \le 2 m {\;\; \mathrm{.}}
\end{equation}
\noindent We remark that in general this does \emph{not mean} that ${e}_i z_j {e}_i^{-1} = z_j$ but this form will result nevertheless useful. To apply this result to actual {\ensuremath{\mbox{SAT}}}{} literals it is easier to use the isomorphic ${\ensuremath{\mathbb{R}}}(2^m)$ matrix algebra.

\section{An algorithm to test for unsatisfiability}
\label{unSAT_algorithm}
We now use the result of previous paragraph to outline an algorithm to test unsatisfiability; as already stated ${\ensuremath{{{{\mathcal} C}\ell} {\left( {{\ensuremath{\mathbb{R}}}^{m,m}} \right)}}} {\cong} {\ensuremath{\mathbb{R}}}(2^m)$ and we can build explicitly this isomorphism (technically we fix the injection of the vector space in the isomorphic matrix algebra $\beta: V \to {\ensuremath{\mathbb{R}}}(2^m)$). Starting from $m = 1$, when ${\ensuremath{{{{\mathcal} C}\ell} {\left( {{\ensuremath{\mathbb{R}}}^{1,1}} \right)}}} {\cong} {\ensuremath{\mathbb{R}}}(2)$, we choose (it's not the only possible choice)
$$
{e}_1 = \left(\begin{array}{r r} 0 & 1 \\ 1 & 0 \end{array}\right) := \sigma \qquad {e}_2 = \left(\begin{array}{r r} 0 & -1 \\ 1 & 0 \end{array}\right) := \epsilon \qquad {e}_1 {e}_2 = \left(\begin{array}{r r} 1 & 0 \\ 0 & -1 \end{array}\right) := \tau
$$
and from this choice we can build, exploiting ${\ensuremath{{{{\mathcal} C}\ell} {\left( {{\ensuremath{\mathbb{R}}}^{m,m}} \right)}}}$ properties, the recursion relation that, from the $2 m$ generators of ${\ensuremath{{{{\mathcal} C}\ell} {\left( {{\ensuremath{\mathbb{R}}}^{m,m}} \right)}}}$, gives the $2m + 2$ of ${\ensuremath{{{{\mathcal} C}\ell} {\left( {{\ensuremath{\mathbb{R}}}^{m+1,m+1}} \right)}}}$, namely
\begin{equation*}
\label{formula_space_signature}
\left\{ \begin{array}{l}
{e}_i \otimes \tau \qquad 1 \le i \le 2 m \\
{\ensuremath{\mathbb{1}}}_{2^m} \otimes \sigma \\
{\ensuremath{\mathbb{1}}}_{2^m} \otimes \epsilon
\end{array} \right.
\end{equation*}
where ${\ensuremath{\mathbb{1}}}_{2^m}$ is the identity matrix of ${\ensuremath{\mathbb{R}}}(2^m)$. For our purposes it is instructive to write the generators explicitly in the generic $m$ case
\begin{equation}
\label{formula_generators_matrices}
\begin{array}{r@{} l l}
{e}_1 & {}= & \boldsymbol{\sigma} \otimes \tau \otimes \tau \otimes \tau \otimes \tau \otimes \tau \otimes \cdots \otimes \tau \\
{e}_2 & {}= & \boldsymbol{\epsilon} \otimes \tau \otimes \tau \otimes \tau \otimes \tau \otimes \tau \otimes \cdots \otimes \tau \\
{e}_3 & {}= & {\ensuremath{\mathbb{1}}} \otimes \boldsymbol{\sigma} \otimes \tau \otimes \tau \otimes \tau \otimes \tau \otimes \cdots \otimes \tau \\
{e}_4 & {}= & {\ensuremath{\mathbb{1}}} \otimes \boldsymbol{\epsilon} \otimes \tau \otimes \tau \otimes \tau \otimes \tau \otimes \cdots \otimes \tau \\
& & \qquad \cdots \\
{e}_{2 i - 1} & {}= & {\ensuremath{\mathbb{1}}} \otimes {\ensuremath{\mathbb{1}}} \otimes \cdots \otimes {\ensuremath{\mathbb{1}}} \otimes \boldsymbol{\sigma} \otimes \tau \otimes \cdots \otimes \tau \\
{e}_{2 i} & {}= & {\ensuremath{\mathbb{1}}} \otimes {\ensuremath{\mathbb{1}}} \otimes \cdots \otimes {\ensuremath{\mathbb{1}}} \otimes \boldsymbol{\epsilon} \otimes \tau \otimes \cdots \otimes \tau\\
& & \qquad \cdots \\
{e}_{2 m - 1} & {}= & {\ensuremath{\mathbb{1}}} \otimes {\ensuremath{\mathbb{1}}} \otimes {\ensuremath{\mathbb{1}}} \otimes {\ensuremath{\mathbb{1}}} \otimes {\ensuremath{\mathbb{1}}} \otimes \cdots \otimes {\ensuremath{\mathbb{1}}} \otimes \boldsymbol{\sigma} \\
{e}_{2 m} & {}= & {\ensuremath{\mathbb{1}}} \otimes {\ensuremath{\mathbb{1}}} \otimes {\ensuremath{\mathbb{1}}} \otimes {\ensuremath{\mathbb{1}}} \otimes {\ensuremath{\mathbb{1}}} \otimes \cdots \otimes {\ensuremath{\mathbb{1}}} \otimes \boldsymbol{\epsilon}\\
\end{array}
\end{equation}
where there are $m-1$ direct products in each term and we marked in bold $\sigma$ and $\epsilon$ matrices for visibility, moreover here ${\ensuremath{\mathbb{1}}}$ stands for the identity matrix in ${\ensuremath{\mathbb{R}}}(2)$. It is immediate to verify that these matrices satisfy the commutation relations (\ref{formula_generators}) of ${\ensuremath{{{{\mathcal} C}\ell} {\left( {{\ensuremath{\mathbb{R}}}^{m,m}} \right)}}}$ and that ${e}_{i}^2 = (-1)^{i + 1} {\ensuremath{\mathbb{1}}}$.

Let us now see the form of a generic literal, ${\ensuremath{\rho}}_i$, that we may write as ${\ensuremath{\rho}}_i \prod_{\stackrel{j = 1}{j \ne i}}^m {\ensuremath{\left\{ {q_j}, {p_j} \right\}}}$. For $m = 1$ it is easy to see that $qp = \frac{1}{2} ({\ensuremath{\mathbb{1}}} + \tau)$ and $pq = \frac{1}{2} ({\ensuremath{\mathbb{1}}} - \tau)$. It is then easy to verify that for generic $m$ a literal takes the form
\begin{equation}
\label{formula_generic_literal}
{\ensuremath{\rho}}_i = \frac{1}{2} {\ensuremath{\mathbb{1}}} \otimes {\ensuremath{\mathbb{1}}} \otimes \cdots \otimes {\ensuremath{\mathbb{1}}} \otimes ({\ensuremath{\mathbb{1}}} \pm \tau) \otimes {\ensuremath{\mathbb{1}}} \otimes \cdots \otimes {\ensuremath{\mathbb{1}}}
\end{equation}
where $({\ensuremath{\mathbb{1}}} \pm \tau)$ appears at $i$-th position and it is easy to see that, as anticipated, that literals can be represented by diagonal matrices. The generic term of the product (\ref{formula_SAT_EFB_2}) is
$$
{\ensuremath{\mathbb{1}}} - z_j = {\ensuremath{\mathbb{1}}} - {\overline{\ensuremath{\rho}}}_r {\overline{\ensuremath{\rho}}}_s \cdots {\overline{\ensuremath{\rho}}}_t = {\ensuremath{\mathbb{1}}} \otimes {\ensuremath{\mathbb{1}}} \otimes \cdots \otimes {\ensuremath{\mathbb{1}}} \; - \; \frac{1}{2^k} {\ensuremath{\mathbb{1}}} \otimes \cdots \otimes ({\ensuremath{\mathbb{1}}} \pm \tau) \otimes \cdots \otimes ({\ensuremath{\mathbb{1}}} \pm \tau) \otimes \cdots \otimes ({\ensuremath{\mathbb{1}}} \pm \tau) \otimes \cdots
$$
where the $k$ literals ${\overline{\ensuremath{\rho}}}_r, {\overline{\ensuremath{\rho}}}_s, \ldots, {\overline{\ensuremath{\rho}}}_t$ appear in the direct products as $({\ensuremath{\mathbb{1}}} \pm \tau)$ at positions $r, s, \ldots, t$ and it is also manifest that also this element of $S$ is represented by a diagonal matrix with $0, 1$ on the diagonal.

To apply the invariance test ${e}_i z_j {e}_i^{-1}$ and looking at the matrix formulation (\ref{formula_generators_matrices}) we easily see that we do not need to manipulate matrices of ${\ensuremath{\mathbb{R}}}(2^m)$ but that the test reduces to testing $m$ copies of ${\ensuremath{\mathbb{R}}}(2)$ matrices. Let us examine first the case $m = 1$, when ${\ensuremath{{{{\mathcal} C}\ell} {\left( {{\ensuremath{\mathbb{R}}}^{1,1}} \right)}}} {\cong} {\ensuremath{\mathbb{R}}}(2)$ where
$$
\sigma \tau \sigma^{-1} = \epsilon \tau \epsilon^{-1} = - \tau \qquad \qquad \tau \tau \tau^{-1} = {\ensuremath{\mathbb{1}}} \tau {\ensuremath{\mathbb{1}}}^{-1} = \tau
$$
and thus, for the generic literal of this case ${\ensuremath{\rho}} = \frac{1}{2} ({\ensuremath{\mathbb{1}}} \pm \tau)$,
$$
\sigma {\ensuremath{\rho}} \sigma^{-1} = \epsilon {\ensuremath{\rho}} \epsilon^{-1} = {\overline{\ensuremath{\rho}}} \qquad \qquad \tau {\ensuremath{\rho}} \tau^{-1} = {\ensuremath{\mathbb{1}}} {\ensuremath{\rho}} {\ensuremath{\mathbb{1}}}^{-1} = {\ensuremath{\rho}}
$$
and we notice that to test invariance it is sufficient to test invariance for $\sigma$ since it is equivalent to invariance for $\epsilon$. In this simple case it is easy to verify also theorem~\ref{SAT_unsat_thm} since the only unsatisfiable {\ensuremath{\mbox{SAT}}}{} for $m = 1$, ${\ensuremath{\rho}} {\overline{\ensuremath{\rho}}}$, is actually invariant since $\sigma {\ensuremath{\rho}} {\overline{\ensuremath{\rho}}} \sigma = {\ensuremath{\rho}} {\overline{\ensuremath{\rho}}}$.

Going to the generic $m$ case also here it will be sufficient to test invariance just for the odd generators ${e}_{2 i - 1}$ for which ${e}_{2 i - 1}^{-1} = {e}_{2 i - 1}$ and with (\ref{formula_generators_matrices}) and (\ref{formula_generic_literal}) it is simple to see that
\begin{equation}
\label{formula_literal_invariances}
{e}_{2 i - 1} {\ensuremath{\rho}}_j {e}_{2 i - 1} = {\ensuremath{\rho}}_j \quad \mbox{for} \quad i \ne j \qquad \qquad {e}_{2 i - 1} {\ensuremath{\rho}}_i {e}_{2 i - 1} = {\overline{\ensuremath{\rho}}}_i \quad \mbox{for} \quad 1 \le i \le m
\end{equation}
so the literal ${\ensuremath{\rho}}_i$ is complemented by ``its'' generator ${e}_{2 i - 1}$ and left invariant by all other generators, a typical case of reflections in Clifford algebras.

\bigskip

\begin{MS_Proposition}
\opt{margin_notes}{{\todo}{mbh.note: there is a slightly different proof of this proposition in the last pages, actually it proved difficult}}\label{e_i_invariance}
Testing the invariance
$$
{e}_{2 i - 1} \; {\ensuremath{\mbox{SAT}}} \; {e}_{2 i - 1} = {\ensuremath{\mbox{SAT}}}
$$
for any single $1 \le i \le m$ is equivalent to test the equality of 2 derived $(k-1)$-{\ensuremath{\mbox{SAT}}}{} problems in $m - 1$ logical variables ${\ensuremath{\mbox{SAT}}}_1 = {\ensuremath{\mbox{SAT}}}_2$ (defined in the sequel).
\end{MS_Proposition}

\begin{proof}
As already stated testing the logical equivalence of two logical expressions is equivalent to testing algebraic equality of the corresponding expressions in $S$ of ${\ensuremath{{{{\mathcal} C}\ell} {\left( {{\ensuremath{\mathbb{R}}}^{m,m}} \right)}}}$.

To test invariance of {\ensuremath{\mbox{SAT}}}{} problem under any of the $m$ odd generators ${e}_{2 i - 1}$ we start from its form (\ref{formula_invariance_condition_2}) and we separate the $p$ clauses into three classes: those in which ${\ensuremath{\rho}}_i$ appears, those in which ${\overline{\ensuremath{\rho}}}_i$ appears and the others in which neither appears. Obviously these three classes form three ``reduced'' $k$-{\ensuremath{\mbox{SAT}}}{} problems that we call respectively ${\ensuremath{\mbox{SAT}}}_1'$, ${\ensuremath{\mbox{SAT}}}_2'$ and ${\ensuremath{\mbox{SAT}}}_0$, clearly ${\ensuremath{\mbox{SAT}}} = {\ensuremath{\mbox{SAT}}}_0 {\ensuremath{\mbox{SAT}}}_1' {\ensuremath{\mbox{SAT}}}_2'$.

We start by ${\ensuremath{\mbox{SAT}}}_0$: by (\ref{formula_literal_invariances}) for all its clauses ${e}_{2 i - 1} z_j {e}_{2 i - 1} = z_j$ so they are invariant and ${\ensuremath{\mbox{SAT}}}_0$ is out of the game when testing ${e}_{2 i - 1}$ invariance.

Let us now consider the product of the clauses of the first set ${\ensuremath{\mbox{SAT}}}_1'$, those with ${\ensuremath{\rho}}_i$, that can be always put in the form (\ref{formula_SAT_EFB_3}). More precisely, since all these clauses contain ${\ensuremath{\rho}}_i$, when written in the form ${\ensuremath{\mathbb{1}}} - z_j$ certainly ${\overline{\ensuremath{\rho}}}_i$ appears in all $z_j$ and so for these clauses the form (\ref{formula_SAT_EFB_3}) is
$$
{\ensuremath{\mbox{SAT}}}_1' = {\ensuremath{\mathbb{1}}} - {\overline{\ensuremath{\rho}}}_i \Delta_1
$$
with $\Delta_1$ ``free'' of literals ${\overline{\ensuremath{\rho}}}_i$ and ${\ensuremath{\rho}}_i$. In a completely similar fashion ${\ensuremath{\mbox{SAT}}}_2'$ takes the form
$$
{\ensuremath{\mbox{SAT}}}_2' = {\ensuremath{\mathbb{1}}} - {\ensuremath{\rho}}_i \Delta_2 {\;\; \mathrm{.}}
$$
In summary we may write our original {\ensuremath{\mbox{SAT}}}{}
\begin{equation}
\label{formula_sat_subproblems}
{\ensuremath{\mbox{SAT}}} = {\ensuremath{\mbox{SAT}}}_0 ({\ensuremath{\mathbb{1}}} - {\overline{\ensuremath{\rho}}}_i \Delta_1) ({\ensuremath{\mathbb{1}}} - {\ensuremath{\rho}}_i \Delta_2) = {\ensuremath{\mbox{SAT}}}_0 \left[{\ensuremath{\mathbb{1}}} - ({\overline{\ensuremath{\rho}}}_i \Delta_1 + {\ensuremath{\rho}}_i \Delta_2)\right]
\end{equation}
and with (\ref{formula_literal_invariances})
$$
{e}_{2 i - 1} {\ensuremath{\mbox{SAT}}} {e}_{2 i - 1} = 
{\ensuremath{\mbox{SAT}}}_0 \left[{\ensuremath{\mathbb{1}}} - ({\overline{\ensuremath{\rho}}}_i \Delta_2 + {\ensuremath{\rho}}_i \Delta_1)\right]
$$
and we have thus to test wether
$$
{\ensuremath{\mbox{SAT}}}_0 \left[{\ensuremath{\mathbb{1}}} - ({\overline{\ensuremath{\rho}}}_i \Delta_1 + {\ensuremath{\rho}}_i \Delta_2)\right] = {\ensuremath{\mbox{SAT}}}_0 \left[{\ensuremath{\mathbb{1}}} - ({\overline{\ensuremath{\rho}}}_i \Delta_2 + {\ensuremath{\rho}}_i \Delta_1)\right]
$$
where both sides of the equality are element of $S$. Since this is an algebraic equality we can rearrange it to get
$$
{\ensuremath{\mbox{SAT}}}_0 \left[{\ensuremath{\mathbb{1}}} - {\overline{\ensuremath{\rho}}}_i (\Delta_1 - \Delta_2)\right] = {\ensuremath{\mbox{SAT}}}_0 \left[{\ensuremath{\mathbb{1}}} - {\ensuremath{\rho}}_i (\Delta_1 - \Delta_2)\right]
$$
and since ${\ensuremath{\mbox{SAT}}}_0, \Delta_1, \Delta_2$ are all without literals ${\ensuremath{\rho}}_i$ and ${\overline{\ensuremath{\rho}}}_i$ this equality may hold\footnote{since ${\ensuremath{\mbox{SAT}}}_0$ do not contain $i$-th literal it is actually $({\ensuremath{\rho}}_i + {\overline{\ensuremath{\rho}}}_i) {\ensuremath{\mbox{SAT}}}_0$ and is thus formed by a sum of two identical parts, one in ${\ensuremath{\rho}}_i$ and one in ${\overline{\ensuremath{\rho}}}_i$.  The factors in square parenthesis act selectively on only one of these parts and thus the result can never be equal unless $\Delta_1 = \Delta_2$.}{} if and only if $\Delta_1 = \Delta_2$ or, going to the complementary relation
$$
{\ensuremath{\mathbb{1}}} - \Delta_1 = {\ensuremath{\mathbb{1}}} - \Delta_2
$$
or ${\ensuremath{\mbox{SAT}}}_1 = {\ensuremath{\mbox{SAT}}}_2$ calling ${\ensuremath{\mbox{SAT}}}_l := {\ensuremath{\mathbb{1}}} - \Delta_l, l = 1,2$. It remains to show now that ${\ensuremath{\mbox{SAT}}}_i$ are actually $(k-1)$-{\ensuremath{\mbox{SAT}}}{} problems in $m - 1$ logical variables. Remembering the definition of {e.g.\ } ${\ensuremath{\mbox{SAT}}}_1'$ as the reduced problems containing only clauses in which ${\ensuremath{\rho}}_i$ appears explicitly, we showed easily that ${\ensuremath{\mbox{SAT}}}_1' = {\ensuremath{\mathbb{1}}} - {\overline{\ensuremath{\rho}}}_i \Delta_1$. It is a simple exercise to show that taking the very same clauses that form ${\ensuremath{\mbox{SAT}}}_1'$ and \emph{removing} from them ${\ensuremath{\rho}}_i$ we obtain a $(k-1)$-{\ensuremath{\mbox{SAT}}}{} problems in $m - 1$ logical variables whose form (\ref{formula_invariance_condition_2}) is ${\ensuremath{\mathbb{1}}} - \Delta_1$.
\end{proof}

Since the proposition holds for all $1 \le i \le m$ we have demonstrated:
\begin{MS_Corollary}
\label{unsatisfiability}
${\ensuremath{\mbox{SAT}}} = 0$ if and only if the $m$ couples of derived $(k-1)$-{\ensuremath{\mbox{SAT}}}{} problems in $m - 1$ logical variables of previous proposition are equivalent.
\end{MS_Corollary}

We can thus derive an algorithm that tests for unsatisfiability:
\begin{MS_Algorithm}
\label{unSAT_algorithm_outline}
{}~{}

\begin{enumerate}
\item set $i = 1$;
\item generate the two auxiliary $(k-1)$-{\ensuremath{\mbox{SAT}}}{} problems in $m - 1$ logical variables ${\ensuremath{\mbox{SAT}}}_1$ and ${\ensuremath{\mbox{SAT}}}_2$ relative to literal ${\ensuremath{\rho}}_i$;
\item if ${\ensuremath{\mbox{SAT}}}_1 \ne {\ensuremath{\mbox{SAT}}}_2$ the problem is satisfiable; STOP;
\item if $i < m$ set $i = i + 1$ and go to 2
\item the problem is unsatisfiable; STOP.
\end{enumerate}
\end{MS_Algorithm}

The central point of this algorithm is to understand how difficult is to perform the test
\begin{equation}
\label{formula_sat_subproblem}
{\ensuremath{\mbox{SAT}}}_1 = {\ensuremath{\mbox{SAT}}}_2
\end{equation}
of step 3.

Before tackling this problem we remark that if our original {\ensuremath{\mbox{SAT}}}{} problem was a $2$-{\ensuremath{\mbox{SAT}}}{} problem the derived problems generated in each test are $1$-{\ensuremath{\mbox{SAT}}}{} problems that thus admit immediate solutions. In other words it is sufficient to remove from the derived ${\ensuremath{\mbox{SAT}}}_1$ and ${\ensuremath{\mbox{SAT}}}_2$ relative to literal ${\ensuremath{\rho}}_i$ the $i$-th literal and compare the resulting $1$-{\ensuremath{\mbox{SAT}}}{} expressions, if they are equal the test is passed. Since this comparison can be done in polynomial time algorithm~\ref{unSAT_algorithm_outline} provides a simple interpretation of the reason that make $2$-{\ensuremath{\mbox{SAT}}}{} problems polynomial.

\bigskip

We try now to analyze the complexity calculating the test (\ref{formula_sat_subproblem}) for $3$-{\ensuremath{\mbox{SAT}}}{} problem; in this case the two derived problems for each of the $m$ invariance tests are $2$-{\ensuremath{\mbox{SAT}}}{} problems in $m - 1$ variables that, on average, are formed by $\frac{3}{2} \alpha$ clauses.

Since we are analyzing algebraic expression the test is equivalent to test wether ${\ensuremath{\mbox{SAT}}}_1 - {\ensuremath{\mbox{SAT}}}_2 = 0$ and we can recursively apply to it proposition~\ref{e_i_invariance} and check wether
$$
{e}_{2 j - 1} \; ({\ensuremath{\mbox{SAT}}}_1 - {\ensuremath{\mbox{SAT}}}_2) \; {e}_{2 j - 1} = {\ensuremath{\mbox{SAT}}}_1 - {\ensuremath{\mbox{SAT}}}_2
$$
for $m - 1$ values of $j$. With an obvious extension of the notation employed in (\ref{formula_sat_subproblems}) we write
\begin{equation}
\label{formula_reduced_1}
{\ensuremath{\mbox{SAT}}}_1 - {\ensuremath{\mbox{SAT}}}_2 = {\ensuremath{\mbox{SAT}}}_{1,0} \left[{\ensuremath{\mathbb{1}}} - ({\overline{\ensuremath{\rho}}}_j \Delta_{1,1} + {\ensuremath{\rho}}_j \Delta_{1,2})\right] -  {\ensuremath{\mbox{SAT}}}_{2,0} \left[{\ensuremath{\mathbb{1}}} - ({\overline{\ensuremath{\rho}}}_j \Delta_{2,1} + {\ensuremath{\rho}}_j \Delta_{2,2})\right]
\end{equation}
where ${\ensuremath{\mbox{SAT}}}_{1,0}$ and ${\ensuremath{\mbox{SAT}}}_{2,0}$ are $2$-{\ensuremath{\mbox{SAT}}}{} problems in $m-2$ variables without the literal $j$ under test and $\Delta_{1,1}, \Delta_{1,2}, \Delta_{2,1}$ and $\Delta_{2,2}$ are the form (\ref{formula_invariance_condition_2}) of $1$-{\ensuremath{\mbox{SAT}}}{} problems in $m-2$ variables also without the literal $j$.

This expression is to be tested for equality with the transformed expression that with (\ref{formula_literal_invariances}) can be easily calculated to be
\begin{equation}
\label{formula_reduced_2}
{e}_{2 j - 1} \; ({\ensuremath{\mbox{SAT}}}_1 - {\ensuremath{\mbox{SAT}}}_2) \; {e}_{2 j - 1} = {\ensuremath{\mbox{SAT}}}_{1,0} \left[{\ensuremath{\mathbb{1}}} - ({\overline{\ensuremath{\rho}}}_j \Delta_{1,2} + {\ensuremath{\rho}}_j \Delta_{1,1})\right] -  {\ensuremath{\mbox{SAT}}}_{2,0} \left[{\ensuremath{\mathbb{1}}} - ({\overline{\ensuremath{\rho}}}_j \Delta_{2,2} + {\ensuremath{\rho}}_j \Delta_{2,1})\right]
\end{equation}
and the equality of the two expressions (\ref{formula_reduced_2}) and (\ref{formula_reduced_1}) can be reduced, with simple algebraic manipulations, to
$$
\begin{array}{l}
{\overline{\ensuremath{\rho}}}_j ({\ensuremath{\mbox{SAT}}}_{1,0} \Delta_{1,2} - {\ensuremath{\mbox{SAT}}}_{2,0} \Delta_{2,2}) + {\ensuremath{\rho}}_j ({\ensuremath{\mbox{SAT}}}_{1,0} \Delta_{1,1} - {\ensuremath{\mbox{SAT}}}_{2,0} \Delta_{2,1}) = \\
{\overline{\ensuremath{\rho}}}_j ({\ensuremath{\mbox{SAT}}}_{1,0} \Delta_{1,1} - {\ensuremath{\mbox{SAT}}}_{2,0} \Delta_{2,1}) + {\ensuremath{\rho}}_j ({\ensuremath{\mbox{SAT}}}_{1,0} \Delta_{1,2} - {\ensuremath{\mbox{SAT}}}_{2,0} \Delta_{2,2})
\end{array}
$$
and since all the terms in parenthesis do not have the literal $j$ this equality may hold if and only if the terms with ${\overline{\ensuremath{\rho}}}_j$ and those with ${\ensuremath{\rho}}_j$ are separately equal and thus iff
$$
{\ensuremath{\mbox{SAT}}}_{1,0} \Delta_{1,2} - {\ensuremath{\mbox{SAT}}}_{2,0} \Delta_{2,2} = {\ensuremath{\mbox{SAT}}}_{1,0} \Delta_{1,1} - {\ensuremath{\mbox{SAT}}}_{2,0} \Delta_{2,1}
$$
that is equivalent to
$$
{\ensuremath{\mbox{SAT}}}_{1,0} (\Delta_{1,2} - \Delta_{1,1}) = {\ensuremath{\mbox{SAT}}}_{2,0} (\Delta_{2,2} - \Delta_{2,1})
$$
that is a logical equality between expressions with $m-2$ logical variables.

By (\ref{formula_SAT_EFB_3}) it is clear that $\Delta_{a,b} = {\overline{{{\ensuremath{\mbox{SAT}}}_{a,b}}}}$ where ${\ensuremath{\mbox{SAT}}}_{a,b}$ is a 1-{\ensuremath{\mbox{SAT}}}{} problem in $m-2$ variables and a problem of this kind has necessarily the form
$$
{\ensuremath{\mbox{SAT}}}_{a,b} =  {\ensuremath{\rho}}_r {\ensuremath{\rho}}_s \cdots {\ensuremath{\rho}}_t := s_{a,b} = {\ensuremath{\mathbb{1}}} - \Delta_{a,b} {\;\; \mathrm{.}}
$$
Leaving aside for the moment the simpler case of $s_{a,b} = 0$, that imply $\Delta_{a,b} = {\ensuremath{\mathbb{1}}}$, we see that the equality we have to test reduces to
$$
{\ensuremath{\mbox{SAT}}}_{1,0} (s_{1,1} - s_{1,2}) = {\ensuremath{\mbox{SAT}}}_{2,0} (s_{2,1} - s_{2,2})
$$
and we remark that ${\ensuremath{\mbox{SAT}}}_{1,0} s_{1,1}$ is a further reduced 2-{\ensuremath{\mbox{SAT}}}{} problem in which the literals that appear in $s_{1,1}$ have been given their logical values. So the initial test (\ref{formula_sat_subproblem}) can be again broken up in a certain number of equality tests between 2-{\ensuremath{\mbox{SAT}}}{} problems. If for example the 1-{\ensuremath{\mbox{SAT}}}{} formula $s_{1,1}$ is made of $r$ literals the problem ${\ensuremath{\mbox{SAT}}}_{1,0} s_{1,1}$ will be a problem in $m - 2 - r$ logical variables.

Obtaining the asymptotic properties of the recursion algorithm we have sketched to test (\ref{formula_sat_subproblem}) appears not simple (at least to the author) and beyond the goal of this paper that was to present the formulation of {\ensuremath{\mbox{SAT}}}{} problems in Clifford algebra and is thus left to further research.

\section{Conclusions}
\label{Conclusions}
It is not clear wether the performances of this algorithm may compete with state of the art {\ensuremath{\mbox{SAT}}}{} solvers but its theoretical properties appears interesting at least for the transformation of a typical combinatorial problem, one is tempted to say \emph{the} archetypical combinatorial problem, in a purely algebraic setting in Clifford algebra.

The main contribution of Clifford algebra is that it allows to manipulate some of the exponentially large expressions obtained by the expansion of {\ensuremath{\mbox{SAT}}}{} problems, manipulating just $m$ matrices of size 2. Moreover testing unsatisfiability by means of geometric invariance of idempotents under reflections of ${e}_{2 i - 1}$ generators appears promising.

We remark that one can exploit {\ensuremath{\mbox{SAT}}}{} formulation (\ref{formula_SAT_EFB_3}) to find also other properties to test unsatisfiability of a given {\ensuremath{\mbox{SAT}}}{} problem, namely to test if $\Delta = {\ensuremath{\mathbb{1}}}$, for example one could use different methods to characterize ${\ensuremath{\mathbb{1}}}$, {e.g.\ } that the secular equation of matrix $\Delta$ is $(\lambda - 1)^m = 0$.

\bigskip
\bigskip
\bigskip
\bigskip

\opt{x,std,AACA}{
\bibliographystyle{plain} 

\bibliography{mbh}
}

\opt{arXiv,JMP}{
\begin{thebibliography}{1}

\bibitem{Budinich_2016}
Marco Budinich.
\newblock On spinors transformations.
\newblock {\em Journal of Mathematical Physics}, 57(7):071703--1--11, July
  2016.
\newblock arXiv:1603.02181 [math-ph] 7 Mar 2016.

\bibitem{Cartan_1913}
{\'{E}}lie Cartan.
\newblock Les groupes projectifs qui ne laissent invariante aucune
  multiplicit{\'e} plane.
\newblock {\em Bulletin de la Soci{\'e}t{\'e} Math{\'e}matique de France},
  41:53--96, 1913.

\bibitem{Cartan_1937}
{\'{E}}lie Cartan.
\newblock {\em The Theory of Spinors}.
\newblock Hermann, Paris, 1966.
\newblock first edition: 1938 in French.

\bibitem{Chevalley_1954}
Claude~C. Chevalley.
\newblock {\em Algebraic Theory of Spinors}.
\newblock Columbia University Press, New York, 1954.

\bibitem{Cook_1971}
Stephen~A. Cook.
\newblock {The Complexity of Theorem-proving Procedures}.
\newblock In {\em Proceedings of the Third Annual ACM Symposium on Theory of
  Computing}, STOC '71, pages 151--158, New York, NY, USA, 1971. ACM.

\bibitem{Knuth_2015}
Donald~Ervin Knuth.
\newblock {\em The Art of Computer Programming. Combinatorial Algorithms},
  volume~IV.
\newblock Addison-Wiley, Reading, MA, pre-release in fascicles edition, 2015.

\bibitem{PaturiPudlakSaksZane_2005}
Ramamohan Paturi, Pavel Pudl\'{a}k, Michael~E. Saks, and Francis Zane.
\newblock {An Improved Exponential-time Algorithm for k-SAT}.
\newblock {\em Journal of the ACM}, 52(3):337--364, May 2005.

\bibitem{Porteous_1995}
Ian~Robertson Porteous.
\newblock {\em Clifford Algebras and the Classical Groups}.
\newblock Cambridge Studies in Advanced Mathematics 50. Cambridge University
  Press, 1995.

\end{thebibliography}
}

\opt{final_notes}{
\newpage

\section*{Things to do, notes, etc.......}

\subsection*{Other propositions, other material, etc.......}
\subsubsection*{Things to do}
\begin{itemize}
\item verify complexity of testing ${\ensuremath{\mbox{SAT}}}_1 = {\ensuremath{\mbox{SAT}}}_2$;
\item put the part on NOT before the part on OR and semplify everything;
\item introduce a better notation for S, P and {\ensuremath{\mbox{SAT}}} ({e.g.\ } ${\mathcal}{S}$, ${\mathcal}{P}$, $S_i$);
\item other ideas:
\begin{itemize}
\item as in Onsager solutions find the transformation in ${\ensuremath{\mathbb{R}}}^{m,m}$ corresponding to a given ${\ensuremath{\mbox{SAT}}}$ problem in ${\ensuremath{{{{\mathcal} C}\ell} {\left( {{\ensuremath{\mathbb{R}}}^{m,m}} \right)}}}$
\item exploit better the solution with $\Delta = {\ensuremath{\mathbb{1}}}$ writing $\Delta = ({\ensuremath{\rho}}_i + {\overline{\ensuremath{\rho}}}_i) \Delta'$ with $\Delta'$ in ${\ensuremath{{{{\mathcal} C}\ell} {\left( {{\ensuremath{\mathbb{R}}}^{m-1,m-1}} \right)}}}$; something is done in the alternative proof of proposition~\ref{e_i_invariance} at the end;
\item exploit idea of secular equation;
\item ...
\end{itemize}

\end{itemize}

\subsection*{Old parts, removed, unnecessary, etc.......}
\subsubsection*{Old parts of section~\ref{SAT_basics}}
A standard representation of Boolean associates $\{\mathrm{T}, \mathrm{F}\}$ to $\{1, 0\}$, logical OR to addition (modulo 2), logical AND to multiplication, and logical complement to the swap of $0$ and $1$, or equivalently, to the addition of $1$, then it is simple to prove that expanding expression (\ref{formula_SAT_std}) using the standard rules of arithmetic, together with ${\ensuremath{\rho}}_i {\ensuremath{\rho}}_i = {\ensuremath{\rho}}_i$ and ${\ensuremath{\rho}}_i {\overline{\ensuremath{\rho}}}_i = 0$, a solution exists if and only if at least one of these terms is non zero.

\subsubsection*{Old parts of section~\ref{SAT_reformulation}}
Remembering the EFB rules
$$
p_i q_i p_i q_i = p_i q_i \quad p_i q_i q_i p_i = 0 \quad p_i q_i p_j q_j = p_j q_j p_i q_i \quad q_i p_i + p_i q_i = 1
$$
it is easy to see that to any logical OR one can assign the sum of the corresponding ${\ensuremath{{{{\mathcal} C}\ell} {\left( {{\ensuremath{\mathbb{R}}}^{m,m}} \right)}}}$ elements {e.g.\ }
$$
x_1 + {\overline{{x}}}_3 \to q_1 p_1 + p_3 q_3
$$
and this formula is satisfied for {e.g.\ } $x_1 = \mathrm{T}, x_3 = \mathrm{F}$, this is represented in ${\ensuremath{{{{\mathcal} C}\ell} {\left( {{\ensuremath{\mathbb{R}}}^{m,m}} \right)}}}$ by the Clifford product
$$
(q_1 p_1 + p_3 q_3) q_1 p_1 p_3 q_3 = q_1 p_1 + p_3 q_3 \ne 0
$$
where one sees that the ``substitution'' of a given assignment of variables ($q_1 p_1 p_3 q_3$) in a {\ensuremath{\mbox{SAT}}}{} formula $(q_1 p_1 + p_3 q_3)$ is done with Clifford product and if the result is non zero the result is $\mathrm{T}$. It is easy to check the other 3 assignments that satisfy this formula and the only one that does not.

The procedure is the same for the logical AND that is associated to Clifford product
$$
x_1 {\overline{{x}}}_2 \to q_1 p_1 p_2 q_2
$$
and also in this case it is easy to see that an assignment of variables satisfies the given formula ($x_1 {\overline{{x}}}_2$) if and only if the Clifford product of the formula with the assignment is non zero. We see that an element like $q_1 p_1 p_2 q_2$ can be thought to represent both a formula and an assignment of variables and the assignment satisfies the formula if their product is non zero.

\bigskip

\noindent old comments following the general logical NOT formula (\ref{formula_complemented_assignement})

We remark that (\ref{formula_complemented_assignement}) needs a more formal proof since it uses the sum that we have seen can not be always mapped to a logical operation. We postpone a proof for a moment and use (\ref{formula_complemented_assignement}) and De Morgan's relations to get a more convenient form for a clause $C_j$....

\subsubsection*{Old parts of section~\ref{unSAT_algorithm}}
Before using these results for an algorithm that tests for unsatisfiability we need a technical
\begin{MS_lemma}
\label{technical_lemma}
given $s \in S - \{0\}$ then $s = {\ensuremath{\mathbb{1}}}$ if and only if, for any $1 \le i \le m$ then $s = {\ensuremath{\left\{ {q_i}, {p_i} \right\}}} s'$ where $s' \in S$ and ${e}_{2 i - 1} s' {e}_{2 i - 1}^{-1} = s'$ and ${e}_{2 i} s' {e}_{2 i}^{-1} = s'$.
\end{MS_lemma}
\begin{proof}
The forward part of the lemma descends immediately from the expression of ${\ensuremath{\mathbb{1}}}$ in EFB (\ref{formula_identity_def}) and the observation that ${e}_{j} {\ensuremath{\left\{ {q_i}, {p_i} \right\}}} {e}_{j}^{-1} = {\ensuremath{\left\{ {q_i}, {p_i} \right\}}}$ for any $j$ since ${\ensuremath{\left\{ {q_i}, {p_i} \right\}}} = 1$. Let us now suppose that for $s$ holds the given property: then for any $1 \le i \le m$ we may write $s = {\ensuremath{\left\{ {q_i}, {p_i} \right\}}} s'$ and ${e}_{2 i - 1} s {e}_{2 i - 1}^{-1} = {e}_{2 i} s {e}_{2 i}^{-1} = s$ so that for all $1 \le i \le 2 m$ ${e}_{i} s {e}_{i}^{-1} = s$ and thus by \cite[Propostion~16.6]{Porteous_1995} $s = \delta {\ensuremath{\mathbb{1}}}$ with $\delta \in {\ensuremath{\mathbb{R}}}$ but since $s \in S - \{0\}$ the only possibility is $\delta = 1$.
\end{proof}

\begin{MS_Proposition}
\label{e_i_invariance_old}
Testing the invariance
$$
{e}_{2 i - 1} \; {\ensuremath{\mbox{SAT}}} \; {e}_{2 i - 1} = {\ensuremath{\mbox{SAT}}}
$$
for any single $1 \le i \le m$ is equivalent to test the equality of 2 derived $(k-1)$-{\ensuremath{\mbox{SAT}}}{} problems in $m - 1$ logical variables ${\ensuremath{\mbox{SAT}}}_1 = {\ensuremath{\mbox{SAT}}}_2$ (defined in the sequel).
\end{MS_Proposition}

\begin{proof}
As already stated it is equivalent to test either logical equality of the logical expressions or the algebraic equality of the corresponding expressions in ${\ensuremath{{{{\mathcal} C}\ell} {\left( {{\ensuremath{\mathbb{R}}}^{m,m}} \right)}}}$.

To test invariance of {\ensuremath{\mbox{SAT}}}{} problem under any of the $m$ odd generators ${e}_{2 i - 1}$ we start from the form (\ref{formula_invariance_condition_2}) and we separate the $p$ clauses into three classes: those in which ${\ensuremath{\rho}}_i$ appears, those in which ${\overline{\ensuremath{\rho}}}_i$ appears and the others in which neither appears. Obviously these three classes form three ``reduced'' $k$-{\ensuremath{\mbox{SAT}}}{} problems that we call respectively ${\ensuremath{\mbox{SAT}}}_1'$, ${\ensuremath{\mbox{SAT}}}_2'$ and ${\ensuremath{\mbox{SAT}}}_0$, clearly ${\ensuremath{\mbox{SAT}}} = {\ensuremath{\mbox{SAT}}}_0 {\ensuremath{\mbox{SAT}}}_1' {\ensuremath{\mbox{SAT}}}_2'$.

We start by ${\ensuremath{\mbox{SAT}}}_0$: for all its clauses ${e}_{2 i - 1} z_j {e}_{2 i - 1} = z_j$ so they are invariant and ${\ensuremath{\mbox{SAT}}}_0$ remains out of the game when testing ${e}_{2 i - 1}$ invariance.

Let us now consider the product of the clauses of the first set ${\ensuremath{\mbox{SAT}}}_1'$, those with ${\ensuremath{\rho}}_i$, that can be always put in the form (\ref{formula_SAT_EFB_3}). More precisely, since all these clauses contain ${\ensuremath{\rho}}_i$, when written in the complemented form ${\ensuremath{\mathbb{1}}} - z_j$ we are sure that ${\overline{\ensuremath{\rho}}}_i$ appears in $z_j$ and so for these clauses
$$
{\ensuremath{\mbox{SAT}}}_1' = {\ensuremath{\mathbb{1}}} - {\overline{\ensuremath{\rho}}}_i \Delta_1
$$
with $\Delta_1$ ``free'' of literals ${\ensuremath{\rho}}_i$ and ${\overline{\ensuremath{\rho}}}_i$. In a completely similar fashion ${\ensuremath{\mbox{SAT}}}_2'$ takes the form
$$
{\ensuremath{\mbox{SAT}}}_2' = {\ensuremath{\mathbb{1}}} - {\ensuremath{\rho}}_i \Delta_2 {\;\; \mathrm{.}}
$$
In summary we may write our original {\ensuremath{\mbox{SAT}}}{}
$$
{\ensuremath{\mbox{SAT}}} = {\ensuremath{\mbox{SAT}}}_0 ({\ensuremath{\mathbb{1}}} - {\overline{\ensuremath{\rho}}}_i \Delta_1) ({\ensuremath{\mathbb{1}}} - {\ensuremath{\rho}}_i \Delta_2) = {\ensuremath{\mbox{SAT}}}_0 \left[{\ensuremath{\mathbb{1}}} - ({\overline{\ensuremath{\rho}}}_i \Delta_1 + {\ensuremath{\rho}}_i \Delta_2)\right]
$$
and, as we have seen, ${\ensuremath{\mbox{SAT}}} = 0$ is equivalent to ${\ensuremath{\mathbb{1}}} - {\ensuremath{\mbox{SAT}}} = \Delta = {\ensuremath{\mathbb{1}}}$ so to apply lemma~\ref{technical_lemma} we consider the complementary expression
$$
{\ensuremath{\mathbb{1}}} - {\ensuremath{\mbox{SAT}}} = {\ensuremath{\mathbb{1}}} - {\ensuremath{\mbox{SAT}}}_0 \left[{\ensuremath{\mathbb{1}}} - ({\overline{\ensuremath{\rho}}}_i \Delta_1 + {\ensuremath{\rho}}_i \Delta_2)\right]
$$
and since literals ${\ensuremath{\rho}}_i$ and ${\overline{\ensuremath{\rho}}}_i$ do not appear neither in ${\ensuremath{\mbox{SAT}}}_0$ nor in $\Delta_1$ nor in $\Delta_2$ but they implicitly appear, with all other anticommutators, in ${\ensuremath{\mathbb{1}}}$, we see that we can write this expression in the form
$$
{\ensuremath{\mathbb{1}}} - {\ensuremath{\mbox{SAT}}} = ({\overline{\ensuremath{\rho}}}_i + {\ensuremath{\rho}}_i) \left[{\ensuremath{\mathbb{1}}} - {\ensuremath{\mbox{SAT}}}_0 ({\ensuremath{\mathbb{1}}} - \Delta_1)\right]
$$
\opt{margin_notes}{{\todo}{mbh.note: note that the expression in square parenthesis is actually in Clifford algebra of ${\ensuremath{\mathbb{R}}}^{m-1,m-1}$}}if and only if $\Delta_1 = \Delta_2$ or, going to the complementary relation, if and only if
$$
{\ensuremath{\mathbb{1}}} - \Delta_1 = {\ensuremath{\mathbb{1}}} - \Delta_2 {\;\; \mathrm{.}}
$$
Clearly if this holds, we satisfy the conditions of technical lemma~\ref{technical_lemma} since $({\overline{\ensuremath{\rho}}}_i + {\ensuremath{\rho}}_i) = {\ensuremath{\left\{ {q_i}, {p_i} \right\}}}$ and $\left[{\ensuremath{\mathbb{1}}} - {\ensuremath{\mbox{SAT}}}_0 ({\ensuremath{\mathbb{1}}} - \Delta_1)\right]$ is free of literals ${\ensuremath{\rho}}_i$ and ${\overline{\ensuremath{\rho}}}_i$, this means that ${\ensuremath{\mathbb{1}}} - {\ensuremath{\mbox{SAT}}}$ is invariant for the reflections generated by ${e}_{2 i - 1}$ and ${e}_{2 i}$ and thus also {\ensuremath{\mbox{SAT}}}.

It remains to show now that ${\ensuremath{\mbox{SAT}}}_1 := {\ensuremath{\mathbb{1}}} - \Delta_1$ and ${\ensuremath{\mbox{SAT}}}_2 := {\ensuremath{\mathbb{1}}} - \Delta_2$ are actually $(k-1)$-{\ensuremath{\mbox{SAT}}}{} problems in $m - 1$ logical variables. Remembering the definition of {e.g.\ } ${\ensuremath{\mbox{SAT}}}_1'$ as the reduced problems containing only clauses in which ${\ensuremath{\rho}}_i$ appears explicitly, we showed easily that ${\ensuremath{\mbox{SAT}}}_1' = {\ensuremath{\mathbb{1}}} - {\overline{\ensuremath{\rho}}}_i \Delta_1$ with $\Delta_1$ free of ${\ensuremath{\rho}}_i$. It is a simple exercise to show that taking the very same clauses that form ${\ensuremath{\mbox{SAT}}}_1'$ and \emph{removing} from them ${\ensuremath{\rho}}_i$ we obtain a $(k-1)$-{\ensuremath{\mbox{SAT}}}{} problems in $m - 1$ logical variables whose form is precisely ${\ensuremath{\mathbb{1}}} - \Delta_1$.
\end{proof}

\bigskip

\noindent old --tentative-- final part of this paragraph

Before tackling the resolution of this subproblem we remark:
\begin{itemize}
\item on average ${\ensuremath{\mbox{SAT}}}_1$ and ${\ensuremath{\mbox{SAT}}}_2$ are formed by $\frac{k}{2} \alpha$ clauses and ${\ensuremath{\mbox{SAT}}}_0$ is formed by $(m - k) \alpha$ clauses;
\item always on average $\Delta_1$ and $\Delta_2$, when fully expanded, can contain at most $2^{\frac{k}{2} \alpha}$ terms, a number of terms that remains constant in the limit $m \to \infty$;
\item if ${\ensuremath{\mbox{SAT}}}_1$ and ${\ensuremath{\mbox{SAT}}}_2$ are formed by $p_{i,1}, p_{i,2}$ clauses each then $\sum_{i = 1}^m p_{i,1} + p_{i,2} = k p$ (assuming all clauses have exactly $k$ literals);
\item if our original {\ensuremath{\mbox{SAT}}}{} problem had $k$ literals per clause in $m$ variables the generated expression $\Delta_1$ and $\Delta_2$ are formulations of $(k-1)$-{\ensuremath{\mbox{SAT}}}{} with $m-1$ variables.

This can be verified with simple algebra manipulation: take the reduced ${\ensuremath{\mbox{SAT}}}_1$problem made only by the clauses in which ${\ensuremath{\rho}}_i$ appears and then remove all the apearences of ${\ensuremath{\rho}}_i$, this produces a reduced $(k-1)$-{\ensuremath{\mbox{SAT}}}{} with $m-1$ variables ${\ensuremath{\mbox{SAT}}}_1'$, that put in its (\ref{formula_SAT_EFB_3}) form is exactly ${\ensuremath{\mbox{SAT}}}_1' = {\ensuremath{\mathbb{1}}} - \Delta_1$;
\item to certify unsatisfiability one need to perform $m$ invariance test of the original problem but the first test that fails guarantees satisfiability but do not provide a solution. It is known that it is simple to use this algorithm to find an actual solution of the problem (test for unsatisfiability the two reduced problems with ${\ensuremath{\rho}}_i = \mathrm{T}, \mathrm{F}$ and then proceed to all other literals).
\item it remains to be established how hard is to test $\Delta_1 = \Delta_2$; if testing the logical equivalence is TAUT we know that this problem is substantially equivalent to {\ensuremath{\mbox{SAT}}}{} but this new {\ensuremath{\mbox{SAT}}}{} problem would be a 2-{\ensuremath{\mbox{SAT}}}....
\end{itemize}

} 

\end{document}

